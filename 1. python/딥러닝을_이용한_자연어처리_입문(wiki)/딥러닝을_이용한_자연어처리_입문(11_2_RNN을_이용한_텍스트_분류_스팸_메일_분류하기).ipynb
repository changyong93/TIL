{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "딥러닝을_이용한_자연어처리_입문(11_2_RNN을 이용한 텍스트 분류- 스팸 메일 분류하기)",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOrHGppdX0Uj02BBo4BC+gr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/changyong93/Natural-language-processing-with-chat-bot/blob/main/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84_%EC%9D%B4%EC%9A%A9%ED%95%9C_%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC_%EC%9E%85%EB%AC%B8(11_2_RNN%EC%9D%84_%EC%9D%B4%EC%9A%A9%ED%95%9C_%ED%85%8D%EC%8A%A4%ED%8A%B8_%EB%B6%84%EB%A5%98_%EC%8A%A4%ED%8C%B8_%EB%A9%94%EC%9D%BC_%EB%B6%84%EB%A5%98%ED%95%98%EA%B8%B0).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6gNa_WwYdSV"
      },
      "source": [
        "## 스팸 메일 분류하기\n",
        "- https://wikidocs.net/22894\n",
        "---\n",
        "캐글(https://www.kaggle.com/uciml/sms-spam-collection-dataset)에서 제공하는 정상메일과 스팸메일이 섞여 있는 스팸 메일 데이터를 가지고, 데이터 전처리 후 바닐라RNN을 이용한 스팸 메일 분류기 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPX9Rin8YyGn"
      },
      "source": [
        "### 스팸 메일 데이터 이해"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKgjt968m7xR"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydQOtmPcYz1S"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1oovrY0ZGEt"
      },
      "source": [
        "import io\n",
        "data = pd.read_csv((io.StringIO(uploaded['spam.csv'].decode('latin1'))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yvp-by8fZR6z"
      },
      "source": [
        "print(f\"총 샘플의 수 : {len(data)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SNs63-qappx"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu0ifXBSarq_"
      },
      "source": [
        "del data['Unnamed: 2']\n",
        "del data['Unnamed: 3']\n",
        "del data['Unnamed: 4']\n",
        "data['v1'] = data['v1'].replace(['ham','spam'],[0,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7as0f8fa-F3"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLvEkT0AbBX1"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pqss6ijbDte"
      },
      "source": [
        "data.isnull().values.any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_7bL_ybbLq2"
      },
      "source": [
        "data.v1.nunique(),data.v2.nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLvgk1NUbfhT"
      },
      "source": [
        "data = data.drop_duplicates(subset = ['v2']).copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw8f1DE-b4rq"
      },
      "source": [
        "print(f\"총 샘플의 수 : {len(data)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD6WlYFJb9Ax"
      },
      "source": [
        "data.v1.value_counts().plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSFNFj-dcBxx"
      },
      "source": [
        "data.groupby('v1').size().reset_index(name = \"count\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47a9lWj9cSPN"
      },
      "source": [
        "X_data = data.v2.copy()\n",
        "y_data = data.v1.copy()\n",
        "print(f\"메일 본문의 개수 : {len(X_data)}\")\n",
        "print(f\"메일 레이블의 개수 : {len(y_data)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L6lN3ACcjPX"
      },
      "source": [
        "#정수인코딩\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_data)\n",
        "sequences = tokenizer.texts_to_sequences(X_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5evU7FYc5G6"
      },
      "source": [
        "print(sequences[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hhXeDZSc-Ew"
      },
      "source": [
        "word_to_index = tokenizer.word_index\n",
        "print(word_to_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHGejBXVbYux"
      },
      "source": [
        "# 빈도수가 1개인 단어의 비율\n",
        "threshold = 2\n",
        "total_cnt = len(word_to_index) #단어의 수\n",
        "rare_cnt = 0 #threshold보다 작은 빈도수를 가진 단어의 개수 카운트\n",
        "total_freq = 0 #훈련 데이터의 전체 단어 빈도수 합\n",
        "rare_freq = 0 #theshold보다 작은 단어의 등장 빈도수 합\n",
        "\n",
        "for key,value in tokenizer.word_counts.items():\n",
        "  total_freq += value\n",
        "\n",
        "  #단어의 등장 빈도수가 threshold보다 작으면\n",
        "  if value < threshold:\n",
        "    rare_cnt += 1\n",
        "    rare_freq += value\n",
        "\n",
        "print('등장 빈도수가 %s 미만인 희귀 단어의 수 %s',(threshold, rare_cnt))\n",
        "print('단어 집합(vocab)에서 희귀 단어의 비율: ',round((rare_cnt/total_cnt)*100,2))\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 비율: \", round(rare_freq/total_freq*100,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMXTVgv-e42n"
      },
      "source": [
        "만약 등장 빈도가 1회 이하인 단어를 제외하고자 할 경우\n",
        "- tokenizer = Tokenizer(num_words = (total_cnt = rare_cnt + 1), 단 이 과정에선 제외\n",
        "---\n",
        "\n",
        "padding\n",
        "-padding 시 padding을 위한 토큰 0번 단어를 고려하여 단어 집합의 크기 vocab_size는 +1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvmpoSuVg2ps"
      },
      "source": [
        "vocab_size = len(word_to_index) + 1\n",
        "print(\"단어 집합의 크기 : \",vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IjVUc4phoh_"
      },
      "source": [
        "#테스트 및 훈련셋 나누기 8:2\n",
        "n_of_train = int(len(sequences) * 0.8)\n",
        "n_of_test = int(len(sequences) - n_of_train)\n",
        "\n",
        "print(f\"훈련 데이터셋 / 테스트 데이터셋 개수 : {n_of_train} / {n_of_test}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF8wtCMeiPFg"
      },
      "source": [
        "X_data = sequences\n",
        "print('메일의 최대 길이 : %d' % max(len(l) for l in X_data))\n",
        "print('메일의 평균 길이 : %.1f' % (sum(map(len,X_data))/len(X_data)))\n",
        "\n",
        "plt.hist([len(s) for s in X_data], bins = 50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('num of samples')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39nvNSzkjITB"
      },
      "source": [
        "max_len = max(len(l) for l in X_data) # 가장 긴 메일의 길이가 189\n",
        "\n",
        "data = pad_sequences(X_data, maxlen = max_len,padding = 'post')\n",
        "print(\"훈련 데이터의 크기(shape) : \", data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW8jCLdQksDa"
      },
      "source": [
        "X_train = data[:n_of_train]\n",
        "y_train = np.array(y_data[:n_of_train])\n",
        "\n",
        "X_test = data[-n_of_test:]\n",
        "y_test = np.array(y_data[-n_of_test:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvHR756Dl4E7"
      },
      "source": [
        "## RNN으로 스팸 메일 분류"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ4qXxv3l9SO"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NS3efmxrncu"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim = vocab_size, output_dim=32)) #임베딩 벡터 차원 32\n",
        "model.add(SimpleRNN(units = 32)) #메모리셀의 hidden_size = 32, 즉 메모리 셀의 output = 32\n",
        "model.add(Dense(units = 1, activation = 'sigmoid')) #최종 output 1개(이진분류), 활성화함수 : 시그모이드\n",
        "\n",
        "model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['acc'])\n",
        "history = model.fit(x = X_train, y = y_train, epochs = 4, batch_size = 64,validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky3cPLhw1JAn"
      },
      "source": [
        "epochs = range(1,len(history.history['acc'])+1)\n",
        "plt.plot(epochs, history.history['loss'])\n",
        "plt.plot(epochs, history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','val'],loc = 'upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esY8KsRBvnWT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}