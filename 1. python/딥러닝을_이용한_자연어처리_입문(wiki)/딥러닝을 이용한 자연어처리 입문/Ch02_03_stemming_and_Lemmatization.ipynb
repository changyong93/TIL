{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 어간 추출(Stemming) and 표제어 추출(Lemmatization)\n",
    "- 단어의 개수를 줄일 수 있는 기법인 표제어 추출(lemmatization)과 어간 추출(stemming)의 개념 학습\n",
    "- 이러한 방법들은 단어의 빈도수를 기반으로 문제를 풀고자 하는 BoW(Bag of Words) 표현을 사용하는 자연어 처리 문제에서 주로 사용\n",
    "- 자연어 처리에서 전처리, 더 정확히는 정규화의 지향점은 언제나 갖고 있는 코퍼스로부터 복잡성을 줄이는 일\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. 표제어 추출(Lemmatization)\n",
    "- 표제어(Lemma)는 한글로는 '표제어' 또는 '기본 사전형 단어' 정도의 의미\n",
    "- 표제어 추출은 단어들이 다른 형태를 가지더라도, 그 뿌리 단어를 찾아가서 단어의 개수를 줄일 수 있는지 판단\n",
    "- 표제어 추출을 하는 가장 섬세한 방법은 단어의 형태학적 파싱을 먼저 진행하는 것\n",
    "  - 형태학(morpholoy) : 형태소로부터 단어를 만들어가는 학문\n",
    "  - 형태소 종류\n",
    "    - 어간(stem) : 단어의 의미를 담고 있는 단어의 핵심 부분\n",
    "    - 접사(affix) : 단어에 추가적인 의미를 주는 부분\n",
    "    \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# import nltk\n",
    "# nltk.download('wordnet')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wordnetlemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "words=['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
    "words_morphs = [wordnetlemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "for w,m in zip(words,words_morphs):\n",
    "    print(f\"{w:^12} || {m:^12}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   policy    ||    policy   \n",
      "   doing     ||    doing    \n",
      "organization || organization\n",
      "    have     ||     have    \n",
      "   going     ||    going    \n",
      "    love     ||     love    \n",
      "   lives     ||     life    \n",
      "    fly      ||     fly     \n",
      "    dies     ||      dy     \n",
      "  watched    ||   watched   \n",
      "    has      ||      ha     \n",
      "  starting   ||   starting  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "표제어 추출기는 어간 추출과 달리 단어의 형태가 적절히 보존되지만, 그럼에도 일부 단어(dy, ha) 등과 같이 의미없는 단어가 나온다.   \n",
    "사실 표제어 추출기에는 단어 뿐만 아니라 품사도 같이 넣어줘야 한다"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "words=['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
    "pos_idx = [0,1,0,1,1,1,1,1,1,1,1,1]\n",
    "words_morphs = [wordnetlemmatizer.lemmatize(word) for word in words]\n",
    "words_morphs_pos = [wordnetlemmatizer.lemmatize(word) if pos == 0 else wordnetlemmatizer.lemmatize(word, \"v\") for pos, word in zip(pos_idx,words)]\n",
    "\n",
    "for w,m,pm in zip(words,words_morphs,words_morphs_pos):\n",
    "    print(f\"{w:^12} || {m:^12} || {pm:^12}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   policy    ||    policy    ||    policy   \n",
      "   doing     ||    doing     ||      do     \n",
      "organization || organization || organization\n",
      "    have     ||     have     ||     have    \n",
      "   going     ||    going     ||      go     \n",
      "    love     ||     love     ||     love    \n",
      "   lives     ||     life     ||     live    \n",
      "    fly      ||     fly      ||     fly     \n",
      "    dies     ||      dy      ||     die     \n",
      "  watched    ||   watched    ||    watch    \n",
      "    has      ||      ha      ||     have    \n",
      "  starting   ||   starting   ||    start    \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "아래 결과에 명사(default)와 동사를 적절히 넣어준 결과 원하는 형태로 출력됨을 확인할 수 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 어간 추출(Stemming)\n",
    "- 어간(Stem)을 추출하는 작업을 어간 추출(stemming)\n",
    "- 어간 추출은 형태학적 분석을 단순화한 버전이라고 볼 수도 있고, 정해진 규칙만 보고 단어의 어미를 자르는 어림짐작의 작업\n",
    "- 표제어 추출과 어간 추출의 차이\n",
    "  - 표제어 추출 : 문맥을 고려하여 수행하며, 단어의 품사 정보를 보존\n",
    "  - 어간 추출 : 품사 정보를 보존하지 않음"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "p = PorterStemmer()\n",
    "l = LancasterStemmer()\n",
    "\n",
    "text=\"This was not the map we found in Billy Bones's chest, but an accurate copy, complete in all things--names and heights and soundings--with the single exception of the red crosses and the written notes.\"\n",
    "words = word_tokenize(text)\n",
    "\n",
    "\n",
    "print(\"[text]\",\"\\n\", text)\n",
    "# print(\"[word_tokenize]\",\"\\n\", words)\n",
    "# print(\"[PorterStemmer]\",\"\\n\", [p.stem(word) for word in words])\n",
    "# print(\"[LancasterStemmer]\",\"\\n\", [l.stem(word) for word in words])\n",
    "print(\"------------------------------------------------------------------------\")\n",
    "print(\"   word_token  ||    Porter     ||   Lancaster   ||   wordnetlemmatizer\")\n",
    "print(\"------------------------------------------------------------------------\")\n",
    "for word in words:\n",
    "    print(f\"{word:^15}||{p.stem(word):^15}||{l.stem(word):^15}||{wordnetlemmatizer.lemmatize(word):^20}\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[text] \n",
      " This was not the map we found in Billy Bones's chest, but an accurate copy, complete in all things--names and heights and soundings--with the single exception of the red crosses and the written notes.\n",
      "------------------------------------------------------------------------\n",
      "   word_token  ||    Porter     ||   Lancaster   ||   wordnetlemmatizer\n",
      "------------------------------------------------------------------------\n",
      "     This      ||      thi      ||      thi      ||        This        \n",
      "      was      ||      wa       ||      was      ||         wa         \n",
      "      not      ||      not      ||      not      ||        not         \n",
      "      the      ||      the      ||      the      ||        the         \n",
      "      map      ||      map      ||      map      ||        map         \n",
      "      we       ||      we       ||      we       ||         we         \n",
      "     found     ||     found     ||     found     ||       found        \n",
      "      in       ||      in       ||      in       ||         in         \n",
      "     Billy     ||     billi     ||      bil      ||       Billy        \n",
      "     Bones     ||     bone      ||      bon      ||       Bones        \n",
      "      's       ||      's       ||      's       ||         's         \n",
      "     chest     ||     chest     ||     chest     ||       chest        \n",
      "       ,       ||       ,       ||       ,       ||         ,          \n",
      "      but      ||      but      ||      but      ||        but         \n",
      "      an       ||      an       ||      an       ||         an         \n",
      "   accurate    ||     accur     ||      acc      ||      accurate      \n",
      "     copy      ||     copi      ||      cop      ||        copy        \n",
      "       ,       ||       ,       ||       ,       ||         ,          \n",
      "   complete    ||    complet    ||    complet    ||      complete      \n",
      "      in       ||      in       ||      in       ||         in         \n",
      "      all      ||      all      ||      al       ||        all         \n",
      "    things     ||     thing     ||     thing     ||       thing        \n",
      "      --       ||      --       ||      --       ||         --         \n",
      "     names     ||     name      ||      nam      ||        name        \n",
      "      and      ||      and      ||      and      ||        and         \n",
      "    heights    ||    height     ||    height     ||       height       \n",
      "      and      ||      and      ||      and      ||        and         \n",
      "   soundings   ||     sound     ||     sound     ||      sounding      \n",
      "      --       ||      --       ||      --       ||         --         \n",
      "     with      ||     with      ||     with      ||        with        \n",
      "      the      ||      the      ||      the      ||        the         \n",
      "    single     ||     singl     ||     singl     ||       single       \n",
      "   exception   ||    except     ||    exceiv     ||     exception      \n",
      "      of       ||      of       ||      of       ||         of         \n",
      "      the      ||      the      ||      the      ||        the         \n",
      "      red      ||      red      ||      red      ||        red         \n",
      "    crosses    ||     cross     ||     cross     ||       cross        \n",
      "      and      ||      and      ||      and      ||        and         \n",
      "      the      ||      the      ||      the      ||        the         \n",
      "    written    ||    written    ||     writ      ||      written       \n",
      "     notes     ||     note      ||      not      ||        note        \n",
      "       .       ||       .       ||       .       ||         .          \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "이처럼 결과는 stemmer마다 상이하며, 결과적으로 테스트 후 적절한 stmmer를 사용하는 것이 옳다.\n",
    "맨 우측은 wordnetlemmatizer이며, 역시나 품사 정보가 따로 없어서 결과가 잘 안나온 것으 볼 수 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. 한국어에서의 어간 추출\n",
    "- 용언에 해당되는 '동사'와 '형용사'는 어간(stem)과 어미(ending)의 결합으로 구성\n",
    "- 활용(conjugation): 이란 용언의 어간(stem)이 어미(ending)를 가지는 일\n",
    "  - 어간(stem) : 용언(동사, 형용사)을 활용할 때, 원칙적으로 모양이 변하지 않는 부분. 활용에서 어미에 선행하는 부분. 때론 어간의 모양도 바뀔 수 있음(예: 긋다, 긋고, 그어서, 그어라).\n",
    "  - 어미(ending): 용언의 어간 뒤에 붙어서 활용하면서 변하는 부분이며, 여러 문법적 기능을 수행\n",
    "- 활용은 어간이 어미를 취할 때, (1)어간의 모습이 일정하다면 규칙 활용, (2)어간이나 어미의 모습이 변하는 불규칙 활용\n",
    "  - (1) : 어미:잡 + 어간:다,은,아,고 등\n",
    "  - (2) : 어미:듣 => 듣+다, 듣+는, 들+어 등...\n",
    "    - 어미가 붙는 과정에서 어간의 모습이 바뀌었으므로 단순한 분리만으로 어간 추출이 되지 않고 좀 더 복잡한 규칙을 필요\n",
    "    - https://namu.wiki/w/%ED%95%9C%EA%B5%AD%EC%96%B4/%EB%B6%88%EA%B7%9C%EC%B9%99%20%ED%99%9C%EC%9A%A9"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}