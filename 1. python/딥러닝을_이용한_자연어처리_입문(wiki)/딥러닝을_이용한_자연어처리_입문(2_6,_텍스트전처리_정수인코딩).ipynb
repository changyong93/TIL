{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "딥러닝을_이용한_자연어처리_입문(2-6, 텍스트전처리-정수인코딩)",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOdCZp/EuipECVdE0tSdTpk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/changyong93/Natural-language-processing-with-chat-bot/blob/main/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84_%EC%9D%B4%EC%9A%A9%ED%95%9C_%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC_%EC%9E%85%EB%AC%B8(2_6%2C_%ED%85%8D%EC%8A%A4%ED%8A%B8%EC%A0%84%EC%B2%98%EB%A6%AC_%EC%A0%95%EC%88%98%EC%9D%B8%EC%BD%94%EB%94%A9).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAsie5mvG7sE"
      },
      "source": [
        "# 정수 인코딩(Integer Encoding)\n",
        "- https://wikidocs.net/31766\n",
        "---\n",
        "- 컴퓨터는 텍스트보다는 숫자를 더 잘처리, 이를 위한 자연어 처리에서는 텍스트를 숫자로 바꾸는 여러가지 기법 존재\n",
        "- 여러 기법들을 적용하기 위한  첫 단계로, 각 단어를 고유한 정수로 맵핑(mapping)시키는 전처리 필요\n",
        "- 예로, 텍스트에 단어가 5000개가 있다면, 단어들 각각에 1번부터 5000번까지 단어와 맵핑되는 고유한 정수(인덱스) 부여\n",
        "- 인덱스 부여 방법은 여러가지가 있는데, 랜덤으로 부여하기도 하지만, 전처리 또는 빈도수가 높은 단어들만 사용하기 위해서 단어에 대한 빈도수를 기준으로 정렬한 뒤 부여"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXR_eLLmO-df"
      },
      "source": [
        "## 정수 인코딩\n",
        "---\n",
        "- 단어에 정수를 부여하는 방법 중 하나로 단어를 빈도수 순으로 정렬한 단어 집합(vocabulary)을 만들고, 빈도수가 높은 순서대로 정수를 부여"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2SOfK2eWJsg"
      },
      "source": [
        "### dictionary 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTNq2ug-PPn0",
        "outputId": "b043913e-2483-4430-d42a-650506cbdf68"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt') #토큰화 기능을 사용하기 위해 punkt analaysis model 설치\n",
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFW3bHzKPXTC"
      },
      "source": [
        "text = \"A barber is a person. a barber is good person. a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain.\""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khMz6SSYPuJk",
        "outputId": "1a4666fa-3749-41a9-b9dd-20c4c1c0d2e1"
      },
      "source": [
        "# 문장 토큰화\n",
        "text = sent_tokenize(text)\n",
        "print(text)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A barber is a person.', 'a barber is good person.', 'a barber is huge person.', 'he Knew A Secret!', 'The Secret He Kept is huge secret.', 'Huge secret.', 'His barber kept his word.', 'a barber kept his word.', 'His barber kept his secret.', 'But keeping and keeping such a huge secret to himself was driving the barber crazy.', 'the barber went up a huge mountain.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuLxj23SPzOY",
        "outputId": "9448406f-dd88-4d0e-80cb-872b976ebd4e"
      },
      "source": [
        "# 정제와 단어 토큰화\n",
        "vocab = {} # 파이썬 dictionary 자료형형\n",
        "sentences = []\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "for i in text:\n",
        "  sentence = word_tokenize(i) #문장별 단어 토큰화 수행\n",
        "  result = []\n",
        "\n",
        "  for word in sentence:\n",
        "    word = word.lower() # 모든 단어를 소문자화하여 단어의 개수 줄임\n",
        "    if word not in stop_words :#단어 토큰화된 결과에 대해서 불용어 제거\n",
        "      \n",
        "      if len(word) > 2: #단어 길이가 2이하인 경우에 대해 추가로 단어 제거\n",
        "\n",
        "        result.append(word)\n",
        "        if word not in vocab:\n",
        "          vocab[word] = 0\n",
        "        vocab[word] +=1\n",
        "  sentences.append(result)\n",
        "print(sentences)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chOb4YnaRV82"
      },
      "source": [
        "- 텍스트를 숫자로 바꾸는 단계는 본격적으로 자연어 처리 작업을 시작한다는 의미\n",
        "- 동일한 단어가 대문자료 표기되었다는 이유로 서로 다른 단어로 카운트 되는 일이 없도록 소문자화\n",
        "- 자연어 처리에서 크게 의미를 갖지 못하는 불용어 및 길이가 짧은 단어 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS01DUhFRrpX",
        "outputId": "7cb9378e-e272-4e47-a4aa-7a77e36325c4"
      },
      "source": [
        "print(vocab)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'barber': 8, 'person': 3, 'good': 1, 'huge': 5, 'knew': 1, 'secret': 6, 'kept': 4, 'word': 2, 'keeping': 2, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bUN-7DxRsjA"
      },
      "source": [
        "- 단어를 키(key)로, 빈도수를 값(value)로 저장\n",
        "- vocab 단어를 입력하면 빈도수 리턴"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyb4rkxpR3mb",
        "outputId": "5fc9b0fb-cad4-405e-b8d0-780b0d317620"
      },
      "source": [
        "print(vocab[\"barber\"]) #'barber'라는 단어의 빈도수 출력"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKokxRbsR61w",
        "outputId": "16de20da-b173-4c18-862f-c33c30968fdd"
      },
      "source": [
        "#빈도수가 높은 순서대로 정렬\n",
        "vocab_sorted = sorted(vocab.items(), key = lambda x : x[1],reverse = True)\n",
        "vocab_sorted"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('barber', 8),\n",
              " ('secret', 6),\n",
              " ('huge', 5),\n",
              " ('kept', 4),\n",
              " ('person', 3),\n",
              " ('word', 2),\n",
              " ('keeping', 2),\n",
              " ('good', 1),\n",
              " ('knew', 1),\n",
              " ('driving', 1),\n",
              " ('crazy', 1),\n",
              " ('went', 1),\n",
              " ('mountain', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIKbhFupSRyC",
        "outputId": "8606dad0-1a41-4d00-950e-e8b510e33eca"
      },
      "source": [
        "#높은 빈도수를 가진 단어일수록 낮은 정수 인덱스 부여\n",
        "word_to_index = {}\n",
        "i = 0\n",
        "for (word, frequency) in vocab_sorted:\n",
        "  if frequency > 1:# 빈도수가 적은(1개) 단어 제외\n",
        "    i +=1\n",
        "    word_to_index[word] = i\n",
        "word_to_index"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'barber': 1,\n",
              " 'huge': 3,\n",
              " 'keeping': 7,\n",
              " 'kept': 4,\n",
              " 'person': 5,\n",
              " 'secret': 2,\n",
              " 'word': 6}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_tD2MgMSxEW",
        "outputId": "38d03b60-8f28-4d55-a5e7-be980ec5bad6"
      },
      "source": [
        "vocab_size = 5\n",
        "words_frequency = [ w for w,c in word_to_index.items() if c >vocab_size] #인덱스가 5 초과인 단어 제거\n",
        "\n",
        "for w in words_frequency:\n",
        "  del word_to_index[w] #해당 단어에 대한 인덱스 정보 삭제\n",
        "word_to_index\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'barber': 1, 'huge': 3, 'kept': 4, 'person': 5, 'secret': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJkYGNPIUEIG"
      },
      "source": [
        "- word_to_index에는 빈도수가 상위 5개인 단어만 저장\n",
        "- 이제 단어 토큰화된 상태로 저장된 sentences에 있는 각 단어를 정수로 변환\n",
        "- 단 word_to_index에 존재하지 않는 단어와 같이, 집합에 존재하지 않는 단어들을 Out-Of_Vocabulary(단어 집합에 없는 단어)의 약자로 'OOV'라고 함.\n",
        "- word_to_index에 'OOV'란 단어를 새롭게 추가하고, 집합에 없는 단어를 'OOV'의 인덱스로 인코딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnJc-bvlVVoZ"
      },
      "source": [
        "word_to_index['OOV'] = len(word_to_index)+1"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qKfC7HxVehn",
        "outputId": "d27a64ac-5eea-44bc-ca31-c13319073f1d"
      },
      "source": [
        "encoded = []\n",
        "for s in sentences:\n",
        "  temp = []\n",
        "\n",
        "  for w in s:\n",
        "    try:\n",
        "      temp.append(word_to_index[w])\n",
        "    except KeyError:\n",
        "      temp.append(word_to_index['OOV'])\n",
        "  encoded.append(temp)\n",
        "print(sentences)\n",
        "print(encoded)\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n",
            "[[1, 5], [1, 6, 5], [1, 3, 5], [6, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [6, 6, 3, 2, 6, 1, 6], [1, 6, 3, 6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DY1x7ClGV5OG"
      },
      "source": [
        "- 파이썬 dict 자료형으로 정수 인코딩 완료\n",
        "- 단, 이보다 더 쉽게 하기 위해 Counter, FreqDist, enumerate 또는 keras tokenizser를 사용하기를 권장"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0F8EE9WWEyB"
      },
      "source": [
        "### Counter 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpKsse8rWRAL"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCMvaWHOWSi7",
        "outputId": "60cc1500-b321-4029-8d21-cc50c553d868"
      },
      "source": [
        "print(sentences)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrjRv9iWWTuY"
      },
      "source": [
        "현재 sentences는 단어 토큰화된 결과가 저장되어 있으며, vocab을 만들기 위해 문장의 경계인 [,]를 제거하고 단어들을 하나의 리스트로 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENDU__aYWgDE",
        "outputId": "597ddc00-60a2-43df-bc78-9b56905c9646"
      },
      "source": [
        "words = sum(sentences, [])\n",
        "\n",
        "# numpy hstack 활용\n",
        "# import numpy as np\n",
        "# np.hstack(sentences)\n",
        "\n",
        "#for문 활용\n",
        "# [word for sentence in sentences for word in sentence]\n",
        "\n",
        "print(words)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['barber', 'person', 'barber', 'good', 'person', 'barber', 'huge', 'person', 'knew', 'secret', 'secret', 'kept', 'huge', 'secret', 'huge', 'secret', 'barber', 'kept', 'word', 'barber', 'kept', 'word', 'barber', 'kept', 'secret', 'keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy', 'barber', 'went', 'huge', 'mountain']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnLL5ualXRPU"
      },
      "source": [
        "파이썬의 Counter()를 사용하면 중복을 제거하고 단어의 빈도수를 기록"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqciRUOxXYmA",
        "outputId": "05fe3ec8-64bf-4a47-d0e6-e64772a1aaa5"
      },
      "source": [
        "vocab = Counter(words) #dict type형태로 단어별 빈도수 생성\n",
        "print(vocab)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'barber': 8, 'secret': 6, 'huge': 5, 'kept': 4, 'person': 3, 'word': 2, 'keeping': 2, 'good': 1, 'knew': 1, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sekomGXVXfDk"
      },
      "source": [
        "most_common()으로 상위 빈도수를 가진 단어만 리턴\n",
        "- 등장 빈도수 상위 5개 단어"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvMvGTBzXsd6",
        "outputId": "29e7f565-be4c-45d0-b2d8-4aa276467717"
      },
      "source": [
        "vocab_size = 5\n",
        "vocab = vocab.most_common(vocab_size) #등장 빈도수 상위 5개의 단어만 저장\n",
        "vocab"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CaLszEfX30k"
      },
      "source": [
        "높은 빈도수를 가진 단어일수록 낮은 정수 인덱스 부여"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmnbrFHCX7Xu",
        "outputId": "353d51c2-1afd-43f3-d522-9d65d4494e11"
      },
      "source": [
        "word_to_index = {}\n",
        "i = 0\n",
        "for (word, frequency) in vocab:\n",
        "  i +=1\n",
        "  word_to_index[word] = i\n",
        "print(word_to_index)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqQruAwdYGm1"
      },
      "source": [
        "### NLTK의 FreqDist 사용\n",
        "- 위에서 사용한 Counter와 같은 방법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcDjJ5vKYOK8"
      },
      "source": [
        "from nltk import FreqDist\n",
        "import numpy as np"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eUwjt2NYRQS",
        "outputId": "6abbcbef-68cd-4a1a-c93f-f40b7a92489f"
      },
      "source": [
        "vocab = FreqDist(np.hstack(sentences))\n",
        "print(vocab)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<FreqDist with 13 samples and 36 outcomes>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBnWxV6KYfqj",
        "outputId": "e1ea08d5-bd70-461e-ab16-c00ebac2af9e"
      },
      "source": [
        "vocab_size = 5\n",
        "vocab = vocab.most_common(vocab_size)\n",
        "vocab"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJfdFc8AYlbq"
      },
      "source": [
        "인덱스 부여 과정은 앞과 같지만, 이번엔 enumerate로 부여"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Jo5tmgjYtDH",
        "outputId": "ebcf105e-5964-44d0-f6c4-3a003949248f"
      },
      "source": [
        "word_to_index = {word[0] : index + 1 for index, word in enumerate(vocab)}\n",
        "print(word_to_index)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kc9ox-ydZBms"
      },
      "source": [
        "### enumerate 이햏기\n",
        "- enumerate는 순서가 있는 자료형(list, set,tuple, dictionary, string)을 입력으로 받아 인덱스를 순차적으로 함께 리턴하는 특징이 있음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AjA47MXZQPD",
        "outputId": "158a5f84-3808-4c41-a1aa-b9fbbab4cb4e"
      },
      "source": [
        "test = ['a','b','c','d','e']\n",
        "[[index, value] for index, value in enumerate(test)]\n",
        "  "
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 'a'], [1, 'b'], [2, 'c'], [3, 'd'], [4, 'e']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBeWa6bLaA-7"
      },
      "source": [
        "## 케라스(Keras)의 텍스트 전처리\n",
        "---\n",
        "- 케라스(Keras)는 기본적인 전처리를 위한 도구 제공"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJGBvGQRaTpt"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBbQWWu4aLKN",
        "outputId": "eeee1dce-1670-4e70-8b10-7de0bd321e65"
      },
      "source": [
        "#단어 토큰화까지 수행된 텍스트 데이터 사용\n",
        "print(sentences)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6hXugeoaSki"
      },
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pgVi3i4apf6"
      },
      "source": [
        "tokenizer.fit_on_texts(sentences)\n",
        "#fit_on_texts() 안에 코퍼스를 입력하면 빈도수를 기준으로 단어 집합 생성"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUs-N-GEa7II",
        "outputId": "d09da361-f775-4b89-c358-a1ab82569f6b"
      },
      "source": [
        "print(tokenizer.word_index)\n",
        "print(tokenizer.word_counts)\n",
        "print(tokenizer.texts_to_sequences(sentences))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7, 'good': 8, 'knew': 9, 'driving': 10, 'crazy': 11, 'went': 12, 'mountain': 13}\n",
            "OrderedDict([('barber', 16), ('person', 6), ('good', 2), ('huge', 10), ('knew', 2), ('secret', 12), ('kept', 8), ('word', 4), ('keeping', 4), ('driving', 2), ('crazy', 2), ('went', 2), ('mountain', 2)])\n",
            "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaomDn5ibEb9"
      },
      "source": [
        "- word_index : 각 단어의 빈도수가 높은 순서대로 인덱스가 부여된 것을 확인\n",
        "- word_counts : 단어별 빈도수 확인\n",
        "- texts_to_sequences() : 입력으로 들어온 코퍼스에 대해서 각 단어를 이미 정해진 인덱스로 변환\n",
        "---\n",
        "- 앞서 빈도수가 가장 높은 nro의 단어만 사용하기 위해 most_common()을 사용\n",
        "- Keras Tokenizer도 개수를 지정할 수 있음\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAmjQShGbpTX"
      },
      "source": [
        "vocab_size = 5\n",
        "tokenizer = Tokenizer(num_words = vocab_size+1)\n",
        "tokenizer.fit_on_texts(sentences)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhWb19juc9Q1"
      },
      "source": [
        "vocab_size+1 : num_words는 숫자를 0부터 카운트하기에, 5를 넣으면 index번호 0~4를 불러오므로 상위 4개만 선택됨, 상위 5개를 사용하고자 한다면 +1 or 6으로 지정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOhafor-dObv",
        "outputId": "56f6bffb-2735-4d98-c1c0-98532e1cddef"
      },
      "source": [
        "print(tokenizer.word_index)\n",
        "print(tokenizer.texts_to_sequences(sentences))"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7, 'good': 8, 'knew': 9, 'driving': 10, 'crazy': 11, 'went': 12, 'mountain': 13}\n",
            "[[1, 5], [1, 5], [1, 3, 5], [2], [2, 4, 3, 2], [3, 2], [1, 4], [1, 4], [1, 4, 2], [3, 2, 1], [1, 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcY1JPnYdXmY"
      },
      "source": [
        "- 기존과 마찬가지로 13개의 단어가 모두 출력되지만, 실제로는 지정한 상위 단어만 인덱스로 변환\n",
        "- 강사님 경험상 굳이 필요하지 않지만, 만약 word_index와 word_counts에서도 지정된 num_words 만큼만 남기고 싶다면 아래와 같이 진행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqMLzEWwdloN",
        "outputId": "f46a68e7-7d73-4d9f-a247-794880a1f14b"
      },
      "source": [
        "vocab_size = 5\n",
        "words_frequency = [w for w,c in tokenizer.word_index.items() if c > vocab_size]\n",
        "for w in words_frequency:\n",
        "  del tokenizer.word_index[w] #해당 단어에 대한 인덱스 정보 삭제\n",
        "  del tokenizer.word_counts[w] #해당 단어에 대한 빈도수 정보 삭제\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(tokenizer.word_counts)\n",
        "print(tokenizer.texts_to_sequences(sentences))"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n",
            "OrderedDict([('barber', 8), ('person', 3), ('huge', 5), ('secret', 6), ('kept', 4)])\n",
            "[[1, 5], [1, 5], [1, 3, 5], [2], [2, 4, 3, 2], [3, 2], [1, 4], [1, 4], [1, 4, 2], [3, 2, 1], [1, 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftDbyhs6eMkO"
      },
      "source": [
        "- 케라스 토크나이저는 기본적으로 단어 집합이 없는 단어인 OOV에 대해 단어를 정수로 바꾸는 과정에서 단어를 아예 삭제\n",
        "- 단어 집합이 없는 단어들을 OOV로 간주하고자 할 경우 oov_token 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4AElZqtetIe"
      },
      "source": [
        "vocab_size = 5\n",
        "tokenizer = Tokenizer(num_words = vocab_size+1, oov_token = \"OOV\")\n",
        "tokenizer.fit_on_texts(sentences)"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARNTW5vEe1ns"
      },
      "source": [
        "oov_token을 사용할 경우, OOV의 인덱스는 기본적으로 1로 지정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXnLX_1ffFFZ",
        "outputId": "3ef3d35b-1fd0-47df-c07b-e0525977f822"
      },
      "source": [
        "print(tokenizer.word_index)\n",
        "print(tokenizer.word_counts)\n",
        "print(tokenizer.texts_to_sequences(sentences))"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'OOV': 1, 'barber': 2, 'secret': 3, 'huge': 4, 'kept': 5, 'person': 6, 'word': 7, 'keeping': 8, 'good': 9, 'knew': 10, 'driving': 11, 'crazy': 12, 'went': 13, 'mountain': 14}\n",
            "OrderedDict([('barber', 8), ('person', 3), ('good', 1), ('huge', 5), ('knew', 1), ('secret', 6), ('kept', 4), ('word', 2), ('keeping', 2), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)])\n",
            "[[2, 1], [2, 1, 1], [2, 4, 1], [1, 3], [3, 5, 4, 3], [4, 3], [2, 5, 1], [2, 5, 1], [2, 5, 3], [1, 1, 4, 3, 1, 2, 1], [2, 1, 4, 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFzXIh3zfTeN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}