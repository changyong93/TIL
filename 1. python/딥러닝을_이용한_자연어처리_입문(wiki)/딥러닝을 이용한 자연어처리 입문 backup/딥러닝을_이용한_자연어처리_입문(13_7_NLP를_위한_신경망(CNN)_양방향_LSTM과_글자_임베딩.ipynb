{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "딥러닝을_이용한_자연어처리_입문(13_7_NLP를 위한 신경망(CNN)_양방향 LSTM과 글자 임베딩",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPRM1ILYIzUjfkKruyV6mTF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/changyong93/Natural-language-processing-with-chat-bot/blob/main/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84_%EC%9D%B4%EC%9A%A9%ED%95%9C_%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC_%EC%9E%85%EB%AC%B8(13_7_NLP%EB%A5%BC_%EC%9C%84%ED%95%9C_%EC%8B%A0%EA%B2%BD%EB%A7%9D(CNN)_%EC%96%91%EB%B0%A9%ED%96%A5_LSTM%EA%B3%BC_%EA%B8%80%EC%9E%90_%EC%9E%84%EB%B2%A0%EB%94%A9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1y8GztzOhsM4"
      },
      "source": [
        "# 양방향 LSTM과 글자 임베딩(Char embedding)\n",
        "---\n",
        "- 기초 전처리는 13-5와 동일"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At941YPYhx4q"
      },
      "source": [
        "## 실습 전 참고사항\n",
        "---\n",
        "- CRF layer는 현재 텐서플로우 1.14.0버전과 케라스 2.2.4에서 가장 원활하게 동작\n",
        "- 버전 맞추기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DTgqSw0iAvA",
        "outputId": "62671d34-3158-4f12-a611-d47970cfb33d"
      },
      "source": [
        "!pip install tensorflow==1.14.0\n",
        "!pip install keras==2.2.4\n",
        "!pip install tensorflow-gpu==1.14.0\n",
        "\n",
        "#CRF 사용을 위한 keras_contrib 설치\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/28/96efba1a516cdacc2e2d6d081f699c001d414cc8ca3250e6d59ae657eb2b/tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3MB 87kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.32.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.19.5)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.12.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.36.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 50.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.12.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 42.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (54.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.3.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.7.4.3)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n",
            "Collecting keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 12.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.19.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.2.4\n",
            "Collecting tensorflow-gpu==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/67/559ca8408431c37ad3a17e859c8c291ea82f092354074baef482b98ffb7b/tensorflow_gpu-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (377.1MB)\n",
            "\u001b[K     |████████████████████████████████| 377.1MB 39kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (3.12.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.36.2)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.19.5)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.32.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14.0) (54.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.4.1)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.14.0\n",
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-koabglxc\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-koabglxc\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-contrib==2.0.8) (2.2.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.19.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp37-none-any.whl size=101065 sha256=cadb2b68ff60e3d15f3ed499385cb922fecbceabe81a1a3c65834030743ba29e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pn082rdd/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey_NN2aTiSdZ"
      },
      "source": [
        "## 개체명 인식 데이터에 대한 이해와 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uoV4bdjjkpi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f2d2e9c-6a49-49a3-f04c-f8ef9e96b026"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qj14-ppNj7jN",
        "outputId": "9e8df8e6-0524-4c54-8420-1d617b5b1549"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "FwOYtGyXmMVC",
        "outputId": "bead1cc1-7bb3-4571-d5e8-1a006ffad2b2"
      },
      "source": [
        "data = pd.read_csv(\"./gdrive/MyDrive/Colab Notebooks/ner_dataset.csv\", encoding = 'latin1')\n",
        "data[:5]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      Thousands  NNS   O\n",
              "1          NaN             of   IN   O\n",
              "2          NaN  demonstrators  NNS   O\n",
              "3          NaN           have  VBP   O\n",
              "4          NaN        marched  VBN   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZc5cK7PmoxI",
        "outputId": "96f2ad87-ca2c-4ec4-da23-245fb9573afb"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1048575, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uU_KIVfdmxeU",
        "outputId": "9d247ca2-8506-4d78-addd-77391b4cd679"
      },
      "source": [
        "print('데이터에 Null 값이 있는지 유무 : ' + str(data.isnull().values.any()))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "데이터에 Null 값이 있는지 유무 : True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeKmY-smm4fl",
        "outputId": "70696595-3d23-4c71-dd80-87b09ecc58be"
      },
      "source": [
        "print('어떤 열에 Null값이 있는지 출력')\n",
        "print('==============================')\n",
        "data.isnull().sum()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "어떤 열에 Null값이 있는지 출력\n",
            "==============================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence #    1000616\n",
              "Word                0\n",
              "POS                 0\n",
              "Tag                 0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9WDv_zbm8qJ",
        "outputId": "606397cf-43de-43bc-8a81-72eaedaeffc0"
      },
      "source": [
        "len(data), data[\"Sentence #\"].nunique(), data.Word.nunique(), data.Tag.nunique()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1048575, 47959, 35178, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "vcs25DH8nYrc",
        "outputId": "91308c3b-cbe1-4519-ac07-f2e772700af1"
      },
      "source": [
        "#테그 카운트\n",
        "data.groupby(\"Tag\").size().reset_index(name = \"count\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tag</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B-art</td>\n",
              "      <td>402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B-eve</td>\n",
              "      <td>308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B-geo</td>\n",
              "      <td>37644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B-gpe</td>\n",
              "      <td>15870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B-nat</td>\n",
              "      <td>201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>B-org</td>\n",
              "      <td>20143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>B-per</td>\n",
              "      <td>16990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>B-tim</td>\n",
              "      <td>20333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I-art</td>\n",
              "      <td>297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>I-eve</td>\n",
              "      <td>253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>I-geo</td>\n",
              "      <td>7414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>I-gpe</td>\n",
              "      <td>198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>I-nat</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>I-org</td>\n",
              "      <td>16784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>I-per</td>\n",
              "      <td>17251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>I-tim</td>\n",
              "      <td>6528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>O</td>\n",
              "      <td>887908</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Tag   count\n",
              "0   B-art     402\n",
              "1   B-eve     308\n",
              "2   B-geo   37644\n",
              "3   B-gpe   15870\n",
              "4   B-nat     201\n",
              "5   B-org   20143\n",
              "6   B-per   16990\n",
              "7   B-tim   20333\n",
              "8   I-art     297\n",
              "9   I-eve     253\n",
              "10  I-geo    7414\n",
              "11  I-gpe     198\n",
              "12  I-nat      51\n",
              "13  I-org   16784\n",
              "14  I-per   17251\n",
              "15  I-tim    6528\n",
              "16      O  887908"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "OQmZLdn4njuK",
        "outputId": "c5150f07-388f-4de2-c270-9e1cedc4fa1d"
      },
      "source": [
        "data = data.fillna(method = 'ffill')\n",
        "data[:20]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>through</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>London</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>to</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>protest</td>\n",
              "      <td>VB</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>war</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>in</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>and</td>\n",
              "      <td>CC</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demand</td>\n",
              "      <td>VB</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>withdrawal</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>British</td>\n",
              "      <td>JJ</td>\n",
              "      <td>B-gpe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>troops</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Sentence #           Word  POS    Tag\n",
              "0   Sentence: 1      Thousands  NNS      O\n",
              "1   Sentence: 1             of   IN      O\n",
              "2   Sentence: 1  demonstrators  NNS      O\n",
              "3   Sentence: 1           have  VBP      O\n",
              "4   Sentence: 1        marched  VBN      O\n",
              "5   Sentence: 1        through   IN      O\n",
              "6   Sentence: 1         London  NNP  B-geo\n",
              "7   Sentence: 1             to   TO      O\n",
              "8   Sentence: 1        protest   VB      O\n",
              "9   Sentence: 1            the   DT      O\n",
              "10  Sentence: 1            war   NN      O\n",
              "11  Sentence: 1             in   IN      O\n",
              "12  Sentence: 1           Iraq  NNP  B-geo\n",
              "13  Sentence: 1            and   CC      O\n",
              "14  Sentence: 1         demand   VB      O\n",
              "15  Sentence: 1            the   DT      O\n",
              "16  Sentence: 1     withdrawal   NN      O\n",
              "17  Sentence: 1             of   IN      O\n",
              "18  Sentence: 1        British   JJ  B-gpe\n",
              "19  Sentence: 1         troops  NNS      O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8IC0fu8nsQ3",
        "outputId": "d9d7ce6b-d444-4c21-9084-8db3f5449311"
      },
      "source": [
        "data.isnull().any()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence #    False\n",
              "Word          False\n",
              "POS           False\n",
              "Tag           False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPJ9dDRSnyjz",
        "outputId": "bd0455d9-d845-4116-e1ca-11dcc217ef79"
      },
      "source": [
        "data[\"Word\"] = data.Word.str.lower()\n",
        "print(\"전체 문자 소문자로 변환 후 단어 개수: \", data.Word.nunique())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 문자 소문자로 변환 후 단어 개수:  31817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "kLr30RNFoKe-",
        "outputId": "9cc11a31-f76d-4479-fc4d-685d95d0d641"
      },
      "source": [
        "data[:5]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      thousands  NNS   O\n",
              "1  Sentence: 1             of   IN   O\n",
              "2  Sentence: 1  demonstrators  NNS   O\n",
              "3  Sentence: 1           have  VBP   O\n",
              "4  Sentence: 1        marched  VBN   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MZ-XS27ob1I",
        "outputId": "0dbc0b5b-ce55-4374-c731-b57db38550b4"
      },
      "source": [
        "#단어와 개체명 묶기\n",
        "func = lambda temp: [(w,t) for w,t in zip(temp[\"Word\"].values.tolist(), temp[\"Tag\"].values.tolist())]\n",
        "tagged_sentences = [t for t in data.groupby(\"Sentence #\").apply(func)]\n",
        "print(\"전체 샘플 수: \", len(tagged_sentences))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 샘플 수:  47959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmFU-8zCpgtS",
        "outputId": "18f7c53b-b7f3-4d39-a73e-6651af594a4d"
      },
      "source": [
        "print(tagged_sentences[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O'), ('marched', 'O'), ('through', 'O'), ('london', 'B-geo'), ('to', 'O'), ('protest', 'O'), ('the', 'O'), ('war', 'O'), ('in', 'O'), ('iraq', 'B-geo'), ('and', 'O'), ('demand', 'O'), ('the', 'O'), ('withdrawal', 'O'), ('of', 'O'), ('british', 'B-gpe'), ('troops', 'O'), ('from', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jg4F4XKpmEp"
      },
      "source": [
        "sentences, ner_tags = [],[]\n",
        "\n",
        "for tagged_sentence in tagged_sentences:\n",
        "  sentence, tag_info = zip(*tagged_sentence)\n",
        "  sentences.append(list(sentence))\n",
        "  ner_tags.append(list(tag_info))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgRP7eu0upbP",
        "outputId": "34a6aed3-3772-417a-e66f-b0aae608cf53"
      },
      "source": [
        "print(sentences[0])\n",
        "print(ner_tags[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "wKkyTKFQusc-",
        "outputId": "6f13fbc0-c240-4c86-d8a5-5b4e5f037e86"
      },
      "source": [
        "print('샘플의 최대 길이 : %d' % max(len(l) for l in sentences))\n",
        "print('샘플의 평균 길이 : %f' % (sum(map(len, sentences))/len(sentences)))\n",
        "plt.hist([len(s) for s in sentences], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "샘플의 최대 길이 : 104\n",
            "샘플의 평균 길이 : 21.863988\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'number of samples')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxHFuK-hvCpw"
      },
      "source": [
        "src_tokenizer = Tokenizer(oov_token= \"OOV\")\n",
        "src_tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "tar_tokenizer = Tokenizer(lower = False) #태깅 정보의 대문자 유지\n",
        "tar_tokenizer.fit_on_texts(ner_tags)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7shpT54wvoQ6",
        "outputId": "e0360120-1bd7-4e72-8981-6573c7ed30fb"
      },
      "source": [
        "vocab_size = len(src_tokenizer.word_index) + 1\n",
        "tag_size = len(tar_tokenizer.word_index) + 1\n",
        "print('단어 집합의 크기 : {}'.format(vocab_size))\n",
        "print('개체명 태깅 정보 집합의 크기 : {}'.format(tag_size))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 31819\n",
            "개체명 태깅 정보 집합의 크기 : 18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bmq8R1SEvqwM",
        "outputId": "2955e99a-3e64-4826-87ff-821518f69732"
      },
      "source": [
        "src_tokenizer.word_index[\"OOV\"]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TABDOyZv-4Y",
        "outputId": "a2c5cfed-3188-419f-9a9b-2a84bc0ee2d0"
      },
      "source": [
        "X_data = src_tokenizer.texts_to_sequences(sentences)\n",
        "y_data = tar_tokenizer.texts_to_sequences(ner_tags)\n",
        "print(X_data[0])\n",
        "print(y_data[0])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[254, 6, 967, 16, 1795, 238, 468, 7, 523, 2, 129, 5, 61, 9, 571, 2, 833, 6, 186, 90, 22, 15, 56, 3]\n",
            "[1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giIDn5rRv_Q1"
      },
      "source": [
        "word_to_index = src_tokenizer.word_index\n",
        "index_to_word = src_tokenizer.index_word\n",
        "\n",
        "ner_to_index = tar_tokenizer.word_index\n",
        "index_to_ner = tar_tokenizer.index_word\n",
        "index_to_ner[0] = \"PAD\""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3QdiQhP0a3Y",
        "outputId": "32753ddf-5bef-4b46-b72e-0d418ce60b61"
      },
      "source": [
        "decoded = []\n",
        "for index in X_data[0] : # 첫번째 샘플 안의 인덱스들에 대해서\n",
        "    decoded.append(index_to_word[index]) # 다시 단어로 변환\n",
        "\n",
        "print('기존의 문장 : {}'.format(sentences[0]))\n",
        "print('디코딩 문장 : {}'.format(decoded))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "기존의 문장 : ['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n",
            "디코딩 문장 : ['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4pc_e3O0iiD"
      },
      "source": [
        "max_len = 70\n",
        "# 모든 샘플들의 길이를 맞출 때 뒤의 공간에 숫자 0으로 채움.\n",
        "X_data = pad_sequences(X_data, padding='post', maxlen=max_len)\n",
        "y_data = pad_sequences(y_data, padding='post', maxlen=max_len)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6In8jKV70zDa"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=.2, random_state=777)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9Qp5AeR00RD"
      },
      "source": [
        "y_train = to_categorical(y_train, num_classes=tag_size)\n",
        "y_test = to_categorical(y_test, num_classes=tag_size)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxXrLe6W06Nr",
        "outputId": "0f464652-6b48-4bf2-9e0e-2fc94477be8e"
      },
      "source": [
        "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n",
        "print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\n",
        "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n",
        "print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련 샘플 문장의 크기 : (38367, 70)\n",
            "훈련 샘플 레이블의 크기 : (38367, 70, 18)\n",
            "테스트 샘플 문장의 크기 : (9592, 70)\n",
            "테스트 샘플 레이블의 크기 : (9592, 70, 18)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHflaMe5W-8M"
      },
      "source": [
        "## 글자 임베딩(Char Embedding)을 위한 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlKCcLFWXBXJ",
        "outputId": "e7abdd17-008c-4887-95c4-6861eded10fa"
      },
      "source": [
        "#char_vocab 만들기\n",
        "words = list(set(data[\"Word\"].values))\n",
        "chars = set([str.lower(w_i) for w in words for w_i in w])\n",
        "chars = sorted(list(chars))\n",
        "print(chars)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '~', '\\x85', '\\x91', '\\x92', '\\x93', '\\x94', '\\x96', '\\x97', '\\xa0', '°', 'é', 'ë', 'ö', 'ü']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7JfVPdYXkAK"
      },
      "source": [
        "char_to_index = {c: i+2 for i,c in enumerate(chars)}\n",
        "char_to_index[\"OOV\"] = 1\n",
        "char_to_index[\"PAD\"] = 0\n",
        "\n",
        "index_to_char = {}\n",
        "for key, value in char_to_index.items():\n",
        "  index_to_char[value] = key"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAePG7cVbwzK"
      },
      "source": [
        "max_len_char = 15\n",
        "\n",
        "def padding_char_indice(char_indice, max_len_char):\n",
        "  return pad_sequences(\n",
        "      sequences = char_indice, maxlen = max_len_char, padding = 'post', value = 0)\n",
        "\n",
        "def integer_coding(sentences):\n",
        "  char_data = []\n",
        "  for ts in sentences:\n",
        "    word_to_indice = [word_to_index[t] for t in ts]\n",
        "    char_indice = [[char_to_index[char] for char in t] for t in ts]\n",
        "    char_indice = padding_char_indice(char_indice = char_indice, max_len_char= max_len_char)\n",
        "    \n",
        "    for chars_of_token in char_indice:\n",
        "      if len(chars_of_token) > max_len_char: # 문자의 개수가 max_len_char을 넘을 경우 continue 이하의 코드는 실행하지 않고 for문의 다음 값 진행\n",
        "        continue\n",
        "    char_data.append(char_indice)\n",
        "  return char_data"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUZS5mGBgF9j"
      },
      "source": [
        "X_char_data = integer_coding(sentences)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxZkwNUugN3_",
        "outputId": "df11ff55-5184-430e-a7b9-d6f05d056549"
      },
      "source": [
        "print(sentences[0])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5jWHQ7Rh_dD",
        "outputId": "5bc1240e-f475-41f5-a250-046dba1c1597"
      },
      "source": [
        "print([index_to_word[idx] for idx in X_data[0] if idx !=0])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W--SoN1LgUOq",
        "outputId": "8e519183-09f4-45db-a0b7-387087ad36b1"
      },
      "source": [
        "print(X_data[0])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 254    6  967   16 1795  238  468    7  523    2  129    5   61    9\n",
            "  571    2  833    6  186   90   22   15   56    3    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXeh0bTugLPZ",
        "outputId": "46d5ca22-d3f8-44d9-eee9-225d79b18389"
      },
      "source": [
        "print(X_char_data[0])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[53 41 48 54 52 34 47 37 52  0  0  0  0  0  0]\n",
            " [48 39  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [37 38 46 48 47 52 53 51 34 53 48 51 52  0  0]\n",
            " [41 34 55 38  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [46 34 51 36 41 38 37  0  0  0  0  0  0  0  0]\n",
            " [53 41 51 48 54 40 41  0  0  0  0  0  0  0  0]\n",
            " [45 48 47 37 48 47  0  0  0  0  0  0  0  0  0]\n",
            " [53 48  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [49 51 48 53 38 52 53  0  0  0  0  0  0  0  0]\n",
            " [53 41 38  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [56 34 51  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [42 47  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [42 51 34 50  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [34 47 37  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [37 38 46 34 47 37  0  0  0  0  0  0  0  0  0]\n",
            " [53 41 38  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [56 42 53 41 37 51 34 56 34 45  0  0  0  0  0]\n",
            " [48 39  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [35 51 42 53 42 52 41  0  0  0  0  0  0  0  0]\n",
            " [53 51 48 48 49 52  0  0  0  0  0  0  0  0  0]\n",
            " [39 51 48 46  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [53 41 34 53  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [36 48 54 47 53 51 58  0  0  0  0  0  0  0  0]\n",
            " [14  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS8gFl32jhM2",
        "outputId": "d3abc420-6c34-45ff-875e-8a763a929ae3"
      },
      "source": [
        "X_char_data = pad_sequences(X_char_data, maxlen=max_len, padding='post', value = 0)\n",
        "X_char_data[0].shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKQ3Ia9ggFv_"
      },
      "source": [
        "X_char_train, X_char_test, _, _ = train_test_split(X_char_data, y_data, test_size=.2, random_state=777)\n",
        "\n",
        "X_char_train = np.array(X_char_train)\n",
        "X_char_test = np.array(X_char_test)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6k23Q6IkzwP",
        "outputId": "77c8e406-6cfe-4812-94bb-aeb66ced07df"
      },
      "source": [
        "print(X_train[0])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 150  928  361   17 2624    9 4131 3567    9    8 2893 1250  880  107\n",
            "    3    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mSdhhv7LlF6K",
        "outputId": "bffb5dd9-033a-4bd4-9b1c-471e3b87dcf5"
      },
      "source": [
        "index_to_word[X_train[0][0]]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'soldiers'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgXzXDaflOhO",
        "outputId": "3818d7fb-62fb-420c-9f71-de4edcfe9952"
      },
      "source": [
        "print([index_to_char[char] for char in X_char_train[0][0]])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['s', 'o', 'l', 'd', 'i', 'e', 'r', 's', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRkGQzrglczq",
        "outputId": "3a962e3e-7d53-439e-93e5-e7bdfb13b591"
      },
      "source": [
        "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n",
        "print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\n",
        "print('훈련 샘플 char 데이터의 크기 : {}'.format(X_char_train.shape))\n",
        "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n",
        "print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련 샘플 문장의 크기 : (38367, 70)\n",
            "훈련 샘플 레이블의 크기 : (38367, 70, 18)\n",
            "훈련 샘플 char 데이터의 크기 : (38367, 70, 15)\n",
            "테스트 샘플 문장의 크기 : (9592, 70)\n",
            "테스트 샘플 레이블의 크기 : (9592, 70, 18)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pflHk2pQ07dT"
      },
      "source": [
        "## F1-Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckF0r_ue09Eo",
        "outputId": "59856e09-17ad-4b6e-9353-2c732c5b83bd"
      },
      "source": [
        "!pip install seqeval"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\r\u001b[K     |███████▌                        | 10kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30kB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40kB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16172 sha256=4a43ce5edf1fc7474ff905fd9298217bf70ead889bcc6a33fab30a6abae4553d\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUr4UmJuAjLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4b81daf-c513-4a8e-f7e0-05f5aa89b821"
      },
      "source": [
        "from keras.callbacks import Callback\n",
        "from seqeval.metrics import f1_score, classification_report"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q3xyo7zAncI"
      },
      "source": [
        "class F1score(Callback):\n",
        "    def __init__(self, value = 0.0, use_char = True):\n",
        "      super(F1score, self).__init__()  #uper(파생클래스, self)로 기반 클래스의 메서드 호출 =>  파생 클래스와 self를 넣어서 현재 클래스가 어떤 클래스인지 명확하게 표시\n",
        "      self.value = value\n",
        "      self.use_char = use_char\n",
        "\n",
        "    def sequences_to_tags(self, sequences): #예측값을 index_to_ner을 사용하여 태깅 정보로 변환\n",
        "      result = []\n",
        "      for sequence in sequences:\n",
        "        tag = []\n",
        "        for pred in sequence:\n",
        "          pred_index = np.argmax(pred)\n",
        "          tag.append(index_to_ner[pred_index].replace(\"PAD\",\"O\"))\n",
        "        result.append(tag)\n",
        "      return result\n",
        "\n",
        "    # 에포크가 끝날 때마다 실행되는 함수\n",
        "    # 부모 클래스(Callback)에서 상속 후 매서드 변경\n",
        "    def on_epoch_end(self, epoch, logs = {}):\n",
        "\n",
        "      #char Embedding을 사용하는 경우\n",
        "      if self.use_char:\n",
        "        X_test = self.validation_data[0]\n",
        "        X_char_test = self.validation_data[1]\n",
        "        y_test = self.validation_data[2]\n",
        "        y_predicted = self.model.predict([X_test, X_char_test])\n",
        "\n",
        "      else:\n",
        "        X_test = self.validation_data[0]\n",
        "        y_test = self.validation_data[1]\n",
        "        y_predicted = self.model.predict([X_test])\n",
        "\n",
        "      pred_tags = self.sequences_to_tags(y_predicted)\n",
        "      test_tags = self.sequences_to_tags(y_test)\n",
        "\n",
        "      score = f1_score(pred_tags, test_tags)\n",
        "      print(' - f1: {:04.2f}'.format(score * 100))\n",
        "      print(classification_report(test_tags, pred_tags))\n",
        "\n",
        "      # F1-score가 지금까지 중 가장 높은 경우\n",
        "      if score > self.value:\n",
        "        print('f1_score improved from %f to %f, saving model to best_model.h5'%(self.value, score))\n",
        "        self.model.save('best_model.h5')\n",
        "        self.value = score\n",
        "      else:\n",
        "        print('f1_score did not improve from %f'%(self.value))\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7xZJNbS_8pn"
      },
      "source": [
        "## BiLSTM-CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5vxgLijA9yM"
      },
      "source": [
        "from keras.layers import Dense, LSTM, Bidirectional, TimeDistributed, Embedding, Dropout, concatenate, Conv1D, GlobalMaxPool1D, GlobalMaxPooling1D, Flatten, MaxPooling1D\n",
        "from keras import Input, Model\n",
        "from keras.initializers import RandomUniform\n",
        "from keras.models import load_model"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dC7CC1oYk9-"
      },
      "source": [
        "# Input = (None) 대신 Max_len을 적어주면 embedding 후 tensor는 (batch_size, input_length, input_dim)\n",
        "# batch size : 전체 데이터를 몇개씩 분리하여 학습시킬지 지정\n",
        "# input_length : 입력한 데이터의 길이, 여기선 max_len\n",
        "# input_dim = output_dim(?), 단어별 벡터 차원 개수"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrfJDtKLMeWR",
        "outputId": "00f9eb8e-5cc8-41a2-840a-600b0d4bb6e9"
      },
      "source": [
        "#워드 임베딩\n",
        "word_ids = Input(shape = (None,), dtype = 'int32', name = 'words_input') # None : Batch size\n",
        "word_embeddings = Embedding(input_dim = vocab_size, output_dim = 64)(word_ids)\n",
        "print(word_ids)\n",
        "print(word_embeddings)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"words_input_4:0\", shape=(?, ?), dtype=int32)\n",
            "Tensor(\"embedding_3/embedding_lookup/Identity:0\", shape=(?, ?, 64), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a3fGOg0nbfI",
        "outputId": "fe02da9d-f3f3-40a3-a7af-7f8557c7f4f2"
      },
      "source": [
        "#워드 임베딩\n",
        "word_ids = Input(shape = (None,), dtype = 'int32', name = 'words_input') # None : Batch size\n",
        "word_embeddings = Embedding(input_dim = vocab_size, output_dim = 64)(word_ids)\n",
        "\n",
        "#char 임베딩\n",
        "char_ids = Input(shape = (None, max_len_char,), name = 'char_input')\n",
        "embed_char_out = TimeDistributed(Embedding(input_dim = len(char_to_index), output_dim = 30, embeddings_initializer=RandomUniform(minval=-0.5,maxval=0.05)),name = 'char_embedding')(char_ids)\n",
        "dropout = Dropout(0.5)(embed_char_out)\n",
        "\n",
        "# char 임베딩에 대해서는 Conv1D 수행\n",
        "conv1d_out= TimeDistributed(Conv1D(kernel_size=3, filters=30, padding='same',activation='tanh', strides=1))(dropout)\n",
        "maxpool_out=TimeDistributed(MaxPooling1D(max_len_char))(conv1d_out)\n",
        "# conv1d_out= TimeDistributed(Conv1D(kernel_size=3, filters=30, padding='valid',activation='tanh', strides=1))(dropout)\n",
        "# maxpool_out=TimeDistributed(GlobalMaxPooling1D())(conv1d_out)\n",
        "char_embeddings = TimeDistributed(Flatten())(maxpool_out)\n",
        "char_embeddings = Dropout(0.5)(char_embeddings)\n",
        "\n",
        "# char 임베딩을 Conv1D 수행한 뒤에 워드 임베딩과 연결\n",
        "output = concatenate([word_embeddings, char_embeddings])\n",
        "\n",
        "# 연결한 벡터를 가지고 문장의 길이만큼 LSTM을 수행\n",
        "output = Bidirectional(LSTM(50, return_sequences=True, dropout=0.50, recurrent_dropout=0.25))(output)\n",
        "\n",
        "# 출력층\n",
        "output = TimeDistributed(Dense(tag_size, activation='softmax'))(output)\n",
        "\n",
        "model = Model(inputs=[word_ids , char_ids], outputs=[output])\n",
        "model.compile(loss='categorical_crossentropy', optimizer='nadam',  metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "char_input (InputLayer)         (None, None, 15)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "char_embedding (TimeDistributed (None, None, 15, 30) 2220        char_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, None, 15, 30) 0           char_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_53 (TimeDistri (None, None, 15, 30) 2730        dropout_30[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_54 (TimeDistri (None, None, 1, 30)  0           time_distributed_53[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "words_input (InputLayer)        (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_55 (TimeDistri (None, None, 30)     0           time_distributed_54[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "embedding_20 (Embedding)        (None, None, 64)     2036416     words_input[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_31 (Dropout)            (None, None, 30)     0           time_distributed_55[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, None, 94)     0           embedding_20[0][0]               \n",
            "                                                                 dropout_31[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_32 (Bidirectional (None, None, 100)    58000       concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_56 (TimeDistri (None, None, 18)     1818        bidirectional_32[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 2,101,184\n",
            "Trainable params: 2,101,184\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc6wivPY-2e5",
        "outputId": "de733541-0cf4-4a2b-b79b-9758b58f7170"
      },
      "source": [
        "history = model.fit([X_train, X_char_train], y_train, batch_size = 32, epochs = 10, validation_split = 0.1, verbose = 1, callbacks=[F1score(use_char=True)])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 34530 samples, validate on 3837 samples\n",
            "Epoch 1/10\n",
            "34530/34530 [==============================] - 235s 7ms/step - loss: 0.1151 - acc: 0.9701 - val_loss: 0.0492 - val_acc: 0.9855\n",
            " - f1: 73.65\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00        37\n",
            "         eve       0.00      0.00      0.00        30\n",
            "         geo       0.77      0.84      0.81      3087\n",
            "         gpe       0.93      0.94      0.93      1146\n",
            "         nat       0.00      0.00      0.00        16\n",
            "         org       0.54      0.52      0.53      1691\n",
            "         per       0.61      0.61      0.61      1310\n",
            "         tim       0.82      0.77      0.80      1672\n",
            "\n",
            "   micro avg       0.74      0.74      0.74      8989\n",
            "   macro avg       0.46      0.46      0.46      8989\n",
            "weighted avg       0.73      0.74      0.73      8989\n",
            "\n",
            "f1_score improved from 0.000000 to 0.736526, saving model to best_model.h5\n",
            "Epoch 2/10\n",
            "34530/34530 [==============================] - 231s 7ms/step - loss: 0.0417 - acc: 0.9877 - val_loss: 0.0441 - val_acc: 0.9869\n",
            " - f1: 76.54\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00        37\n",
            "         eve       0.00      0.00      0.00        30\n",
            "         geo       0.81      0.85      0.83      3087\n",
            "         gpe       0.92      0.95      0.94      1146\n",
            "         nat       0.00      0.00      0.00        16\n",
            "         org       0.61      0.49      0.55      1691\n",
            "         per       0.66      0.65      0.66      1310\n",
            "         tim       0.84      0.81      0.83      1672\n",
            "\n",
            "   micro avg       0.78      0.75      0.77      8989\n",
            "   macro avg       0.48      0.47      0.47      8989\n",
            "weighted avg       0.76      0.75      0.76      8989\n",
            "\n",
            "f1_score improved from 0.736526 to 0.765447, saving model to best_model.h5\n",
            "Epoch 3/10\n",
            "34530/34530 [==============================] - 232s 7ms/step - loss: 0.0337 - acc: 0.9897 - val_loss: 0.0411 - val_acc: 0.9876\n",
            " - f1: 78.20\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00        37\n",
            "         eve       0.86      0.20      0.32        30\n",
            "         geo       0.81      0.87      0.84      3087\n",
            "         gpe       0.95      0.95      0.95      1146\n",
            "         nat       0.00      0.00      0.00        16\n",
            "         org       0.61      0.54      0.58      1691\n",
            "         per       0.68      0.69      0.69      1310\n",
            "         tim       0.84      0.84      0.84      1672\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      8989\n",
            "   macro avg       0.60      0.51      0.53      8989\n",
            "weighted avg       0.78      0.78      0.78      8989\n",
            "\n",
            "f1_score improved from 0.765447 to 0.781998, saving model to best_model.h5\n",
            "Epoch 4/10\n",
            "34530/34530 [==============================] - 230s 7ms/step - loss: 0.0295 - acc: 0.9908 - val_loss: 0.0417 - val_acc: 0.9876\n",
            " - f1: 78.35\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       1.00      0.03      0.05        37\n",
            "         eve       0.60      0.20      0.30        30\n",
            "         geo       0.83      0.86      0.84      3087\n",
            "         gpe       0.95      0.95      0.95      1146\n",
            "         nat       0.36      0.25      0.30        16\n",
            "         org       0.64      0.54      0.59      1691\n",
            "         per       0.66      0.71      0.68      1310\n",
            "         tim       0.85      0.84      0.84      1672\n",
            "\n",
            "   micro avg       0.79      0.78      0.78      8989\n",
            "   macro avg       0.74      0.55      0.57      8989\n",
            "weighted avg       0.79      0.78      0.78      8989\n",
            "\n",
            "f1_score improved from 0.781998 to 0.783457, saving model to best_model.h5\n",
            "Epoch 5/10\n",
            "34530/34530 [==============================] - 231s 7ms/step - loss: 0.0266 - acc: 0.9915 - val_loss: 0.0417 - val_acc: 0.9876\n",
            " - f1: 78.99\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.71      0.14      0.23        37\n",
            "         eve       0.38      0.20      0.26        30\n",
            "         geo       0.84      0.85      0.84      3087\n",
            "         gpe       0.95      0.95      0.95      1146\n",
            "         nat       0.50      0.19      0.27        16\n",
            "         org       0.60      0.61      0.61      1691\n",
            "         per       0.70      0.71      0.70      1310\n",
            "         tim       0.86      0.85      0.85      1672\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      8989\n",
            "   macro avg       0.69      0.56      0.59      8989\n",
            "weighted avg       0.79      0.79      0.79      8989\n",
            "\n",
            "f1_score improved from 0.783457 to 0.789950, saving model to best_model.h5\n",
            "Epoch 6/10\n",
            "34530/34530 [==============================] - 231s 7ms/step - loss: 0.0246 - acc: 0.9921 - val_loss: 0.0438 - val_acc: 0.9873\n",
            " - f1: 78.34\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.86      0.16      0.27        37\n",
            "         eve       0.35      0.20      0.26        30\n",
            "         geo       0.87      0.81      0.84      3087\n",
            "         gpe       0.94      0.95      0.95      1146\n",
            "         nat       0.80      0.25      0.38        16\n",
            "         org       0.56      0.63      0.60      1691\n",
            "         per       0.70      0.71      0.70      1310\n",
            "         tim       0.84      0.85      0.85      1672\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      8989\n",
            "   macro avg       0.74      0.57      0.61      8989\n",
            "weighted avg       0.79      0.78      0.78      8989\n",
            "\n",
            "f1_score did not improve from 0.789950\n",
            "Epoch 7/10\n",
            "34530/34530 [==============================] - 230s 7ms/step - loss: 0.0233 - acc: 0.9925 - val_loss: 0.0441 - val_acc: 0.9878\n",
            " - f1: 79.03\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.33      0.19      0.24        37\n",
            "         eve       0.47      0.23      0.31        30\n",
            "         geo       0.83      0.86      0.85      3087\n",
            "         gpe       0.95      0.95      0.95      1146\n",
            "         nat       0.55      0.38      0.44        16\n",
            "         org       0.65      0.57      0.60      1691\n",
            "         per       0.69      0.70      0.70      1310\n",
            "         tim       0.84      0.85      0.85      1672\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      8989\n",
            "   macro avg       0.66      0.59      0.62      8989\n",
            "weighted avg       0.79      0.79      0.79      8989\n",
            "\n",
            "f1_score improved from 0.789950 to 0.790256, saving model to best_model.h5\n",
            "Epoch 8/10\n",
            "34530/34530 [==============================] - 230s 7ms/step - loss: 0.0217 - acc: 0.9929 - val_loss: 0.0453 - val_acc: 0.9871\n",
            " - f1: 78.11\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.27      0.16      0.20        37\n",
            "         eve       0.44      0.23      0.30        30\n",
            "         geo       0.84      0.84      0.84      3087\n",
            "         gpe       0.94      0.95      0.95      1146\n",
            "         nat       0.53      0.56      0.55        16\n",
            "         org       0.57      0.62      0.60      1691\n",
            "         per       0.69      0.71      0.70      1310\n",
            "         tim       0.83      0.85      0.84      1672\n",
            "\n",
            "   micro avg       0.77      0.79      0.78      8989\n",
            "   macro avg       0.64      0.62      0.62      8989\n",
            "weighted avg       0.78      0.79      0.78      8989\n",
            "\n",
            "f1_score did not improve from 0.790256\n",
            "Epoch 9/10\n",
            "34530/34530 [==============================] - 231s 7ms/step - loss: 0.0206 - acc: 0.9933 - val_loss: 0.0465 - val_acc: 0.9874\n",
            " - f1: 78.26\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.43      0.16      0.24        37\n",
            "         eve       0.35      0.23      0.28        30\n",
            "         geo       0.83      0.86      0.84      3087\n",
            "         gpe       0.94      0.95      0.95      1146\n",
            "         nat       0.75      0.38      0.50        16\n",
            "         org       0.61      0.58      0.59      1691\n",
            "         per       0.67      0.69      0.68      1310\n",
            "         tim       0.84      0.84      0.84      1672\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      8989\n",
            "   macro avg       0.68      0.59      0.62      8989\n",
            "weighted avg       0.78      0.78      0.78      8989\n",
            "\n",
            "f1_score did not improve from 0.790256\n",
            "Epoch 10/10\n",
            "34530/34530 [==============================] - 231s 7ms/step - loss: 0.0196 - acc: 0.9935 - val_loss: 0.0472 - val_acc: 0.9876\n",
            " - f1: 78.94\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.33      0.16      0.22        37\n",
            "         eve       0.29      0.23      0.26        30\n",
            "         geo       0.83      0.85      0.84      3087\n",
            "         gpe       0.94      0.95      0.95      1146\n",
            "         nat       0.71      0.31      0.43        16\n",
            "         org       0.62      0.59      0.60      1691\n",
            "         per       0.71      0.69      0.70      1310\n",
            "         tim       0.87      0.84      0.86      1672\n",
            "\n",
            "   micro avg       0.80      0.78      0.79      8989\n",
            "   macro avg       0.66      0.58      0.61      8989\n",
            "weighted avg       0.79      0.78      0.79      8989\n",
            "\n",
            "f1_score did not improve from 0.790256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwDLcBzI-ujL"
      },
      "source": [
        "bilstm_cnn_model = load_model('best_model.h5')"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLJsDPMyLWPm"
      },
      "source": [
        "f1score = F1score(use_char=True)\n",
        "\n",
        "y_predicted = bilstm_cnn_model.predict([X_test, X_char_test])\n",
        "pred_tags = f1score.sequences_to_tags(y_predicted)\n",
        "test_tags = f1score.sequences_to_tags(y_test)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElANqaHPLXyI",
        "outputId": "295bf5d8-e1eb-45e0-a746-6f8489b688d0"
      },
      "source": [
        "print(classification_report(test_tags, pred_tags))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.24      0.17      0.20        63\n",
            "         eve       0.40      0.33      0.36        52\n",
            "         geo       0.82      0.86      0.84      7620\n",
            "         gpe       0.96      0.94      0.95      3145\n",
            "         nat       0.53      0.43      0.48        37\n",
            "         org       0.63      0.55      0.59      4033\n",
            "         per       0.75      0.73      0.74      3545\n",
            "         tim       0.84      0.86      0.85      4067\n",
            "\n",
            "   micro avg       0.80      0.79      0.80     22562\n",
            "   macro avg       0.65      0.61      0.63     22562\n",
            "weighted avg       0.79      0.79      0.79     22562\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7_MJdbqLZZ1",
        "outputId": "d4cc340f-db58-4209-e0c3-d456d6f679e0"
      },
      "source": [
        "print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score: 79.7%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oC7a9DGLLbf8"
      },
      "source": [
        "## BiLSTM-CNN-CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1NI2xSNLd-n"
      },
      "source": [
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy\n",
        "\n",
        "from keras.layers import Dense, LSTM, Bidirectional, TimeDistributed, Embedding, Dropout, concatenate, Conv1D, GlobalMaxPool1D, Flatten, MaxPooling1D\n",
        "from keras import Input, Model\n",
        "from keras.initializers import RandomUniform\n",
        "from keras.models import load_model"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BocxBoTgbZal",
        "outputId": "eb6c56ec-7ada-454b-9526-3103b2a087b3"
      },
      "source": [
        "#워드 임베딩\n",
        "word_ids = Input(shape = (None,), dtype = \"int32\", name = 'words_input')\n",
        "word_embeddings = Embedding(input_dim = vocab_size, output_dim = 64)(word_ids)\n",
        "\n",
        "#char 임베딩\n",
        "char_ids = Input(shape = (None,max_len_char,), dtype = \"int32\", name = 'char_input')\n",
        "embed_char_out = TimeDistributed(Embedding(input_dim = len(char_to_index), output_dim = 30, embeddings_initializer = RandomUniform(minval= -0.5, maxval = 0.5), name = 'char_embedding'))(char_ids)\n",
        "dropout = Dropout(rate = 0.5)(embed_char_out)\n",
        "\n",
        "#char 임베딩에 대해서 Cond1D 수행\n",
        "conv1d_out = TimeDistributed(Conv1D(kernel_size=3, filters = 30, strides=1, padding = 'same',activation='tanh'))(dropout)\n",
        "maxpool_out = TimeDistributed(MaxPooling1D(pool_size = max_len_char))(conv1d_out)\n",
        "char_embeddings = TimeDistributed(Flatten())(maxpool_out)\n",
        "char_embeddings = Dropout(rate = 0.5)(char_embeddings)\n",
        "\n",
        "# char 임베딩을 Conv1D 수행한 뒤에 워드 임베딩과 연결\n",
        "output = concatenate([word_embeddings, char_embeddings])\n",
        "\n",
        "# 출력층에 CRF 층을 추가\n",
        "output = TimeDistributed(Dense(50, activation='relu'))(output)\n",
        "crf = CRF(units = tag_size)\n",
        "output = crf(output)\n",
        "\n",
        "model = Model(inputs=[word_ids, char_ids], outputs=[output])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBm_0X8_mkXx",
        "outputId": "64aae43b-1d57-480c-8843-17cd395a9c0c"
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=crf.loss_function, metrics=[crf.accuracy])\n",
        "history = model.fit([X_train, X_char_train], y_train, batch_size = 32, epochs = 15, validation_split = 0.1, verbose = 1, callbacks=[F1score(use_char=True)])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:2403: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "Train on 34530 samples, validate on 3837 samples\n",
            "Epoch 1/15\n",
            "34530/34530 [==============================] - 127s 4ms/step - loss: 0.1747 - crf_viterbi_accuracy: 0.9557 - val_loss: 0.0560 - val_crf_viterbi_accuracy: 0.9830\n",
            " - f1: 73.37\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00        37\n",
            "         eve       0.00      0.00      0.00        30\n",
            "         geo       0.73      0.82      0.77      3087\n",
            "         gpe       0.91      0.95      0.93      1146\n",
            "         nat       0.00      0.00      0.00        16\n",
            "         org       0.69      0.44      0.54      1691\n",
            "         per       0.68      0.63      0.65      1310\n",
            "         tim       0.80      0.73      0.77      1672\n",
            "\n",
            "   micro avg       0.76      0.71      0.73      8989\n",
            "   macro avg       0.48      0.45      0.46      8989\n",
            "weighted avg       0.74      0.71      0.72      8989\n",
            "\n",
            "f1_score improved from 0.000000 to 0.733711, saving model to best_model.h5\n",
            "Epoch 2/15\n",
            "34530/34530 [==============================] - 120s 3ms/step - loss: 0.0411 - crf_viterbi_accuracy: 0.9857 - val_loss: 0.0390 - val_crf_viterbi_accuracy: 0.9854\n",
            " - f1: 77.37\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00        37\n",
            "         eve       0.86      0.20      0.32        30\n",
            "         geo       0.79      0.86      0.82      3087\n",
            "         gpe       0.93      0.95      0.94      1146\n",
            "         nat       0.00      0.00      0.00        16\n",
            "         org       0.73      0.49      0.58      1691\n",
            "         per       0.72      0.70      0.71      1310\n",
            "         tim       0.84      0.75      0.80      1672\n",
            "\n",
            "   micro avg       0.80      0.75      0.77      8989\n",
            "   macro avg       0.61      0.49      0.52      8989\n",
            "weighted avg       0.79      0.75      0.76      8989\n",
            "\n",
            "f1_score improved from 0.733711 to 0.773686, saving model to best_model.h5\n",
            "Epoch 3/15\n",
            "34530/34530 [==============================] - 118s 3ms/step - loss: 0.0248 - crf_viterbi_accuracy: 0.9878 - val_loss: 0.0278 - val_crf_viterbi_accuracy: 0.9857\n",
            " - f1: 77.93\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       1.00      0.05      0.10        37\n",
            "         eve       0.71      0.17      0.27        30\n",
            "         geo       0.81      0.85      0.83      3087\n",
            "         gpe       0.94      0.95      0.95      1146\n",
            "         nat       0.75      0.19      0.30        16\n",
            "         org       0.67      0.51      0.58      1691\n",
            "         per       0.73      0.70      0.71      1310\n",
            "         tim       0.87      0.76      0.81      1672\n",
            "\n",
            "   micro avg       0.81      0.75      0.78      8989\n",
            "   macro avg       0.81      0.52      0.57      8989\n",
            "weighted avg       0.80      0.75      0.77      8989\n",
            "\n",
            "f1_score improved from 0.773686 to 0.779285, saving model to best_model.h5\n",
            "Epoch 4/15\n",
            "34530/34530 [==============================] - 119s 3ms/step - loss: 0.0114 - crf_viterbi_accuracy: 0.9887 - val_loss: 0.0145 - val_crf_viterbi_accuracy: 0.9857\n",
            " - f1: 78.12\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       1.00      0.05      0.10        37\n",
            "         eve       0.75      0.20      0.32        30\n",
            "         geo       0.82      0.85      0.83      3087\n",
            "         gpe       0.95      0.95      0.95      1146\n",
            "         nat       0.75      0.19      0.30        16\n",
            "         org       0.68      0.50      0.58      1691\n",
            "         per       0.75      0.69      0.72      1310\n",
            "         tim       0.88      0.76      0.82      1672\n",
            "\n",
            "   micro avg       0.82      0.75      0.78      8989\n",
            "   macro avg       0.82      0.52      0.58      8989\n",
            "weighted avg       0.81      0.75      0.77      8989\n",
            "\n",
            "f1_score improved from 0.779285 to 0.781243, saving model to best_model.h5\n",
            "Epoch 5/15\n",
            "34530/34530 [==============================] - 119s 3ms/step - loss: -0.0028 - crf_viterbi_accuracy: 0.9891 - val_loss: 2.1123e-04 - val_crf_viterbi_accuracy: 0.9858\n",
            " - f1: 78.56\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.67      0.11      0.19        37\n",
            "         eve       0.75      0.20      0.32        30\n",
            "         geo       0.82      0.86      0.84      3087\n",
            "         gpe       0.95      0.95      0.95      1146\n",
            "         nat       0.67      0.12      0.21        16\n",
            "         org       0.69      0.49      0.57      1691\n",
            "         per       0.76      0.68      0.72      1310\n",
            "         tim       0.90      0.76      0.82      1672\n",
            "\n",
            "   micro avg       0.82      0.75      0.79      8989\n",
            "   macro avg       0.78      0.52      0.58      8989\n",
            "weighted avg       0.82      0.75      0.78      8989\n",
            "\n",
            "f1_score improved from 0.781243 to 0.785619, saving model to best_model.h5\n",
            "Epoch 6/15\n",
            "34530/34530 [==============================] - 124s 4ms/step - loss: -0.0182 - crf_viterbi_accuracy: 0.9894 - val_loss: -0.0152 - val_crf_viterbi_accuracy: 0.9858\n",
            " - f1: 78.44\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.57      0.11      0.18        37\n",
            "         eve       0.60      0.20      0.30        30\n",
            "         geo       0.82      0.86      0.84      3087\n",
            "         gpe       0.95      0.95      0.95      1146\n",
            "         nat       0.47      0.44      0.45        16\n",
            "         org       0.71      0.48      0.57      1691\n",
            "         per       0.75      0.67      0.71      1310\n",
            "         tim       0.91      0.76      0.83      1672\n",
            "\n",
            "   micro avg       0.83      0.75      0.78      8989\n",
            "   macro avg       0.72      0.56      0.60      8989\n",
            "weighted avg       0.82      0.75      0.78      8989\n",
            "\n",
            "f1_score did not improve from 0.785619\n",
            "Epoch 7/15\n",
            "34530/34530 [==============================] - 120s 3ms/step - loss: -0.0341 - crf_viterbi_accuracy: 0.9896 - val_loss: -0.0308 - val_crf_viterbi_accuracy: 0.9860\n",
            " - f1: 78.86\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.67      0.11      0.19        37\n",
            "         eve       0.50      0.20      0.29        30\n",
            "         geo       0.82      0.86      0.84      3087\n",
            "         gpe       0.95      0.94      0.95      1146\n",
            "         nat       0.75      0.19      0.30        16\n",
            "         org       0.71      0.51      0.59      1691\n",
            "         per       0.75      0.68      0.71      1310\n",
            "         tim       0.91      0.77      0.83      1672\n",
            "\n",
            "   micro avg       0.83      0.75      0.79      8989\n",
            "   macro avg       0.76      0.53      0.59      8989\n",
            "weighted avg       0.82      0.75      0.78      8989\n",
            "\n",
            "f1_score improved from 0.785619 to 0.788588, saving model to best_model.h5\n",
            "Epoch 8/15\n",
            "34530/34530 [==============================] - 121s 3ms/step - loss: -0.0501 - crf_viterbi_accuracy: 0.9897 - val_loss: -0.0463 - val_crf_viterbi_accuracy: 0.9856\n",
            " - f1: 78.38\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.57      0.11      0.18        37\n",
            "         eve       0.50      0.20      0.29        30\n",
            "         geo       0.83      0.85      0.84      3087\n",
            "         gpe       0.95      0.94      0.95      1146\n",
            "         nat       1.00      0.25      0.40        16\n",
            "         org       0.69      0.50      0.58      1691\n",
            "         per       0.75      0.68      0.71      1310\n",
            "         tim       0.90      0.76      0.83      1672\n",
            "\n",
            "   micro avg       0.82      0.75      0.78      8989\n",
            "   macro avg       0.77      0.54      0.60      8989\n",
            "weighted avg       0.82      0.75      0.78      8989\n",
            "\n",
            "f1_score did not improve from 0.788588\n",
            "Epoch 9/15\n",
            "34530/34530 [==============================] - 120s 3ms/step - loss: -0.0660 - crf_viterbi_accuracy: 0.9898 - val_loss: -0.0618 - val_crf_viterbi_accuracy: 0.9857\n",
            " - f1: 78.56\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.50      0.11      0.18        37\n",
            "         eve       0.43      0.20      0.27        30\n",
            "         geo       0.83      0.85      0.84      3087\n",
            "         gpe       0.95      0.94      0.95      1146\n",
            "         nat       1.00      0.25      0.40        16\n",
            "         org       0.73      0.48      0.58      1691\n",
            "         per       0.72      0.69      0.71      1310\n",
            "         tim       0.91      0.76      0.83      1672\n",
            "\n",
            "   micro avg       0.83      0.75      0.79      8989\n",
            "   macro avg       0.76      0.54      0.59      8989\n",
            "weighted avg       0.82      0.75      0.78      8989\n",
            "\n",
            "f1_score did not improve from 0.788588\n",
            "Epoch 10/15\n",
            "34530/34530 [==============================] - 124s 4ms/step - loss: -0.0819 - crf_viterbi_accuracy: 0.9899 - val_loss: -0.0773 - val_crf_viterbi_accuracy: 0.9858\n",
            " - f1: 78.65\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.50      0.11      0.18        37\n",
            "         eve       0.46      0.20      0.28        30\n",
            "         geo       0.83      0.85      0.84      3087\n",
            "         gpe       0.95      0.95      0.95      1146\n",
            "         nat       0.75      0.19      0.30        16\n",
            "         org       0.72      0.50      0.59      1691\n",
            "         per       0.74      0.68      0.71      1310\n",
            "         tim       0.90      0.76      0.83      1672\n",
            "\n",
            "   micro avg       0.83      0.75      0.79      8989\n",
            "   macro avg       0.73      0.53      0.58      8989\n",
            "weighted avg       0.82      0.75      0.78      8989\n",
            "\n",
            "f1_score did not improve from 0.788588\n",
            "Epoch 11/15\n",
            "34530/34530 [==============================] - 121s 4ms/step - loss: -0.0976 - crf_viterbi_accuracy: 0.9900 - val_loss: -0.0931 - val_crf_viterbi_accuracy: 0.9859\n",
            " - f1: 78.78\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.57      0.11      0.18        37\n",
            "         eve       0.46      0.20      0.28        30\n",
            "         geo       0.83      0.85      0.84      3087\n",
            "         gpe       0.95      0.94      0.95      1146\n",
            "         nat       1.00      0.25      0.40        16\n",
            "         org       0.71      0.51      0.59      1691\n",
            "         per       0.75      0.68      0.72      1310\n",
            "         tim       0.90      0.76      0.82      1672\n",
            "\n",
            "   micro avg       0.83      0.75      0.79      8989\n",
            "   macro avg       0.77      0.54      0.60      8989\n",
            "weighted avg       0.82      0.75      0.78      8989\n",
            "\n",
            "f1_score did not improve from 0.788588\n",
            "Epoch 12/15\n",
            "34530/34530 [==============================] - 123s 4ms/step - loss: -0.1133 - crf_viterbi_accuracy: 0.9900 - val_loss: -0.1082 - val_crf_viterbi_accuracy: 0.9855\n",
            " - f1: 78.34\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.50      0.14      0.21        37\n",
            "         eve       0.46      0.20      0.28        30\n",
            "         geo       0.83      0.85      0.84      3087\n",
            "         gpe       0.96      0.93      0.95      1146\n",
            "         nat       0.67      0.12      0.21        16\n",
            "         org       0.70      0.50      0.58      1691\n",
            "         per       0.74      0.68      0.71      1310\n",
            "         tim       0.89      0.75      0.82      1672\n",
            "\n",
            "   micro avg       0.82      0.75      0.78      8989\n",
            "   macro avg       0.72      0.52      0.57      8989\n",
            "weighted avg       0.82      0.75      0.78      8989\n",
            "\n",
            "f1_score did not improve from 0.788588\n",
            "Epoch 13/15\n",
            "34530/34530 [==============================] - 121s 4ms/step - loss: -0.1289 - crf_viterbi_accuracy: 0.9901 - val_loss: -0.1236 - val_crf_viterbi_accuracy: 0.9856\n",
            " - f1: 78.20\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.50      0.14      0.21        37\n",
            "         eve       0.46      0.20      0.28        30\n",
            "         geo       0.82      0.84      0.83      3087\n",
            "         gpe       0.95      0.94      0.95      1146\n",
            "         nat       0.47      0.44      0.45        16\n",
            "         org       0.69      0.51      0.59      1691\n",
            "         per       0.75      0.69      0.71      1310\n",
            "         tim       0.89      0.75      0.82      1672\n",
            "\n",
            "   micro avg       0.82      0.75      0.78      8989\n",
            "   macro avg       0.69      0.56      0.61      8989\n",
            "weighted avg       0.81      0.75      0.78      8989\n",
            "\n",
            "f1_score did not improve from 0.788588\n",
            "Epoch 14/15\n",
            "34530/34530 [==============================] - 120s 3ms/step - loss: -0.1445 - crf_viterbi_accuracy: 0.9901 - val_loss: -0.1388 - val_crf_viterbi_accuracy: 0.9855\n",
            " - f1: 78.35\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.56      0.14      0.22        37\n",
            "         eve       0.46      0.20      0.28        30\n",
            "         geo       0.83      0.85      0.84      3087\n",
            "         gpe       0.95      0.93      0.94      1146\n",
            "         nat       0.53      0.50      0.52        16\n",
            "         org       0.67      0.53      0.59      1691\n",
            "         per       0.75      0.68      0.72      1310\n",
            "         tim       0.90      0.75      0.82      1672\n",
            "\n",
            "   micro avg       0.82      0.75      0.78      8989\n",
            "   macro avg       0.71      0.57      0.62      8989\n",
            "weighted avg       0.81      0.75      0.78      8989\n",
            "\n",
            "f1_score did not improve from 0.788588\n",
            "Epoch 15/15\n",
            "34530/34530 [==============================] - 123s 4ms/step - loss: -0.1601 - crf_viterbi_accuracy: 0.9901 - val_loss: -0.1540 - val_crf_viterbi_accuracy: 0.9855\n",
            " - f1: 78.30\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.67      0.11      0.19        37\n",
            "         eve       0.53      0.27      0.36        30\n",
            "         geo       0.83      0.84      0.83      3087\n",
            "         gpe       0.95      0.94      0.95      1146\n",
            "         nat       1.00      0.25      0.40        16\n",
            "         org       0.67      0.53      0.59      1691\n",
            "         per       0.75      0.67      0.71      1310\n",
            "         tim       0.91      0.76      0.82      1672\n",
            "\n",
            "   micro avg       0.82      0.75      0.78      8989\n",
            "   macro avg       0.79      0.54      0.61      8989\n",
            "weighted avg       0.82      0.75      0.78      8989\n",
            "\n",
            "f1_score did not improve from 0.788588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--T7DmT8mnAi"
      },
      "source": [
        "bilstm_cnn_crf_model = load_model(filepath = \"best_model.h5\", custom_objects={'CRF' : CRF,\n",
        "                                                                             'crf_loss' : crf_loss,\n",
        "                                                                             'crf_viterbi_accuracy' : crf_viterbi_accuracy})\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qz3zJwJ5fI1c"
      },
      "source": [
        "f1score = F1score(use_char = True)\n",
        "\n",
        "y_predict = bilstm_cnn_crf_model.predict([X_test, X_char_test])\n",
        "pred_tags = f1score.sequences_to_tags(y_predict)\n",
        "test_tags = f1score.sequences_to_tags(y_test)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQxT0xJafxgK",
        "outputId": "4bf1dcb9-9445-419d-e882-3953dc5a1c80"
      },
      "source": [
        "print(classification_report(test_tags,pred_tags))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.28      0.08      0.12        63\n",
            "         eve       0.70      0.31      0.43        52\n",
            "         geo       0.81      0.85      0.83      7620\n",
            "         gpe       0.96      0.94      0.95      3145\n",
            "         nat       0.54      0.19      0.28        37\n",
            "         org       0.71      0.51      0.59      4033\n",
            "         per       0.80      0.72      0.76      3545\n",
            "         tim       0.89      0.75      0.82      4067\n",
            "\n",
            "   micro avg       0.83      0.76      0.79     22562\n",
            "   macro avg       0.71      0.54      0.60     22562\n",
            "weighted avg       0.83      0.76      0.79     22562\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4SxVq1hf1u3",
        "outputId": "bf963390-1ec4-4dab-c090-bbf6c35a8f63"
      },
      "source": [
        "print(f\"F1-Score : {f1_score(test_tags,pred_tags)*100:.2f}%\")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-Score : 79.34%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm2RwSqggAnT"
      },
      "source": [
        "## BiLSTM-BiLSTM-CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABB9KG5LgH65"
      },
      "source": [
        "#워드 임베딩\n",
        "word_ids = Input(shape = (None,),dtype = 'int32',name = 'word_input')\n",
        "word_embeddings = Embedding(input_dim = vocab_size,\n",
        "                            output_dim = 64,\n",
        "                            mask_zero=True,\n",
        "                            name = 'word_embedding')(word_ids)\n",
        "\n",
        "#char 임베딩\n",
        "char_ids = Input(shape = (None, max_len_char,), dtype = 'int32', name = 'char_input')\n",
        "char_embeddings = Embedding(input_dim = len(char_to_index),\n",
        "                            output_dim = 30,\n",
        "                            mask_zero = True,\n",
        "                            embeddings_initializer = RandomUniform(minval = -0.5, maxval = 0.5),\n",
        "                            name = 'char_embedding')(char_ids)\n",
        "\n",
        "char_embeddings = TimeDistributed(Bidirectional(LSTM(64,return_sequences=False)))(char_embeddings) # 각 방향별 양끝의 입력값에서 반대끝의 입력값까지 순차적으로 진행하여 최종 결과를 반환, 이때 양방향이므로 지정한 output의 2배가 출력됨\n",
        "\n",
        "#char 임베딩을 워드 임베딩과 concat\n",
        "word_embeddings = concatenate(inputs = [word_embeddings, char_embeddings])\n",
        "word_embeddings = Dropout(0.3)(word_embeddings)\n",
        "z = Bidirectional(LSTM(64, return_sequences=True))(word_embeddings)\n",
        "z = Dense(tag_size, activation='tanh')(z)\n",
        "\n",
        "crf = CRF(tag_size)\n",
        "output = crf(z)\n",
        "\n",
        "model = Model(inputs = [word_ids,char_ids],outputs = output)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmnkgVn_rfQZ",
        "outputId": "4780e3e8-c533-48b7-f6a0-da49406a54ca"
      },
      "source": [
        "model.compile(optimizer='adam', loss = crf.loss_function, metrics = [crf.accuracy])\n",
        "history = model.fit(x = [X_train, X_char_train], y = y_train, epochs = 15, batch_size = 32, validation_split=0.1, verbose = 1, callbacks=[F1score(use_char=True)])"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.7/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 34530 samples, validate on 3837 samples\n",
            "Epoch 1/15\n",
            "34530/34530 [==============================] - 892s 26ms/step - loss: 8.4046 - crf_viterbi_accuracy: 0.8967 - val_loss: 8.1519 - val_crf_viterbi_accuracy: 0.9481\n",
            " - f1: 73.55\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00        37\n",
            "         eve       0.00      0.00      0.00        30\n",
            "         geo       0.78      0.84      0.81      3087\n",
            "         gpe       0.93      0.91      0.92      1146\n",
            "         nat       0.00      0.00      0.00        16\n",
            "         org       0.57      0.47      0.52      1691\n",
            "         per       0.65      0.63      0.64      1310\n",
            "         tim       0.79      0.75      0.77      1672\n",
            "\n",
            "   micro avg       0.75      0.72      0.74      8989\n",
            "   macro avg       0.46      0.45      0.46      8989\n",
            "weighted avg       0.73      0.72      0.73      8989\n",
            "\n",
            "f1_score improved from 0.000000 to 0.735545, saving model to best_model.h5\n",
            "Epoch 2/15\n",
            "34530/34530 [==============================] - 872s 25ms/step - loss: 8.1225 - crf_viterbi_accuracy: 0.9563 - val_loss: 8.1011 - val_crf_viterbi_accuracy: 0.9569\n",
            " - f1: 78.93\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00        37\n",
            "         eve       0.00      0.00      0.00        30\n",
            "         geo       0.83      0.85      0.84      3087\n",
            "         gpe       0.95      0.93      0.94      1146\n",
            "         nat       0.00      0.00      0.00        16\n",
            "         org       0.71      0.50      0.59      1691\n",
            "         per       0.71      0.70      0.71      1310\n",
            "         tim       0.88      0.82      0.85      1672\n",
            "\n",
            "   micro avg       0.82      0.76      0.79      8989\n",
            "   macro avg       0.51      0.48      0.49      8989\n",
            "weighted avg       0.81      0.76      0.78      8989\n",
            "\n",
            "f1_score improved from 0.735545 to 0.789258, saving model to best_model.h5\n",
            "Epoch 3/15\n",
            "34530/34530 [==============================] - 864s 25ms/step - loss: 8.0860 - crf_viterbi_accuracy: 0.9650 - val_loss: 8.0852 - val_crf_viterbi_accuracy: 0.9602\n",
            " - f1: 80.47\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00        37\n",
            "         eve       0.00      0.00      0.00        30\n",
            "         geo       0.84      0.87      0.85      3087\n",
            "         gpe       0.94      0.95      0.94      1146\n",
            "         nat       0.00      0.00      0.00        16\n",
            "         org       0.73      0.54      0.62      1691\n",
            "         per       0.71      0.75      0.73      1310\n",
            "         tim       0.91      0.82      0.86      1672\n",
            "\n",
            "   micro avg       0.83      0.78      0.80      8989\n",
            "   macro avg       0.52      0.49      0.50      8989\n",
            "weighted avg       0.82      0.78      0.80      8989\n",
            "\n",
            "f1_score improved from 0.789258 to 0.804686, saving model to best_model.h5\n",
            "Epoch 4/15\n",
            "34530/34530 [==============================] - 880s 25ms/step - loss: 8.0702 - crf_viterbi_accuracy: 0.9686 - val_loss: 8.0805 - val_crf_viterbi_accuracy: 0.9594\n",
            " - f1: 80.23\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00        37\n",
            "         eve       0.00      0.00      0.00        30\n",
            "         geo       0.87      0.84      0.86      3087\n",
            "         gpe       0.93      0.95      0.94      1146\n",
            "         nat       0.00      0.00      0.00        16\n",
            "         org       0.64      0.61      0.62      1691\n",
            "         per       0.74      0.71      0.73      1310\n",
            "         tim       0.90      0.83      0.87      1672\n",
            "\n",
            "   micro avg       0.82      0.78      0.80      8989\n",
            "   macro avg       0.51      0.49      0.50      8989\n",
            "weighted avg       0.81      0.78      0.80      8989\n",
            "\n",
            "f1_score did not improve from 0.804686\n",
            "Epoch 5/15\n",
            "34530/34530 [==============================] - 873s 25ms/step - loss: 8.0600 - crf_viterbi_accuracy: 0.9710 - val_loss: 8.0754 - val_crf_viterbi_accuracy: 0.9608\n",
            " - f1: 80.88\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00        37\n",
            "         eve       0.00      0.00      0.00        30\n",
            "         geo       0.83      0.88      0.85      3087\n",
            "         gpe       0.94      0.95      0.95      1146\n",
            "         nat       1.00      0.19      0.32        16\n",
            "         org       0.75      0.54      0.62      1691\n",
            "         per       0.72      0.76      0.74      1310\n",
            "         tim       0.88      0.85      0.86      1672\n",
            "\n",
            "   micro avg       0.82      0.79      0.81      8989\n",
            "   macro avg       0.64      0.52      0.54      8989\n",
            "weighted avg       0.82      0.79      0.80      8989\n",
            "\n",
            "f1_score improved from 0.804686 to 0.808836, saving model to best_model.h5\n",
            "Epoch 6/15\n",
            "34530/34530 [==============================] - 868s 25ms/step - loss: 8.0521 - crf_viterbi_accuracy: 0.9734 - val_loss: 8.0728 - val_crf_viterbi_accuracy: 0.9615\n",
            " - f1: 81.13\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00        37\n",
            "         eve       1.00      0.10      0.18        30\n",
            "         geo       0.83      0.88      0.85      3087\n",
            "         gpe       0.95      0.94      0.95      1146\n",
            "         nat       0.50      0.19      0.27        16\n",
            "         org       0.71      0.60      0.65      1691\n",
            "         per       0.72      0.75      0.73      1310\n",
            "         tim       0.89      0.85      0.87      1672\n",
            "\n",
            "   micro avg       0.82      0.81      0.81      8989\n",
            "   macro avg       0.70      0.54      0.56      8989\n",
            "weighted avg       0.81      0.81      0.81      8989\n",
            "\n",
            "f1_score improved from 0.808836 to 0.811268, saving model to best_model.h5\n",
            "Epoch 7/15\n",
            "34530/34530 [==============================] - 873s 25ms/step - loss: 8.0461 - crf_viterbi_accuracy: 0.9749 - val_loss: 8.0724 - val_crf_viterbi_accuracy: 0.9627\n",
            " - f1: 82.03\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00        37\n",
            "         eve       0.80      0.13      0.23        30\n",
            "         geo       0.85      0.87      0.86      3087\n",
            "         gpe       0.95      0.95      0.95      1146\n",
            "         nat       0.50      0.25      0.33        16\n",
            "         org       0.73      0.59      0.65      1691\n",
            "         per       0.76      0.74      0.75      1310\n",
            "         tim       0.90      0.86      0.88      1672\n",
            "\n",
            "   micro avg       0.84      0.80      0.82      8989\n",
            "   macro avg       0.69      0.55      0.58      8989\n",
            "weighted avg       0.83      0.80      0.81      8989\n",
            "\n",
            "f1_score improved from 0.811268 to 0.820323, saving model to best_model.h5\n",
            "Epoch 8/15\n",
            "34530/34530 [==============================] - 866s 25ms/step - loss: 8.0411 - crf_viterbi_accuracy: 0.9769 - val_loss: 8.0723 - val_crf_viterbi_accuracy: 0.9614\n",
            " - f1: 81.68\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       1.00      0.05      0.10        37\n",
            "         eve       0.67      0.20      0.31        30\n",
            "         geo       0.84      0.88      0.86      3087\n",
            "         gpe       0.96      0.94      0.95      1146\n",
            "         nat       0.57      0.25      0.35        16\n",
            "         org       0.70      0.61      0.65      1691\n",
            "         per       0.75      0.74      0.75      1310\n",
            "         tim       0.89      0.86      0.88      1672\n",
            "\n",
            "   micro avg       0.83      0.81      0.82      8989\n",
            "   macro avg       0.80      0.57      0.61      8989\n",
            "weighted avg       0.82      0.81      0.81      8989\n",
            "\n",
            "f1_score did not improve from 0.820323\n",
            "Epoch 9/15\n",
            "34530/34530 [==============================] - 878s 25ms/step - loss: 8.0369 - crf_viterbi_accuracy: 0.9784 - val_loss: 8.0737 - val_crf_viterbi_accuracy: 0.9588\n",
            " - f1: 81.13\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       1.00      0.05      0.10        37\n",
            "         eve       0.44      0.13      0.21        30\n",
            "         geo       0.85      0.87      0.86      3087\n",
            "         gpe       0.95      0.95      0.95      1146\n",
            "         nat       0.58      0.44      0.50        16\n",
            "         org       0.63      0.64      0.64      1691\n",
            "         per       0.77      0.73      0.75      1310\n",
            "         tim       0.87      0.87      0.87      1672\n",
            "\n",
            "   micro avg       0.81      0.81      0.81      8989\n",
            "   macro avg       0.76      0.58      0.61      8989\n",
            "weighted avg       0.81      0.81      0.81      8989\n",
            "\n",
            "f1_score did not improve from 0.820323\n",
            "Epoch 10/15\n",
            "34530/34530 [==============================] - 879s 25ms/step - loss: 8.0336 - crf_viterbi_accuracy: 0.9795 - val_loss: 8.0743 - val_crf_viterbi_accuracy: 0.9609\n",
            " - f1: 81.26\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.50      0.08      0.14        37\n",
            "         eve       0.38      0.20      0.26        30\n",
            "         geo       0.84      0.87      0.86      3087\n",
            "         gpe       0.95      0.94      0.95      1146\n",
            "         nat       0.62      0.50      0.55        16\n",
            "         org       0.66      0.63      0.65      1691\n",
            "         per       0.74      0.74      0.74      1310\n",
            "         tim       0.90      0.87      0.88      1672\n",
            "\n",
            "   micro avg       0.82      0.81      0.81      8989\n",
            "   macro avg       0.70      0.60      0.63      8989\n",
            "weighted avg       0.81      0.81      0.81      8989\n",
            "\n",
            "f1_score did not improve from 0.820323\n",
            "Epoch 11/15\n",
            "34530/34530 [==============================] - 875s 25ms/step - loss: 8.0303 - crf_viterbi_accuracy: 0.9809 - val_loss: 8.0792 - val_crf_viterbi_accuracy: 0.9593\n",
            " - f1: 80.80\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.12      0.03      0.04        37\n",
            "         eve       0.29      0.13      0.18        30\n",
            "         geo       0.86      0.85      0.85      3087\n",
            "         gpe       0.94      0.95      0.95      1146\n",
            "         nat       0.71      0.31      0.43        16\n",
            "         org       0.65      0.62      0.63      1691\n",
            "         per       0.77      0.73      0.75      1310\n",
            "         tim       0.88      0.86      0.87      1672\n",
            "\n",
            "   micro avg       0.82      0.80      0.81      8989\n",
            "   macro avg       0.65      0.56      0.59      8989\n",
            "weighted avg       0.82      0.80      0.81      8989\n",
            "\n",
            "f1_score did not improve from 0.820323\n",
            "Epoch 12/15\n",
            "34530/34530 [==============================] - 887s 26ms/step - loss: 8.0277 - crf_viterbi_accuracy: 0.9823 - val_loss: 8.0808 - val_crf_viterbi_accuracy: 0.9570\n",
            " - f1: 80.36\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.33      0.05      0.09        37\n",
            "         eve       0.40      0.20      0.27        30\n",
            "         geo       0.87      0.84      0.85      3087\n",
            "         gpe       0.95      0.94      0.95      1146\n",
            "         nat       0.50      0.25      0.33        16\n",
            "         org       0.60      0.64      0.62      1691\n",
            "         per       0.74      0.75      0.75      1310\n",
            "         tim       0.88      0.87      0.87      1672\n",
            "\n",
            "   micro avg       0.81      0.80      0.80      8989\n",
            "   macro avg       0.66      0.57      0.59      8989\n",
            "weighted avg       0.81      0.80      0.80      8989\n",
            "\n",
            "f1_score did not improve from 0.820323\n",
            "Epoch 13/15\n",
            "34530/34530 [==============================] - 876s 25ms/step - loss: 8.0251 - crf_viterbi_accuracy: 0.9833 - val_loss: 8.0816 - val_crf_viterbi_accuracy: 0.9588\n",
            " - f1: 80.68\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.25      0.11      0.15        37\n",
            "         eve       0.31      0.17      0.22        30\n",
            "         geo       0.85      0.86      0.86      3087\n",
            "         gpe       0.95      0.95      0.95      1146\n",
            "         nat       0.60      0.38      0.46        16\n",
            "         org       0.65      0.62      0.63      1691\n",
            "         per       0.75      0.73      0.74      1310\n",
            "         tim       0.86      0.86      0.86      1672\n",
            "\n",
            "   micro avg       0.81      0.80      0.81      8989\n",
            "   macro avg       0.65      0.58      0.61      8989\n",
            "weighted avg       0.81      0.80      0.80      8989\n",
            "\n",
            "f1_score did not improve from 0.820323\n",
            "Epoch 14/15\n",
            "34530/34530 [==============================] - 874s 25ms/step - loss: 8.0225 - crf_viterbi_accuracy: 0.9842 - val_loss: 8.0842 - val_crf_viterbi_accuracy: 0.9587\n",
            " - f1: 80.73\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.40      0.11      0.17        37\n",
            "         eve       0.19      0.20      0.20        30\n",
            "         geo       0.85      0.86      0.85      3087\n",
            "         gpe       0.94      0.94      0.94      1146\n",
            "         nat       0.46      0.38      0.41        16\n",
            "         org       0.64      0.62      0.63      1691\n",
            "         per       0.76      0.73      0.74      1310\n",
            "         tim       0.89      0.86      0.88      1672\n",
            "\n",
            "   micro avg       0.82      0.80      0.81      8989\n",
            "   macro avg       0.64      0.59      0.60      8989\n",
            "weighted avg       0.81      0.80      0.81      8989\n",
            "\n",
            "f1_score did not improve from 0.820323\n",
            "Epoch 15/15\n",
            "34530/34530 [==============================] - 888s 26ms/step - loss: 8.0207 - crf_viterbi_accuracy: 0.9850 - val_loss: 8.0903 - val_crf_viterbi_accuracy: 0.9589\n",
            " - f1: 80.48\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.18      0.08      0.11        37\n",
            "         eve       0.33      0.20      0.25        30\n",
            "         geo       0.82      0.87      0.85      3087\n",
            "         gpe       0.95      0.94      0.94      1146\n",
            "         nat       0.55      0.38      0.44        16\n",
            "         org       0.68      0.58      0.63      1691\n",
            "         per       0.73      0.75      0.74      1310\n",
            "         tim       0.87      0.87      0.87      1672\n",
            "\n",
            "   micro avg       0.81      0.80      0.80      8989\n",
            "   macro avg       0.64      0.58      0.60      8989\n",
            "weighted avg       0.80      0.80      0.80      8989\n",
            "\n",
            "f1_score did not improve from 0.820323\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "666i6wnHr0Xa"
      },
      "source": [
        "bilstm_bilstm_crf_model = load_model(filepath = \"best_model.h5\", custom_objects = {'CRF' : CRF,\n",
        "                                                                                   'crf_loss' : crf_loss,\n",
        "                                                                                   'crf_viterbi_accuracy' : crf_viterbi_accuracy})\n",
        "f1score = F1score(use_char = True)\n",
        "y_predicted = bilstm_bilstm_crf_model.predict([X_test, X_char_test])"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlQeyKGsiCc5"
      },
      "source": [
        "pred_tags = f1score.sequences_to_tags(y_predicted)\n",
        "test_tags = f1score.sequences_to_tags(y_test)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXyhsoRytSNp",
        "outputId": "b9dcadf8-7d2e-4066-cb18-e06a4b8b8cee"
      },
      "source": [
        "print(classification_report(test_tags, pred_tags))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.25      0.02      0.03        63\n",
            "         eve       0.91      0.19      0.32        52\n",
            "         geo       0.84      0.87      0.86      7620\n",
            "         gpe       0.96      0.94      0.95      3145\n",
            "         nat       0.55      0.16      0.25        37\n",
            "         org       0.72      0.58      0.64      4033\n",
            "         per       0.80      0.76      0.78      3545\n",
            "         tim       0.89      0.85      0.87      4067\n",
            "\n",
            "   micro avg       0.84      0.80      0.82     22562\n",
            "   macro avg       0.74      0.55      0.59     22562\n",
            "weighted avg       0.84      0.80      0.82     22562\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oU2s0zUtVzy",
        "outputId": "5336db8b-0b2b-4b3e-f630-e2a686c5c533"
      },
      "source": [
        "print(f\"F1_score : {f1_score(test_tags,pred_tags)*100:.2f}%\")"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1_score : 82.24%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oOKVhqJtfoC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}