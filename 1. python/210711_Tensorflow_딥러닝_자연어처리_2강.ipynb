{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "210711_Tensorflow_딥러닝_자연어처리_2강",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNguqlyTbbRjOwnC1zzmVst",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/changyong93/TIL/blob/main/1.%20python/210711_Tensorflow_%EB%94%A5%EB%9F%AC%EB%8B%9D_%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC_2%EA%B0%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMKd0Ol6y3pz"
      },
      "source": [
        "# 선형회귀 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HduzDQdgxT8w"
      },
      "source": [
        "## 자동 미분을 이용한 선형 회귀 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSWtWZYOxYOV"
      },
      "source": [
        "### 자동 미분"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52Xcg72Qxb54"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZhuYXg2zUKC"
      },
      "source": [
        "tape_gradient()는 자동 미분 기능을 수행. 임의로 2w^2+5라는 식을 세워보고 w에 대해 미분"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWfox1BFxdd3"
      },
      "source": [
        "w = tf.Variable(2.)\n",
        "# tensorflow type으로 변수 선언\n",
        "# tensor(텐서)를 메모리에 저장하는 변수\n",
        "\n",
        "def f(w):\n",
        "    y = w**2\n",
        "    z = 2*y + 5\n",
        "    return z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDXXInySxjtB"
      },
      "source": [
        "이제 gradients를 출력하면 w에 대한 미분한 값이 저장된 것을 확인할 수 있음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfDlgtk4yOsW",
        "outputId": "cf4b4f7a-4eae-4563-8710-d8c6ee9847ab"
      },
      "source": [
        "# tf.GradientTape는 컨텍스트(context) 안에서 실행된 모든 연산을 테이프(tape)에 \"기록\"\n",
        "# https://www.tensorflow.org/guide/autodiff?hl=ko\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    z = f(w)\n",
        "\n",
        "gradients = tape.gradient(z, [w])\n",
        "# z를 w에 대해 미분을 하는데, 이때 w가 2일 때의 미분 값을 출력\n",
        "print(gradients)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Tensor: shape=(), dtype=float32, numpy=8.0>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fY7k86gn0DWa"
      },
      "source": [
        "### 선형 회귀 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RO5kanC92CSJ",
        "outputId": "24dca0f4-6e2d-4a72-ab8b-7232e61a1377"
      },
      "source": [
        "# 선형 회귀 모델(Wx+b)를 위한 tf.Variable을 선언합니다\n",
        "W = tf.Variable(tf.random.normal(shape = [1])) #랜덤으로 초기값 지정\n",
        "b = tf.Variable(tf.random.normal(shape = [1])) #랜덤으로 초기값 지정\n",
        "print(W)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([-1.091866], dtype=float32)>\n",
            "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.16852678], dtype=float32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hiWfjsu3f6C"
      },
      "source": [
        "#### 가설 정의\n",
        "---\n",
        "@tf.function을 추가하면 파이썬 코드가 동일한 텐서플로우 코드로 변경되며, 이렇게 하면 성능을 최적화 할 수 있음  \n",
        "모든 파이썬 함수에 tf.funciton 데코레이터를 적용 할 필요는 없음.   \n",
        "모델 훈련의 한 단계(step)나 정방향 연산(forward pass) 같은 고수준 연산에만 tf.function 데코레이터를 적용\n",
        "\n",
        "---\n",
        "데코레이션\n",
        "- http://solarisailab.com/archives/2351 : 텐서플로우 기초 그래프 생성과 실행 설명\n",
        "- https://www.tensorflow.org/guide/function?hl=ko : (정식 문서)\n",
        "- https://www.inflearn.com/questions/174459 : tf.functions 역할 설명(인프런)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3w1j9kEABPYK"
      },
      "source": [
        "#여기서 정방향연산은 입력을 넣었을 때 결과를 출력하는 아래 linear_model 함수\n",
        "@tf.function\n",
        "def linear_model(x):\n",
        "    return W*x + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z-pQD7mBT0P"
      },
      "source": [
        "#### 손실 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mmzj_dMBW7a"
      },
      "source": [
        "#손실 함수를 정의\n",
        "#MSE 손실함수 사용(mean(y - yy)^2)\n",
        "@tf.function\n",
        "def mse_loss(y_pred,y): #제곱한 값이므로, y와 y' 위치가 바뀌어도 상관없음\n",
        "    return tf.reduce_mean(tf.square(y_pred - y)) #tf.reduce_mean = 평균을 출력해주는 메소드"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyL69Zf_B0MJ"
      },
      "source": [
        "#### 옵티마이저 정의(경사 하강법)\n",
        "\n",
        "파라미터를 업데이트 하는 한 순간을 step이라고 할 때, 그 한 순간을  정의한 함수를 train_step이라는 이름의 함수로 작성   \n",
        "아래 내용은 이해가 안되면 일단 처음에는 암기를 해도 무방할 만큼, TF2.0에서는 당연하게 사용되는 패턴   \n",
        "앞으로의 강의에서는 이보다도 더 쉬운 keras 패턴을 사용할 예정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOqBUAPNCL14"
      },
      "source": [
        "# 최적화를 위한 그라디언트 디센트 옵티마이저 정의\n",
        "# 사용자가 정한 learning rate 값을 sgd()에 작성\n",
        "optimizer = tf.optimizers.SGD(learning_rate=0.01)\n",
        "\n",
        "# 첫 번째 인자인 x는 입력 데이터\n",
        "# 두 번째 인자인 y는 레이블\n",
        "@tf.function\n",
        "def train_step(x,y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    #현재 파라미터에 기반한 입력 x에 대한 예측값을 y_pred\n",
        "    y_pred = linear_model(x)\n",
        "    \n",
        "    #MSE 계산\n",
        "    loss = mse_loss(y_pred,y)\n",
        "\n",
        "  #손실 함수에 대한 파라미터의 미분값 계산\n",
        "  gradients = tape.gradient(loss,[W,b]) #loss를 W와 b에 대해서 미분\n",
        "\n",
        "  #파라미터 업데이트\n",
        "  optimizer.apply_gradients(zip(gradients, [W,b])) #미분한 값을 기준으로 W,b를 업데이트"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xQSnc80EUF1",
        "outputId": "f6097129-ff50-4a74-d7c4-5a282126a7ce"
      },
      "source": [
        "# 트레이닝을 위한 입력값과 출력값 준비\n",
        "x_train = [1,2,3,4]\n",
        "y_train = [2,4,6,8]\n",
        "\n",
        "# 경사하강법을 1000번 수행\n",
        "for i in range(1000):\n",
        "  if (i+1) % 100 == 0:\n",
        "    print(i+1, \"회 학습\")\n",
        "  train_step(x_train,y_train)\n",
        "\n",
        "# 테스트를 위한 입력값을 준비\n",
        "x_test = [3.5, 5, 5.5, 6]\n",
        "# 테스트 데이터를 이요해 학습된 선형회귀 모델이 데이터의 경향성(y = 2x)을 잘 학습했는지 측정\n",
        "\n",
        "# 예상되는 참값 : [7, 10, 11, 12]\n",
        "# print(linear_model(x_test))\n",
        "print(linear_model(x_test).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 회 학습\n",
            "200 회 학습\n",
            "300 회 학습\n",
            "400 회 학습\n",
            "500 회 학습\n",
            "600 회 학습\n",
            "700 회 학습\n",
            "800 회 학습\n",
            "900 회 학습\n",
            "1000 회 학습\n",
            "[ 6.9896154  9.961792  10.9525175 11.943244 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ay1UfkjxWPo"
      },
      "source": [
        "## 케라스를 이용한 선형 회귀 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPtR5-nk014O"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awSJej2xIgjE"
      },
      "source": [
        "keras 모델을 만드는 방법은 sequential 방법과 functional API 방법이 있다(https://leestation.tistory.com/777, https://subinium.github.io/Keras-7/)\n",
        "- Sequential : 층층이(layer-by-layer) 쌓아 올릴 수 있게 하는 방법\n",
        "  - 대부분의 문제를 해결할 수 있지만, layer를 공유하는 구조나, 다중 입력/출력을 사용하지 못하는 문제가 있다\n",
        "- functional API : layer가 앞/뒤 layer에만 연결된 구조뿐 아니라 훨씬 더 자유자재로 그 구조를 정의하여 사용 가능\n",
        "  - layer들을 어떤 layer에든지 연결하여 사용 가능\n",
        "---\n",
        "- 첫 번째 인자인 1은 출력 차원을 정의\n",
        "- 두 번째 인자인 input_dim은 입력 차원을 정의\n",
        "- 이번 실습과 같이 1개의 실수 x를 가지고 하는 1개의 실수 y를 예측하는 단순 선형 회귀를 구현하는 경우에는 각각 1의 값을 가짐"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dohd5Mw0GzYv",
        "outputId": "8ad44db9-5c2a-45c6-f1a4-4926ea3a1d3f"
      },
      "source": [
        "X=[1,2,3,4,5,6,7,8,9] # 공부하는 시간\n",
        "y=[11,22,33,44,53,66,77,87,95] # 각 공부하는 시간에 맵핑되는 성적\n",
        "\n",
        "#방식 1)\n",
        "model = Sequential()\n",
        "\n",
        "# 입력 x의 차원은 1, 출력 y의 차원도 1. 선형 회귀이므로 activation은 'linear'\n",
        "#1-1)\n",
        "model.add(Dense(units = 1, input_dim = 1, activation = 'linear'))\n",
        "#1-2)\n",
        "# model.add(Dense(units = 1, input_shape = (1,), activation = 'linear'))\n",
        "\n",
        "#방식 2)\n",
        "# model = Sequential(\n",
        "#     [\n",
        "#      Dense(units = 1, input_dim = 1,activation = 'linear')\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "# sgd는 경하 하강법을 의미. 학습률(learning rate,lr)은 0.01\n",
        "sgd = optimizers.SGD(lr=0.01)\n",
        "\n",
        "\n",
        "# 손실 함수(Loss function)은 평균제곱오차 mse를 사용\n",
        "model.compile(optimizer = sgd, loss = 'mse', metrics = ['mse'])\n",
        "\n",
        "model.fit(X,y, batch_size = 1, epochs = 300, shuffle = False)\n",
        "#shuffle은 batch_size 단위로 섞음\n",
        "#shuffle을 안할 시 입력 데이터 순서까지 학습할 수 있음\n",
        "#일반적으로 데이터 순서가 무의미 하기에 셔플을 적용하지만 수업에선 셔플 옵션이 있다는 것을 보여주기 위해 False를 함"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 308.0792 - mse: 308.0792\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1537 - mse: 2.1537\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1534 - mse: 2.1534\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1532 - mse: 2.1532\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1530 - mse: 2.1530\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1527 - mse: 2.1527\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1525 - mse: 2.1525\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1523 - mse: 2.1523\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1521 - mse: 2.1521\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1519 - mse: 2.1519\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1517 - mse: 2.1517\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1515 - mse: 2.1515\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1513 - mse: 2.1513\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1511 - mse: 2.1511\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1510 - mse: 2.1510\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1508 - mse: 2.1508\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1506 - mse: 2.1506\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1505 - mse: 2.1505\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1504 - mse: 2.1504\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1502 - mse: 2.1502\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1501 - mse: 2.1501\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1499 - mse: 2.1499\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1498 - mse: 2.1498\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1497 - mse: 2.1497\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1496 - mse: 2.1496\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1494 - mse: 2.1494\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1493 - mse: 2.1493\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1492 - mse: 2.1492\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1491 - mse: 2.1491\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1490 - mse: 2.1490\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1489 - mse: 2.1489\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1488 - mse: 2.1488\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1487 - mse: 2.1487\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1486 - mse: 2.1486\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1486 - mse: 2.1486\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1485 - mse: 2.1485\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1484 - mse: 2.1484\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1483 - mse: 2.1483\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1482 - mse: 2.1482\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1482 - mse: 2.1482\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1481 - mse: 2.1481\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1480 - mse: 2.1480\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1480 - mse: 2.1480\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1479 - mse: 2.1479\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1478 - mse: 2.1478\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1478 - mse: 2.1478\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1477 - mse: 2.1477\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1476 - mse: 2.1476\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1476 - mse: 2.1476\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1476 - mse: 2.1476\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1475 - mse: 2.1475\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1475 - mse: 2.1475\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1474 - mse: 2.1474\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1474 - mse: 2.1474\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1473 - mse: 2.1473\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1473 - mse: 2.1473\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1472 - mse: 2.1472\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1472 - mse: 2.1472\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1472 - mse: 2.1472\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1471 - mse: 2.1471\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1471 - mse: 2.1471\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1470 - mse: 2.1470\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1470 - mse: 2.1470\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1470 - mse: 2.1470\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1469 - mse: 2.1469\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 2.1469 - mse: 2.1469\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1469 - mse: 2.1469\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1469 - mse: 2.1469\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1468 - mse: 2.1468\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1468 - mse: 2.1468\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1468 - mse: 2.1468\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1468 - mse: 2.1468\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1467 - mse: 2.1467\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1467 - mse: 2.1467\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1467 - mse: 2.1467\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1467 - mse: 2.1467\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1466 - mse: 2.1466\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1466 - mse: 2.1466\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1466 - mse: 2.1466\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1466 - mse: 2.1466\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1466 - mse: 2.1466\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1465 - mse: 2.1465\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1465 - mse: 2.1465\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1465 - mse: 2.1465\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1465 - mse: 2.1465\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1465 - mse: 2.1465\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1465 - mse: 2.1465\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1464 - mse: 2.1464\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1464 - mse: 2.1464\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1464 - mse: 2.1464\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1464 - mse: 2.1464\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1464 - mse: 2.1464\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1464 - mse: 2.1464\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1464 - mse: 2.1464\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1464 - mse: 2.1464\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1463 - mse: 2.1463\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1463 - mse: 2.1463\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1463 - mse: 2.1463\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1463 - mse: 2.1463\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1463 - mse: 2.1463\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1463 - mse: 2.1463\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1463 - mse: 2.1463\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1463 - mse: 2.1463\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1463 - mse: 2.1463\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1463 - mse: 2.1463\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1463 - mse: 2.1463\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1462 - mse: 2.1462\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1462 - mse: 2.1462\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1462 - mse: 2.1462\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1462 - mse: 2.1462\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1462 - mse: 2.1462\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1462 - mse: 2.1462\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1462 - mse: 2.1462\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1462 - mse: 2.1462\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1462 - mse: 2.1462\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1462 - mse: 2.1462\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1462 - mse: 2.1462\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1462 - mse: 2.1462\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1462 - mse: 2.1462\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1462 - mse: 2.1462\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1462 - mse: 2.1462\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1462 - mse: 2.1462\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1462 - mse: 2.1462\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1462 - mse: 2.1462\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1461 - mse: 2.1461\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 1ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 2.1460 - mse: 2.1460\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7987d81f50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "nt2R0uj0Tt0s",
        "outputId": "87458c66-d591-45c3-f445-1aace701cbf7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(X,model.predict(X),'b',X,y,'k--')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7985513e90>,\n",
              " <matplotlib.lines.Line2D at 0x7f7985521090>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv6rZQs8MRYz"
      },
      "source": [
        "# 2강 수업 내용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdD5cYYVMURi"
      },
      "source": [
        "## Bag of Words\n",
        "---\n",
        "단어의 순서는 고려하지 않고, 단어의 출현 빈도(frequency)에만 집중하는 텍스트 데이터 수치화 표현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADMHHyZUMi3a",
        "outputId": "be7150f1-9c59-4c2b-daf6-ff45cb1e6bfd"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.3MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.3MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/88/f817ef1af6f794e8f11313dcd1549de833f4599abcec82746ab5ed086686/JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 56.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Installing collected packages: beautifulsoup4, colorama, JPype1, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9O5uHEqMXid"
      },
      "source": [
        "### 직접 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wScozePIMY6F",
        "outputId": "922027bc-d64b-4bef-8616-14a3a2ff2bab"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "import re\n",
        "okt = Okt()\n",
        "\n",
        "sentence = \"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\"\n",
        "\n",
        "#정규표현식을 통해 온점 제거\n",
        "token = re.sub(\"(\\.)\",\"\",sentence)\n",
        "\n",
        "#Okt 형태소 분석기를 통해 토큰화 작업을 수행한 뒤에 token 변수에 값 할당\n",
        "token = okt.morphs(token)\n",
        "\n",
        "word2idx = {}\n",
        "bow = []\n",
        "for voca in token:\n",
        "    if voca not in word2idx.keys():\n",
        "        # token을 읽으면서, word2idx에 없는 단어는 새로 추가하고, 있으면 넘기고, bow에는 기본값 1개를 추가(단어 개수가 1개 이상이기 때문)\n",
        "        word2idx[voca] = len(word2idx)\n",
        "        bow.append(1)\n",
        "        # bow.insert(len(word2idx)-1,1) #강사님의 경우 이렇게 작성하셨지만, 단어가 없는 경우 순서대로 입력되기에 굳이 idx 위치를 맞춰줄 필요는 없어보임 \n",
        "    else:\n",
        "        idx = word2idx[voca]\n",
        "        # idx = word2idx.get(voca) # dict 데이터로 부터 특정 단어에 대한 idx 번호를 가져와야 하는데, get을 써도 되고, 아니면 indexing으로 찾아도 무방함\n",
        "        bow[idx] += 1\n",
        "        # 재등장한 단어는 해당하는 인덱스 위치에 +1을 추가(단어의 개수 세는 것)\n",
        "print(word2idx)\n",
        "print(bow)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9}\n",
            "[1, 2, 1, 1, 2, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl6SD7TvPP2e"
      },
      "source": [
        "### CounterVectorizer 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TY9yqXcxPSwP",
        "outputId": "72af04a5-05cc-4095-e34b-09acade64ca5"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vector = CountVectorizer()\n",
        "corpus = ['you know I want your love. because I love you.']\n",
        "print(vector.fit_transform(corpus).toarray()) #코퍼스로부터 각 단어의 빈도수 기록\n",
        "print(vector.vocabulary_) #단어별 인덱스가 어떻게 부여되어있는지 보여줌"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 1 2 1 2 1]]\n",
            "{'you': 4, 'know': 1, 'want': 3, 'your': 5, 'love': 2, 'because': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DBKT0CCPy5J"
      },
      "source": [
        "### TF-IDF 행렬 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6ytQjS5UOkE"
      },
      "source": [
        "import pandas as pd #데이터프레임 사용\n",
        "from math import log #idf 계산"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAoO8X7qUWDc",
        "outputId": "0c28a402-cb26-4414-84d9-9e8e9d1c0bc7"
      },
      "source": [
        "docs = [\n",
        "  '먹고 싶은 사과',\n",
        "  '먹고 싶은 바나나',\n",
        "  '길고 노란 바나나 바나나',\n",
        "  '저는 과일이 좋아요'\n",
        "] \n",
        "vocab = list(set(w for doc in docs for w in doc.split()))\n",
        "vocab.sort()\n",
        "vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['과일이', '길고', '노란', '먹고', '바나나', '사과', '싶은', '저는', '좋아요']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUo-0BBJUgXj"
      },
      "source": [
        "N = len(docs) #총 문서 수\n",
        "\n",
        "def tf(t,d): #t(word), d(document)\n",
        "  return d.count(t)\n",
        "\n",
        "def idf(t):\n",
        "  df = 0\n",
        "  for doc in docs:\n",
        "    df += t in doc #t, 즉 단어가 문서에 있으면 True(1) 아니면 False(0)\n",
        "  return log(N / (df + 1))\n",
        "\n",
        "def tfidf(t,d):\n",
        "  return tf(t,d) * idf(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "oeNm3qBxVe79",
        "outputId": "b1e5a40c-b0be-444b-b68c-aaed4dc791d5"
      },
      "source": [
        "result = []\n",
        "for doc in docs: # 각 문서에 대해 아래 명령을 수행\n",
        "    result.append([tf(v,doc) for v in vocab])\n",
        "tf_ = pd.DataFrame(result,columns = vocab)\n",
        "tf_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>과일이</th>\n",
              "      <th>길고</th>\n",
              "      <th>노란</th>\n",
              "      <th>먹고</th>\n",
              "      <th>바나나</th>\n",
              "      <th>사과</th>\n",
              "      <th>싶은</th>\n",
              "      <th>저는</th>\n",
              "      <th>좋아요</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   과일이  길고  노란  먹고  바나나  사과  싶은  저는  좋아요\n",
              "0    0   0   0   1    0   1   1   0    0\n",
              "1    0   0   0   1    1   0   1   0    0\n",
              "2    0   1   1   0    2   0   0   0    0\n",
              "3    1   0   0   0    0   0   0   1    1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "PZle3OkfWbQu",
        "outputId": "e0695967-d122-4a1a-de84-4252d21e1f99"
      },
      "source": [
        "result = [idf(t) for t in vocab]\n",
        "idf_ = pd.DataFrame(result, index = vocab, columns = ['idf'])\n",
        "idf_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>과일이</th>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>길고</th>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>노란</th>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>먹고</th>\n",
              "      <td>0.287682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>바나나</th>\n",
              "      <td>0.287682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>사과</th>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>싶은</th>\n",
              "      <td>0.287682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>저는</th>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>좋아요</th>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          idf\n",
              "과일이  0.693147\n",
              "길고   0.693147\n",
              "노란   0.693147\n",
              "먹고   0.287682\n",
              "바나나  0.287682\n",
              "사과   0.693147\n",
              "싶은   0.287682\n",
              "저는   0.693147\n",
              "좋아요  0.693147"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "IAQ4qNZpXkUP",
        "outputId": "c83a3a56-1b35-4ad4-c4ba-4ea41b58f6ca"
      },
      "source": [
        "result = []\n",
        "for doc in docs:\n",
        "  result.append([tfidf(t,doc) for t in vocab])\n",
        "tfidf_ = pd.DataFrame(result, columns = vocab)\n",
        "tfidf_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>과일이</th>\n",
              "      <th>길고</th>\n",
              "      <th>노란</th>\n",
              "      <th>먹고</th>\n",
              "      <th>바나나</th>\n",
              "      <th>사과</th>\n",
              "      <th>싶은</th>\n",
              "      <th>저는</th>\n",
              "      <th>좋아요</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.287682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.287682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.287682</td>\n",
              "      <td>0.287682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.287682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.575364</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        과일이        길고        노란  ...        싶은        저는       좋아요\n",
              "0  0.000000  0.000000  0.000000  ...  0.287682  0.000000  0.000000\n",
              "1  0.000000  0.000000  0.000000  ...  0.287682  0.000000  0.000000\n",
              "2  0.000000  0.693147  0.693147  ...  0.000000  0.000000  0.000000\n",
              "3  0.693147  0.000000  0.000000  ...  0.000000  0.693147  0.693147\n",
              "\n",
              "[4 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4rwh8CnYM_V"
      },
      "source": [
        "- 지금까지 IF-IDF의 가장 기본적인 식에 대해서 학습 및 실제 구현\n",
        "- 하지만 실제 TF-IDF 구현을 제공하는 많은 패키지들은 패키지마다 상위 기본적인 식을 기준으로 조금씩 다르게 구현\n",
        "- 만약 문서수가 4인데 df가 3인 경우 idf값이 0으로 출력되는 문제가 발생함, 이런 문제를 해결하기 위해 idf 값에 +1을 한 경우도 있는데 사이킷런도 이런 방식을 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaTXmfAmYoD9"
      },
      "source": [
        "### Tensorflow로 Bag of Words 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9spp-RWYvuS"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_upwECglZM1W",
        "outputId": "932748f2-8646-4375-91a4-a8fd96ff0803"
      },
      "source": [
        "texts = ['먹고 싶은 사과', '먹고 싶은 바나나', '길고 노란 바나나 바나나', '저는 과일이 좋아요']\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(texts)\n",
        "print(t.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'바나나': 1, '먹고': 2, '싶은': 3, '사과': 4, '길고': 5, '노란': 6, '저는': 7, '과일이': 8, '좋아요': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSMEufOyZbcO"
      },
      "source": [
        "- 각 단어에 숫자 1부터 시작하는 정수 인덱스 부여\n",
        "- text데이터를 matrix로 출력하는 texts_to_matrix()를 활용(총 4가지 모드)\n",
        "  - binary, count, freq, tfidf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzwesTyWZy1P",
        "outputId": "4a6205c9-9682-46e3-9b9b-41a033aabf43"
      },
      "source": [
        "print(t.texts_to_matrix(texts,mode = 'count'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 2. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEHhBrePbk-7"
      },
      "source": [
        "count 모드   \n",
        "- 각 문서별 단어 빈도 수\n",
        "- 주의할 점은, 단어의 index는 1번부터 부여되며 0번 인덱스는 그 어떤 단어도 할당되어 있지 않음\n",
        "- 따라서 실제 단어가 9개라도 열의 개수는 10개인 것을 주의 해야 함\n",
        "- DTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oQZhagRZryX",
        "outputId": "d899a053-d63a-45f5-ab96-166bbd7d34dd"
      },
      "source": [
        "print(t.texts_to_matrix(texts,mode = 'binary'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVaHZgK4b8J9"
      },
      "source": [
        "binary 모드\n",
        "- count 모드와 유사하지만 각 문서별 특정 단어가 있으면 1 아니면 0으로 값을 반환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nisLfaPRZ0ru",
        "outputId": "bff87304-c323-4c3c-ee9b-40975bcda8e0"
      },
      "source": [
        "print(t.texts_to_matrix(texts,mode = 'freq').round(3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.    0.    0.333 0.333 0.333 0.    0.    0.    0.    0.   ]\n",
            " [0.    0.333 0.333 0.333 0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.5   0.    0.    0.    0.25  0.25  0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    0.    0.    0.333 0.333 0.333]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEEcIgnYcCRG"
      },
      "source": [
        "freq 모드\n",
        "- 각 문서별 전체 단어 개수에서 특정 단어 개수를 나눠서 값을 반환\n",
        "- ex) 길고 노란 바나나 바나나 => 바나나의 값은 2 / 4, 길고와 노란의 값은 1/4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wNbu7ifZ17D",
        "outputId": "ddc43692-24e4-411f-bcd3-4ed74b44393d"
      },
      "source": [
        "print(t.texts_to_matrix(texts,mode = 'tfidf').round(3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.    0.    0.847 0.847 1.099 0.    0.    0.    0.    0.   ]\n",
            " [0.    0.847 0.847 0.847 0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    1.435 0.    0.    0.    1.099 1.099 0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    0.    0.    1.099 1.099 1.099]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDdBoWppcZ31"
      },
      "source": [
        "tfidf 모드\n",
        "- 직접 구현 및 sklearn의 tfidf와 조금 다른 방식\n",
        "- idf 계산 시 idf = log((N / (df+1)) + 1)로 log 내에 1을 더해줌\n",
        "- 조금씩 구현 방식은 다르지만 기본은 동일하므로 필요한 조건에 맞춰서 사용하면 됌"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZUyQqn9dD0X"
      },
      "source": [
        "## Tensorflow 기초(Keras)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtLs_ZloWy7Y"
      },
      "source": [
        "### import 시 패키지 네이밍"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJ0yX_wUW12l"
      },
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja-TJ9WgXD2O"
      },
      "source": [
        "### 딥러닝 실행 순서"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04tGoCgIXGA_"
      },
      "source": [
        "1. 전처리 : 학습에 필요한 데이터 전처리 수행   \n",
        "2. 모델링(model) : 모델을 정의   \n",
        "3. 컴파일(compile) : 모델 생성   \n",
        "4. 학습(fit) : 모델 학습   \n",
        "\n",
        "아래는 실세 전처리 - 모델링 - 컴파일 - 학습으로 이어지는 코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLoe55oiXV3_",
        "outputId": "959f7a5a-c9f5-43f5-e4cd-cf6a0d0df175"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.layers.Dense(units = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.core.Dense at 0x7f3c8c539ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUanUOvYXhuF",
        "outputId": "0cb0e977-c7d9-40f7-ef4b-649c39bb1a8f"
      },
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "Dense(units = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.core.Dense at 0x7f3c7e499750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilykgk7WXlwW",
        "outputId": "1d5aee20-7ccc-4fe8-ebbc-138bdcf22336"
      },
      "source": [
        "# 필요한 패키지 import\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# 데이터 전처리\n",
        "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
        "ys = np.array([5.0, 6.0, 7.0, 8.0, 9.0, 10.0], dtype=float)\n",
        "\n",
        "# 모델 정의(modeling)\n",
        "model = Sequential()\n",
        "\n",
        "# Dense의 첫번째 인자는 항상 출력의 차원을 의미\n",
        "model.add(Dense(units = 1,activation = 'linear',input_shape = (1,)))\n",
        "# model.add(Dense(units = 1,activation = 'linear',input_dim = 1))\n",
        "\n",
        "# 모델 생성(compile)\n",
        "model.compile(optimizer = 'sgd',loss = 'mse')\n",
        "\n",
        "# 학습(fit)\n",
        "model.fit(xs,ys,epochs = 1200, verbose = 0)\n",
        "\n",
        "# 검증\n",
        "# 16.000046\n",
        "model.predict([10.0])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[16.000046]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eoOsRd9YZ3v"
      },
      "source": [
        "tensorflow 2.0은 keras의 sequential 방식과 동일하게 블록쌓기 방식으로 매우 쉽게 모델링이 가능   \n",
        "Dense Layer는 가장 기본적인 신경망층   \n",
        "Dense == fully Connected layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "XPuDHYoGYy_b",
        "outputId": "f86284c9-bbee-49f7-af1a-ac98c34fd4e3"
      },
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image('https://cs231n.github.io/assets/nn1/neural_net2.jpeg')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPK4K54vYzui"
      },
      "source": [
        "model = Sequential([\n",
        "                    Dense(1)\n",
        "])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jh6vJbzzZC-C"
      },
      "source": [
        "### 적절한 optimizer와 loss 선정\n",
        "---\n",
        "- 모델별로 적절한 optimizer와 loss 선정이 필요\n",
        "- regression(회귀) 예측을 위해서는 loss = mse를 선택\n",
        "- optimizer는 여러가지를 활용할 수 있지만, 단순 회귀에선 sgd가 적당"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7eXgg50ZFis"
      },
      "source": [
        "### compile\n",
        "---\n",
        "- 선택한 optimizer와 loss를 지정해주고 컴파일 진행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRhr78-XkBxS"
      },
      "source": [
        "model.compile(optimizer = 'sgd', loss = 'mse')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqLiml0bkQjB"
      },
      "source": [
        "### fit\n",
        "---\n",
        "- fit 메소드를 이용하여 모델 학습 진행\n",
        "- 학습 시 feature, label 값 지정, 그리고 epochs 지정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdPLM35OkcHJ",
        "outputId": "a5af4e04-1d5d-45ba-934d-f3b941c4c233"
      },
      "source": [
        "model.fit(xs,ys, epochs = 1200, verbose = 0)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb6f6c3a590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiTyJ5LVkf2y"
      },
      "source": [
        "### Predict\n",
        "---\n",
        "잘 학습되었는지 검증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60LbGJWckmKn",
        "outputId": "4a0b54ea-07b2-4669-c655-ad2023a75aea"
      },
      "source": [
        "# output\n",
        "# 16.000046\n",
        "model.predict([10.0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[16.000046]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmyWoPyIkquM"
      },
      "source": [
        "## 선형 회귀 구현(Keras)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YujjpF7Vk1GU"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import optimizers\n",
        "import numpy as np"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CpcK8fwlCpU"
      },
      "source": [
        "X=[1,2,3,4,5,6,7,8,9] # 공부하는 시간\n",
        "y=[11,22,33,44,53,66,77,87,95] # 각 공부하는 시간에 맵핑되는 성적"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufpcrba6lDNj",
        "outputId": "e94bbb18-a0a5-4f6d-d065-5d543db62c21"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(units = 1, activation = 'linear'))\n",
        "sgd = optimizers.SGD(lr = 0.01)\n",
        "model.compile(optimizer = sgd, loss = 'mse', metrics = ['mse'])\n",
        "model.fit(X,y,epochs = 300, shuffle=False)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 2940.3147 - mse: 2940.3147\n",
            "Epoch 2/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 362.7996 - mse: 362.7996\n",
            "Epoch 3/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 45.6551 - mse: 45.6551\n",
            "Epoch 4/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.6321 - mse: 6.6321\n",
            "Epoch 5/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8300 - mse: 1.8300\n",
            "Epoch 6/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2384 - mse: 1.2384\n",
            "Epoch 7/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1649 - mse: 1.1649\n",
            "Epoch 8/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1552 - mse: 1.1552\n",
            "Epoch 9/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1533 - mse: 1.1533\n",
            "Epoch 10/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1524 - mse: 1.1524\n",
            "Epoch 11/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1517 - mse: 1.1517\n",
            "Epoch 12/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1509 - mse: 1.1509\n",
            "Epoch 13/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1502 - mse: 1.1502\n",
            "Epoch 14/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1494 - mse: 1.1494\n",
            "Epoch 15/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1487 - mse: 1.1487\n",
            "Epoch 16/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1480 - mse: 1.1480\n",
            "Epoch 17/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.1472 - mse: 1.1472\n",
            "Epoch 18/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1465 - mse: 1.1465\n",
            "Epoch 19/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1458 - mse: 1.1458\n",
            "Epoch 20/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1451 - mse: 1.1451\n",
            "Epoch 21/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1444 - mse: 1.1444\n",
            "Epoch 22/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1437 - mse: 1.1437\n",
            "Epoch 23/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1430 - mse: 1.1430\n",
            "Epoch 24/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1423 - mse: 1.1423\n",
            "Epoch 25/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1417 - mse: 1.1417\n",
            "Epoch 26/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1410 - mse: 1.1410\n",
            "Epoch 27/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1403 - mse: 1.1403\n",
            "Epoch 28/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1397 - mse: 1.1397\n",
            "Epoch 29/300\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.1390 - mse: 1.1390\n",
            "Epoch 30/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1384 - mse: 1.1384\n",
            "Epoch 31/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1377 - mse: 1.1377\n",
            "Epoch 32/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1371 - mse: 1.1371\n",
            "Epoch 33/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1365 - mse: 1.1365\n",
            "Epoch 34/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1358 - mse: 1.1358\n",
            "Epoch 35/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1352 - mse: 1.1352\n",
            "Epoch 36/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1346 - mse: 1.1346\n",
            "Epoch 37/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1340 - mse: 1.1340\n",
            "Epoch 38/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1334 - mse: 1.1334\n",
            "Epoch 39/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1328 - mse: 1.1328\n",
            "Epoch 40/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1322 - mse: 1.1322\n",
            "Epoch 41/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1316 - mse: 1.1316\n",
            "Epoch 42/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1310 - mse: 1.1310\n",
            "Epoch 43/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1304 - mse: 1.1304\n",
            "Epoch 44/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1298 - mse: 1.1298\n",
            "Epoch 45/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1292 - mse: 1.1292\n",
            "Epoch 46/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1287 - mse: 1.1287\n",
            "Epoch 47/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1281 - mse: 1.1281\n",
            "Epoch 48/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1276 - mse: 1.1276\n",
            "Epoch 49/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1270 - mse: 1.1270\n",
            "Epoch 50/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1265 - mse: 1.1265\n",
            "Epoch 51/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1259 - mse: 1.1259\n",
            "Epoch 52/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1254 - mse: 1.1254\n",
            "Epoch 53/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1248 - mse: 1.1248\n",
            "Epoch 54/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1243 - mse: 1.1243\n",
            "Epoch 55/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1238 - mse: 1.1238\n",
            "Epoch 56/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1232 - mse: 1.1232\n",
            "Epoch 57/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1227 - mse: 1.1227\n",
            "Epoch 58/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1222 - mse: 1.1222\n",
            "Epoch 59/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1217 - mse: 1.1217\n",
            "Epoch 60/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1212 - mse: 1.1212\n",
            "Epoch 61/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1207 - mse: 1.1207\n",
            "Epoch 62/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1202 - mse: 1.1202\n",
            "Epoch 63/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1197 - mse: 1.1197\n",
            "Epoch 64/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1192 - mse: 1.1192\n",
            "Epoch 65/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1187 - mse: 1.1187\n",
            "Epoch 66/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1182 - mse: 1.1182\n",
            "Epoch 67/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1178 - mse: 1.1178\n",
            "Epoch 68/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1173 - mse: 1.1173\n",
            "Epoch 69/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1168 - mse: 1.1168\n",
            "Epoch 70/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1163 - mse: 1.1163\n",
            "Epoch 71/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1159 - mse: 1.1159\n",
            "Epoch 72/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1154 - mse: 1.1154\n",
            "Epoch 73/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1150 - mse: 1.1150\n",
            "Epoch 74/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1145 - mse: 1.1145\n",
            "Epoch 75/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1141 - mse: 1.1141\n",
            "Epoch 76/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1136 - mse: 1.1136\n",
            "Epoch 77/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1132 - mse: 1.1132\n",
            "Epoch 78/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1127 - mse: 1.1127\n",
            "Epoch 79/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1123 - mse: 1.1123\n",
            "Epoch 80/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1119 - mse: 1.1119\n",
            "Epoch 81/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1115 - mse: 1.1115\n",
            "Epoch 82/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1110 - mse: 1.1110\n",
            "Epoch 83/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1106 - mse: 1.1106\n",
            "Epoch 84/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1102 - mse: 1.1102\n",
            "Epoch 85/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1098 - mse: 1.1098\n",
            "Epoch 86/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1094 - mse: 1.1094\n",
            "Epoch 87/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1090 - mse: 1.1090\n",
            "Epoch 88/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1086 - mse: 1.1086\n",
            "Epoch 89/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1082 - mse: 1.1082\n",
            "Epoch 90/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1078 - mse: 1.1078\n",
            "Epoch 91/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1074 - mse: 1.1074\n",
            "Epoch 92/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1070 - mse: 1.1070\n",
            "Epoch 93/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1066 - mse: 1.1066\n",
            "Epoch 94/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1062 - mse: 1.1062\n",
            "Epoch 95/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1058 - mse: 1.1058\n",
            "Epoch 96/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1055 - mse: 1.1055\n",
            "Epoch 97/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1051 - mse: 1.1051\n",
            "Epoch 98/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1047 - mse: 1.1047\n",
            "Epoch 99/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1044 - mse: 1.1044\n",
            "Epoch 100/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1040 - mse: 1.1040\n",
            "Epoch 101/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1036 - mse: 1.1036\n",
            "Epoch 102/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1033 - mse: 1.1033\n",
            "Epoch 103/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1029 - mse: 1.1029\n",
            "Epoch 104/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1026 - mse: 1.1026\n",
            "Epoch 105/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1022 - mse: 1.1022\n",
            "Epoch 106/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1019 - mse: 1.1019\n",
            "Epoch 107/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1015 - mse: 1.1015\n",
            "Epoch 108/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1012 - mse: 1.1012\n",
            "Epoch 109/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1008 - mse: 1.1008\n",
            "Epoch 110/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1005 - mse: 1.1005\n",
            "Epoch 111/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1002 - mse: 1.1002\n",
            "Epoch 112/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0998 - mse: 1.0998\n",
            "Epoch 113/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0995 - mse: 1.0995\n",
            "Epoch 114/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0992 - mse: 1.0992\n",
            "Epoch 115/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0989 - mse: 1.0989\n",
            "Epoch 116/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0985 - mse: 1.0985\n",
            "Epoch 117/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0982 - mse: 1.0982\n",
            "Epoch 118/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0979 - mse: 1.0979\n",
            "Epoch 119/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0976 - mse: 1.0976\n",
            "Epoch 120/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0973 - mse: 1.0973\n",
            "Epoch 121/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0970 - mse: 1.0970\n",
            "Epoch 122/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0967 - mse: 1.0967\n",
            "Epoch 123/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0964 - mse: 1.0964\n",
            "Epoch 124/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0961 - mse: 1.0961\n",
            "Epoch 125/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0958 - mse: 1.0958\n",
            "Epoch 126/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0955 - mse: 1.0955\n",
            "Epoch 127/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0952 - mse: 1.0952\n",
            "Epoch 128/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0949 - mse: 1.0949\n",
            "Epoch 129/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0946 - mse: 1.0946\n",
            "Epoch 130/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0943 - mse: 1.0943\n",
            "Epoch 131/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0941 - mse: 1.0941\n",
            "Epoch 132/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0938 - mse: 1.0938\n",
            "Epoch 133/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0935 - mse: 1.0935\n",
            "Epoch 134/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0932 - mse: 1.0932\n",
            "Epoch 135/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0929 - mse: 1.0929\n",
            "Epoch 136/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0927 - mse: 1.0927\n",
            "Epoch 137/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0924 - mse: 1.0924\n",
            "Epoch 138/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0921 - mse: 1.0921\n",
            "Epoch 139/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0919 - mse: 1.0919\n",
            "Epoch 140/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0916 - mse: 1.0916\n",
            "Epoch 141/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0914 - mse: 1.0914\n",
            "Epoch 142/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0911 - mse: 1.0911\n",
            "Epoch 143/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0908 - mse: 1.0908\n",
            "Epoch 144/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0906 - mse: 1.0906\n",
            "Epoch 145/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0903 - mse: 1.0903\n",
            "Epoch 146/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0901 - mse: 1.0901\n",
            "Epoch 147/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0898 - mse: 1.0898\n",
            "Epoch 148/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0896 - mse: 1.0896\n",
            "Epoch 149/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0893 - mse: 1.0893\n",
            "Epoch 150/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0891 - mse: 1.0891\n",
            "Epoch 151/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0889 - mse: 1.0889\n",
            "Epoch 152/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0886 - mse: 1.0886\n",
            "Epoch 153/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0884 - mse: 1.0884\n",
            "Epoch 154/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0882 - mse: 1.0882\n",
            "Epoch 155/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0879 - mse: 1.0879\n",
            "Epoch 156/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0877 - mse: 1.0877\n",
            "Epoch 157/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0875 - mse: 1.0875\n",
            "Epoch 158/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0872 - mse: 1.0872\n",
            "Epoch 159/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0870 - mse: 1.0870\n",
            "Epoch 160/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0868 - mse: 1.0868\n",
            "Epoch 161/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0866 - mse: 1.0866\n",
            "Epoch 162/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0864 - mse: 1.0864\n",
            "Epoch 163/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0861 - mse: 1.0861\n",
            "Epoch 164/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0859 - mse: 1.0859\n",
            "Epoch 165/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0857 - mse: 1.0857\n",
            "Epoch 166/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0855 - mse: 1.0855\n",
            "Epoch 167/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0853 - mse: 1.0853\n",
            "Epoch 168/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0851 - mse: 1.0851\n",
            "Epoch 169/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0849 - mse: 1.0849\n",
            "Epoch 170/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0847 - mse: 1.0847\n",
            "Epoch 171/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0845 - mse: 1.0845\n",
            "Epoch 172/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0843 - mse: 1.0843\n",
            "Epoch 173/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0841 - mse: 1.0841\n",
            "Epoch 174/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0839 - mse: 1.0839\n",
            "Epoch 175/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0837 - mse: 1.0837\n",
            "Epoch 176/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0835 - mse: 1.0835\n",
            "Epoch 177/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0833 - mse: 1.0833\n",
            "Epoch 178/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0831 - mse: 1.0831\n",
            "Epoch 179/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0829 - mse: 1.0829\n",
            "Epoch 180/300\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0827 - mse: 1.0827\n",
            "Epoch 181/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0825 - mse: 1.0825\n",
            "Epoch 182/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0823 - mse: 1.0823\n",
            "Epoch 183/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0821 - mse: 1.0821\n",
            "Epoch 184/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0820 - mse: 1.0820\n",
            "Epoch 185/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0818 - mse: 1.0818\n",
            "Epoch 186/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0816 - mse: 1.0816\n",
            "Epoch 187/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0814 - mse: 1.0814\n",
            "Epoch 188/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0813 - mse: 1.0813\n",
            "Epoch 189/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0811 - mse: 1.0811\n",
            "Epoch 190/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0809 - mse: 1.0809\n",
            "Epoch 191/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0807 - mse: 1.0807\n",
            "Epoch 192/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0806 - mse: 1.0806\n",
            "Epoch 193/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0804 - mse: 1.0804\n",
            "Epoch 194/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0802 - mse: 1.0802\n",
            "Epoch 195/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0801 - mse: 1.0801\n",
            "Epoch 196/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0799 - mse: 1.0799\n",
            "Epoch 197/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0797 - mse: 1.0797\n",
            "Epoch 198/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0796 - mse: 1.0796\n",
            "Epoch 199/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0794 - mse: 1.0794\n",
            "Epoch 200/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0792 - mse: 1.0792\n",
            "Epoch 201/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0791 - mse: 1.0791\n",
            "Epoch 202/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0789 - mse: 1.0789\n",
            "Epoch 203/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0788 - mse: 1.0788\n",
            "Epoch 204/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0786 - mse: 1.0786\n",
            "Epoch 205/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0785 - mse: 1.0785\n",
            "Epoch 206/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0783 - mse: 1.0783\n",
            "Epoch 207/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0782 - mse: 1.0782\n",
            "Epoch 208/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0780 - mse: 1.0780\n",
            "Epoch 209/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0779 - mse: 1.0779\n",
            "Epoch 210/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0777 - mse: 1.0777\n",
            "Epoch 211/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0776 - mse: 1.0776\n",
            "Epoch 212/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0774 - mse: 1.0774\n",
            "Epoch 213/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0773 - mse: 1.0773\n",
            "Epoch 214/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0771 - mse: 1.0771\n",
            "Epoch 215/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0770 - mse: 1.0770\n",
            "Epoch 216/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0769 - mse: 1.0769\n",
            "Epoch 217/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0767 - mse: 1.0767\n",
            "Epoch 218/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0766 - mse: 1.0766\n",
            "Epoch 219/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0764 - mse: 1.0764\n",
            "Epoch 220/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0763 - mse: 1.0763\n",
            "Epoch 221/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0762 - mse: 1.0762\n",
            "Epoch 222/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0760 - mse: 1.0760\n",
            "Epoch 223/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0759 - mse: 1.0759\n",
            "Epoch 224/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0758 - mse: 1.0758\n",
            "Epoch 225/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0756 - mse: 1.0756\n",
            "Epoch 226/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0755 - mse: 1.0755\n",
            "Epoch 227/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0754 - mse: 1.0754\n",
            "Epoch 228/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0753 - mse: 1.0753\n",
            "Epoch 229/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0751 - mse: 1.0751\n",
            "Epoch 230/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0750 - mse: 1.0750\n",
            "Epoch 231/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0749 - mse: 1.0749\n",
            "Epoch 232/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0748 - mse: 1.0748\n",
            "Epoch 233/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0746 - mse: 1.0746\n",
            "Epoch 234/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0745 - mse: 1.0745\n",
            "Epoch 235/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0744 - mse: 1.0744\n",
            "Epoch 236/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0743 - mse: 1.0743\n",
            "Epoch 237/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0742 - mse: 1.0742\n",
            "Epoch 238/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0740 - mse: 1.0740\n",
            "Epoch 239/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0739 - mse: 1.0739\n",
            "Epoch 240/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0738 - mse: 1.0738\n",
            "Epoch 241/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0737 - mse: 1.0737\n",
            "Epoch 242/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0736 - mse: 1.0736\n",
            "Epoch 243/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0735 - mse: 1.0735\n",
            "Epoch 244/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0734 - mse: 1.0734\n",
            "Epoch 245/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0732 - mse: 1.0732\n",
            "Epoch 246/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0731 - mse: 1.0731\n",
            "Epoch 247/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0730 - mse: 1.0730\n",
            "Epoch 248/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0729 - mse: 1.0729\n",
            "Epoch 249/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0728 - mse: 1.0728\n",
            "Epoch 250/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0727 - mse: 1.0727\n",
            "Epoch 251/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0726 - mse: 1.0726\n",
            "Epoch 252/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0725 - mse: 1.0725\n",
            "Epoch 253/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0724 - mse: 1.0724\n",
            "Epoch 254/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0723 - mse: 1.0723\n",
            "Epoch 255/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0722 - mse: 1.0722\n",
            "Epoch 256/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0721 - mse: 1.0721\n",
            "Epoch 257/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0720 - mse: 1.0720\n",
            "Epoch 258/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0719 - mse: 1.0719\n",
            "Epoch 259/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0718 - mse: 1.0718\n",
            "Epoch 260/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0717 - mse: 1.0717\n",
            "Epoch 261/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0716 - mse: 1.0716\n",
            "Epoch 262/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0715 - mse: 1.0715\n",
            "Epoch 263/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0714 - mse: 1.0714\n",
            "Epoch 264/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0713 - mse: 1.0713\n",
            "Epoch 265/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0712 - mse: 1.0712\n",
            "Epoch 266/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0711 - mse: 1.0711\n",
            "Epoch 267/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0710 - mse: 1.0710\n",
            "Epoch 268/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0709 - mse: 1.0709\n",
            "Epoch 269/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0708 - mse: 1.0708\n",
            "Epoch 270/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0708 - mse: 1.0708\n",
            "Epoch 271/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0707 - mse: 1.0707\n",
            "Epoch 272/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0706 - mse: 1.0706\n",
            "Epoch 273/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0705 - mse: 1.0705\n",
            "Epoch 274/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0704 - mse: 1.0704\n",
            "Epoch 275/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0703 - mse: 1.0703\n",
            "Epoch 276/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0702 - mse: 1.0702\n",
            "Epoch 277/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0701 - mse: 1.0701\n",
            "Epoch 278/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0701 - mse: 1.0701\n",
            "Epoch 279/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0700 - mse: 1.0700\n",
            "Epoch 280/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0699 - mse: 1.0699\n",
            "Epoch 281/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0698 - mse: 1.0698\n",
            "Epoch 282/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0697 - mse: 1.0697\n",
            "Epoch 283/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0697 - mse: 1.0697\n",
            "Epoch 284/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0696 - mse: 1.0696\n",
            "Epoch 285/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0695 - mse: 1.0695\n",
            "Epoch 286/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0694 - mse: 1.0694\n",
            "Epoch 287/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0693 - mse: 1.0693\n",
            "Epoch 288/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0693 - mse: 1.0693\n",
            "Epoch 289/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0692 - mse: 1.0692\n",
            "Epoch 290/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0691 - mse: 1.0691\n",
            "Epoch 291/300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0690 - mse: 1.0690\n",
            "Epoch 292/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0690 - mse: 1.0690\n",
            "Epoch 293/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0689 - mse: 1.0689\n",
            "Epoch 294/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0688 - mse: 1.0688\n",
            "Epoch 295/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0687 - mse: 1.0687\n",
            "Epoch 296/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0687 - mse: 1.0687\n",
            "Epoch 297/300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0686 - mse: 1.0686\n",
            "Epoch 298/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0685 - mse: 1.0685\n",
            "Epoch 299/300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0685 - mse: 1.0685\n",
            "Epoch 300/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0684 - mse: 1.0684\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb6ee91c710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "UphJrBOGlhGB",
        "outputId": "69f83fcf-1798-4eb3-b372-23d573f14573"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(X,model.predict(X),'b',X,y,'k.')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb6ecee9e10>,\n",
              " <matplotlib.lines.Line2D at 0x7fb6ecee9fd0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuVAePxylw3s"
      },
      "source": [
        "## 선형 회귀 구현(Tage 버전)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoVcccWRm09D"
      },
      "source": [
        "### 자동 미분 설명"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTr7oIvImBGa"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNhu-pJ5mC-E"
      },
      "source": [
        "자동 미분을 수행하는 tape_gradient() 메소드 활용   \n",
        "이해를 위해 우선 2w^2 + 5라는 식을 세워보고, w에 대해 미분"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrKSi1BImPJm"
      },
      "source": [
        "w = tf.Variable(2.)\n",
        "\n",
        "def f(w):\n",
        "  y = w**2\n",
        "  return 2*y+5"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b1zaOkwmVF7",
        "outputId": "9b988079-1296-4873-fc7c-b2db50f94f33"
      },
      "source": [
        "with tf.GradientTape() as tape:\n",
        "  z = f(w)\n",
        "gradients = tape.gradient(z,[w])\n",
        "print(gradients)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Tensor: shape=(), dtype=float32, numpy=8.0>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EO2kT6rm28k"
      },
      "source": [
        "- with wf.GradientTape()을 할 경우, 해당 with문이 내에서 수행 시 모든 연산을 기록\n",
        "- tape.gradient(z,[w])는 연산 기록을 토대로 z를 w에 대해 미분\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_IVIh-_moZO"
      },
      "source": [
        "### Tape로 선형회귀 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-AKCOVmnH7a"
      },
      "source": [
        "X=[1,2,3,4,5,6,7,8,9] # 공부하는 시간\n",
        "y=[11,22,33,44,53,66,77,87,95] # 각 공부하는 시간에 맵핑되는 성적"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Crge-MgnJIe",
        "outputId": "1a2481c2-8727-4198-f7cc-97451c07894b"
      },
      "source": [
        "# 훈련 가중치 선언\n",
        "W = tf.Variable(tf.random.normal(shape = [1]))\n",
        "b = tf.Variable(tf.random.normal(shape = [1]))\n",
        "print(W)\n",
        "print(b)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.09368575], dtype=float32)>\n",
            "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([-0.36977583], dtype=float32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6qivjqLna9o"
      },
      "source": [
        "@tf.function\n",
        "def hypothesis(x):\n",
        "  return W*x + b"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ski9reU5nf9x",
        "outputId": "162cef4c-879d-4840-c1e8-d614cd9f1cc7"
      },
      "source": [
        "# 테스트를 위한 입력값을 준비합니다.\n",
        "x_test = [3.5, 5, 5.5, 6]\n",
        "# 테스트 데이터를 이용해 학습된 선형회귀 모델이 데이터의 경향성(y=10.6x)을 잘 학습했는지 측정합니다.\n",
        "print(hypothesis(x_test).numpy())"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.04187569  0.09865293  0.14549583  0.1923387 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_FzXmntnsG_"
      },
      "source": [
        "#손실함수 정의\n",
        "#MSE_loss mean((y-y')^2)\n",
        "@tf.function\n",
        "def mse_loss(y_pred, y):\n",
        "  return tf.reduce_mean(tf.square(y_pred-y))"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r2lsCngoBqf",
        "outputId": "f1d65e52-1fc7-43fa-d770-c58399c3632b"
      },
      "source": [
        "optimizer = tf.optimizers.SGD(learning_rate = 0.01)\n",
        "for i in range(1000):\n",
        "  with tf.GradientTape() as tape:\n",
        "    y_pred = hypothesis(X)\n",
        "    cost = mse_loss(y_pred,y)\n",
        "  gradients = tape.gradient(cost,[W,b])\n",
        "  optimizer.apply_gradients(zip(gradients,[W,b]))\n",
        "  if (i+1)%100 == 0:\n",
        "    print(f\"epoch : {i+1} | W의 값 : {(W.numpy())} | b의 값 : {b.numpy()} | cost : {cost}\")"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch : 100 | W의 값 : [10.631195] | b의 값 : [1.1336235] | cost : 1.0827279090881348\n",
            "epoch : 200 | W의 값 : [10.648787] | b의 값 : [1.0229318] | cost : 1.0699070692062378\n",
            "epoch : 300 | W의 값 : [10.660443] | b의 값 : [0.9495881] | cost : 1.0642788410186768\n",
            "epoch : 400 | W의 값 : [10.668166] | b의 값 : [0.9009906] | cost : 1.061813235282898\n",
            "epoch : 500 | W의 값 : [10.673284] | b의 값 : [0.8687906] | cost : 1.0607234239578247\n",
            "epoch : 600 | W의 값 : [10.676675] | b의 값 : [0.84745514] | cost : 1.0602529048919678\n",
            "epoch : 700 | W의 값 : [10.678921] | b의 값 : [0.83331794] | cost : 1.0600378513336182\n",
            "epoch : 800 | W의 값 : [10.680409] | b의 값 : [0.82395107] | cost : 1.0599466562271118\n",
            "epoch : 900 | W의 값 : [10.6813965] | b의 값 : [0.8177441] | cost : 1.0599093437194824\n",
            "epoch : 1000 | W의 값 : [10.68205] | b의 값 : [0.81363225] | cost : 1.0598901510238647\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ga3qP2qKo0jy",
        "outputId": "7ab70d42-a139-4c46-c248-17c1cf4a9a10"
      },
      "source": [
        "# 테스트를 위한 입력값을 준비합니다.\n",
        "x_test = [3.5, 5, 5.5, 6, 9.5]\n",
        "# 테스트 데이터를 이용해 학습된 선형회귀 모델이 데이터의 경향성(y=10.6x)을 잘 학습했는지 측정합니다.\n",
        "\n",
        "print(hypothesis(x_test).numpy())"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 38.200806  54.22388   59.564907  64.90593  102.2931  ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEfcTfGQr94N"
      },
      "source": [
        "## 로지스틱 회귀 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ye_FWF4It0li",
        "outputId": "36037350-20b3-49a1-f453-5d4d99ec6d40"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "# X의 입력이 10부터 y의 출력이 1이 되도록 설계된 데이터\n",
        "X = np.array([-50, -40, -30, -20, -10, -5, 0, 5, 10, 20, 30, 40, 50])\n",
        "y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "sgd = optimizers.SGD(learning_rate = 0.01)\n",
        "model.compile(optimizer = sgd, loss = 'binary_crossentropy',metrics = ['binary_crossentropy'])\n",
        "model.fit(X,y,epochs = 200, shuffle = False)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 36.6157 - binary_crossentropy: 36.6157\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 31.1114 - binary_crossentropy: 31.1114\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 25.6075 - binary_crossentropy: 25.6075\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 20.1052 - binary_crossentropy: 20.1052\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 14.6081 - binary_crossentropy: 14.6081\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.1291 - binary_crossentropy: 9.1291\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7294 - binary_crossentropy: 3.7294\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2790 - binary_crossentropy: 0.2790\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2497 - binary_crossentropy: 0.2497\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2365 - binary_crossentropy: 0.2365\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2284 - binary_crossentropy: 0.2284\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2229 - binary_crossentropy: 0.2229\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2189 - binary_crossentropy: 0.2189\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2158 - binary_crossentropy: 0.2158\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2133 - binary_crossentropy: 0.2133\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2112 - binary_crossentropy: 0.2112\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2095 - binary_crossentropy: 0.2095\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2081 - binary_crossentropy: 0.2081\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2068 - binary_crossentropy: 0.2068\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2058 - binary_crossentropy: 0.2058\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2048 - binary_crossentropy: 0.2048\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2040 - binary_crossentropy: 0.2040\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2032 - binary_crossentropy: 0.2032\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2026 - binary_crossentropy: 0.2026\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2020 - binary_crossentropy: 0.2020\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2014 - binary_crossentropy: 0.2014\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2009 - binary_crossentropy: 0.2009\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2004 - binary_crossentropy: 0.2004\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2000 - binary_crossentropy: 0.2000\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1996 - binary_crossentropy: 0.1996\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1992 - binary_crossentropy: 0.1992\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1989 - binary_crossentropy: 0.1989\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1985 - binary_crossentropy: 0.1985\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1982 - binary_crossentropy: 0.1982\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1979 - binary_crossentropy: 0.1979\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1977 - binary_crossentropy: 0.1977\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1974 - binary_crossentropy: 0.1974\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1971 - binary_crossentropy: 0.1971\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1969 - binary_crossentropy: 0.1969\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1967 - binary_crossentropy: 0.1967\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1965 - binary_crossentropy: 0.1965\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1962 - binary_crossentropy: 0.1962\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1960 - binary_crossentropy: 0.1960\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1958 - binary_crossentropy: 0.1958\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1956 - binary_crossentropy: 0.1956\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1954 - binary_crossentropy: 0.1954\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1953 - binary_crossentropy: 0.1953\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1951 - binary_crossentropy: 0.1951\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1949 - binary_crossentropy: 0.1949\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1947 - binary_crossentropy: 0.1947\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1946 - binary_crossentropy: 0.1946\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1944 - binary_crossentropy: 0.1944\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1942 - binary_crossentropy: 0.1942\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1941 - binary_crossentropy: 0.1941\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1939 - binary_crossentropy: 0.1939\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1938 - binary_crossentropy: 0.1938\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1936 - binary_crossentropy: 0.1936\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1935 - binary_crossentropy: 0.1935\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1933 - binary_crossentropy: 0.1933\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1932 - binary_crossentropy: 0.1932\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1930 - binary_crossentropy: 0.1930\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1929 - binary_crossentropy: 0.1929\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1927 - binary_crossentropy: 0.1927\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1926 - binary_crossentropy: 0.1926\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1925 - binary_crossentropy: 0.1925\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1923 - binary_crossentropy: 0.1923\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1922 - binary_crossentropy: 0.1922\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1921 - binary_crossentropy: 0.1921\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1919 - binary_crossentropy: 0.1919\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1918 - binary_crossentropy: 0.1918\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1917 - binary_crossentropy: 0.1917\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1915 - binary_crossentropy: 0.1915\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1914 - binary_crossentropy: 0.1914\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1913 - binary_crossentropy: 0.1913\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1911 - binary_crossentropy: 0.1911\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1910 - binary_crossentropy: 0.1910\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1909 - binary_crossentropy: 0.1909\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1908 - binary_crossentropy: 0.1908\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1906 - binary_crossentropy: 0.1906\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1905 - binary_crossentropy: 0.1905\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1904 - binary_crossentropy: 0.1904\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1903 - binary_crossentropy: 0.1903\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1901 - binary_crossentropy: 0.1901\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1900 - binary_crossentropy: 0.1900\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1899 - binary_crossentropy: 0.1899\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1898 - binary_crossentropy: 0.1898\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1896 - binary_crossentropy: 0.1896\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1895 - binary_crossentropy: 0.1895\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1894 - binary_crossentropy: 0.1894\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1893 - binary_crossentropy: 0.1893\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1892 - binary_crossentropy: 0.1892\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1890 - binary_crossentropy: 0.1890\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1889 - binary_crossentropy: 0.1889\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1888 - binary_crossentropy: 0.1888\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1887 - binary_crossentropy: 0.1887\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1886 - binary_crossentropy: 0.1886\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1884 - binary_crossentropy: 0.1884\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1883 - binary_crossentropy: 0.1883\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1882 - binary_crossentropy: 0.1882\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1881 - binary_crossentropy: 0.1881\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1880 - binary_crossentropy: 0.1880\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1878 - binary_crossentropy: 0.1878\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1877 - binary_crossentropy: 0.1877\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1876 - binary_crossentropy: 0.1876\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1875 - binary_crossentropy: 0.1875\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1874 - binary_crossentropy: 0.1874\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1872 - binary_crossentropy: 0.1872\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1871 - binary_crossentropy: 0.1871\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1870 - binary_crossentropy: 0.1870\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1869 - binary_crossentropy: 0.1869\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1868 - binary_crossentropy: 0.1868\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1867 - binary_crossentropy: 0.1867\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1865 - binary_crossentropy: 0.1865\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1864 - binary_crossentropy: 0.1864\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1863 - binary_crossentropy: 0.1863\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1862 - binary_crossentropy: 0.1862\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1861 - binary_crossentropy: 0.1861\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1860 - binary_crossentropy: 0.1860\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1859 - binary_crossentropy: 0.1859\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1857 - binary_crossentropy: 0.1857\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1856 - binary_crossentropy: 0.1856\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1855 - binary_crossentropy: 0.1855\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1854 - binary_crossentropy: 0.1854\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1853 - binary_crossentropy: 0.1853\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1852 - binary_crossentropy: 0.1852\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1851 - binary_crossentropy: 0.1851\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1849 - binary_crossentropy: 0.1849\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1848 - binary_crossentropy: 0.1848\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1847 - binary_crossentropy: 0.1847\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1846 - binary_crossentropy: 0.1846\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1845 - binary_crossentropy: 0.1845\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1844 - binary_crossentropy: 0.1844\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1843 - binary_crossentropy: 0.1843\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1841 - binary_crossentropy: 0.1841\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1840 - binary_crossentropy: 0.1840\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1839 - binary_crossentropy: 0.1839\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1838 - binary_crossentropy: 0.1838\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1837 - binary_crossentropy: 0.1837\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1836 - binary_crossentropy: 0.1836\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1835 - binary_crossentropy: 0.1835\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1834 - binary_crossentropy: 0.1834\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1832 - binary_crossentropy: 0.1832\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1831 - binary_crossentropy: 0.1831\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1830 - binary_crossentropy: 0.1830\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1829 - binary_crossentropy: 0.1829\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1828 - binary_crossentropy: 0.1828\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1827 - binary_crossentropy: 0.1827\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1826 - binary_crossentropy: 0.1826\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1825 - binary_crossentropy: 0.1825\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1824 - binary_crossentropy: 0.1824\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1823 - binary_crossentropy: 0.1823\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1821 - binary_crossentropy: 0.1821\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1820 - binary_crossentropy: 0.1820\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1819 - binary_crossentropy: 0.1819\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1818 - binary_crossentropy: 0.1818\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1817 - binary_crossentropy: 0.1817\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1816 - binary_crossentropy: 0.1816\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1815 - binary_crossentropy: 0.1815\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1814 - binary_crossentropy: 0.1814\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1813 - binary_crossentropy: 0.1813\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1812 - binary_crossentropy: 0.1812\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1810 - binary_crossentropy: 0.1810\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1809 - binary_crossentropy: 0.1809\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1808 - binary_crossentropy: 0.1808\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1807 - binary_crossentropy: 0.1807\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1806 - binary_crossentropy: 0.1806\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1805 - binary_crossentropy: 0.1805\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1804 - binary_crossentropy: 0.1804\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1803 - binary_crossentropy: 0.1803\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1802 - binary_crossentropy: 0.1802\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1801 - binary_crossentropy: 0.1801\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1800 - binary_crossentropy: 0.1800\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1799 - binary_crossentropy: 0.1799\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1798 - binary_crossentropy: 0.1798\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.1796 - binary_crossentropy: 0.1796\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1795 - binary_crossentropy: 0.1795\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1794 - binary_crossentropy: 0.1794\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1793 - binary_crossentropy: 0.1793\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1792 - binary_crossentropy: 0.1792\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1791 - binary_crossentropy: 0.1791\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1790 - binary_crossentropy: 0.1790\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1789 - binary_crossentropy: 0.1789\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1788 - binary_crossentropy: 0.1788\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1787 - binary_crossentropy: 0.1787\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1786 - binary_crossentropy: 0.1786\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1785 - binary_crossentropy: 0.1785\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1784 - binary_crossentropy: 0.1784\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1783 - binary_crossentropy: 0.1783\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1782 - binary_crossentropy: 0.1782\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1781 - binary_crossentropy: 0.1781\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1780 - binary_crossentropy: 0.1780\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1778 - binary_crossentropy: 0.1778\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1777 - binary_crossentropy: 0.1777\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1776 - binary_crossentropy: 0.1776\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1775 - binary_crossentropy: 0.1775\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1774 - binary_crossentropy: 0.1774\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1773 - binary_crossentropy: 0.1773\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1772 - binary_crossentropy: 0.1772\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1771 - binary_crossentropy: 0.1771\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1770 - binary_crossentropy: 0.1770\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb6f41f85d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "lLvw-Ss2u3qY",
        "outputId": "8a31bb32-1a71-4bae-a965-e7af47ce6696"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(X, model.predict(X), 'b', X,y, 'k.')"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb6f41694d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb6f425e290>,\n",
              " <matplotlib.lines.Line2D at 0x7fb6f425e210>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qt2-tdEyu7um"
      },
      "source": [
        "## 다중 선형 회귀 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz8nxN8VwZrO"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import optimizers"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJkY1msXwqK8",
        "outputId": "af5ad121-d167-4e07-d70d-3064e0fe9024"
      },
      "source": [
        "# 입력 벡터의 차원은 3입니다. 즉, input_dim은 3입니다.\n",
        "X = np.array([[70,85,11],[71,89,18],[50,80,20],[99,20,10],[50,10,10]]) # 중간, 기말, 가산점\n",
        "# 출력 벡터의 차원은 1입니다. 즉, output_dim은 1입니다.\n",
        "y = np.array([73,82,72,57,34]) # 최종 성적\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(units = 1, input_shape = (3,), activation = 'linear'))\n",
        "optimizer = optimizers.SGD(learning_rate=0.00001)\n",
        "model.compile(optimizer = optimizer, loss = ['mse'], metrics = ['mse'])\n",
        "model.fit(X,y,epochs = 500, batch_size = 1, shuffle = False)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 2577.8972 - mse: 2577.8972\n",
            "Epoch 2/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 456.0607 - mse: 456.0607\n",
            "Epoch 3/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 189.3710 - mse: 189.3710\n",
            "Epoch 4/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 150.8535 - mse: 150.8535\n",
            "Epoch 5/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 134.9400 - mse: 134.9400\n",
            "Epoch 6/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 120.6479 - mse: 120.6479\n",
            "Epoch 7/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 107.5127 - mse: 107.5127\n",
            "Epoch 8/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 96.0818 - mse: 96.0818\n",
            "Epoch 9/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 86.4300 - mse: 86.4300\n",
            "Epoch 10/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 78.3879 - mse: 78.3879\n",
            "Epoch 11/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 71.7216 - mse: 71.7216\n",
            "Epoch 12/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 66.2034 - mse: 66.2034\n",
            "Epoch 13/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 61.6341 - mse: 61.6341\n",
            "Epoch 14/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 57.8458 - mse: 57.8458\n",
            "Epoch 15/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 54.6993 - mse: 54.6993\n",
            "Epoch 16/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 52.0802 - mse: 52.0802\n",
            "Epoch 17/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 49.8942 - mse: 49.8942\n",
            "Epoch 18/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 48.0644 - mse: 48.0644\n",
            "Epoch 19/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 46.5274 - mse: 46.5274\n",
            "Epoch 20/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 45.2313 - mse: 45.2313\n",
            "Epoch 21/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 44.1336 - mse: 44.1336\n",
            "Epoch 22/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 43.1993 - mse: 43.1993\n",
            "Epoch 23/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 42.3997 - mse: 42.3997\n",
            "Epoch 24/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 41.7115 - mse: 41.7115\n",
            "Epoch 25/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 41.1152 - mse: 41.1152\n",
            "Epoch 26/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 40.5948 - mse: 40.5948\n",
            "Epoch 27/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 40.1375 - mse: 40.1375\n",
            "Epoch 28/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 39.7323 - mse: 39.7323\n",
            "Epoch 29/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 39.3706 - mse: 39.3706\n",
            "Epoch 30/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 39.0448 - mse: 39.0448\n",
            "Epoch 31/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 38.7492 - mse: 38.7492\n",
            "Epoch 32/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 38.4786 - mse: 38.4786\n",
            "Epoch 33/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 38.2291 - mse: 38.2291\n",
            "Epoch 34/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 37.9971 - mse: 37.9971\n",
            "Epoch 35/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 37.7800 - mse: 37.7800\n",
            "Epoch 36/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 37.5752 - mse: 37.5752\n",
            "Epoch 37/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 37.3812 - mse: 37.3812\n",
            "Epoch 38/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 37.1959 - mse: 37.1959\n",
            "Epoch 39/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 37.0184 - mse: 37.0184\n",
            "Epoch 40/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 36.8473 - mse: 36.8473\n",
            "Epoch 41/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 36.6818 - mse: 36.6818\n",
            "Epoch 42/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 36.5211 - mse: 36.5211\n",
            "Epoch 43/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 36.3646 - mse: 36.3646\n",
            "Epoch 44/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 36.2117 - mse: 36.2117\n",
            "Epoch 45/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 36.0619 - mse: 36.0619\n",
            "Epoch 46/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 35.9149 - mse: 35.9149\n",
            "Epoch 47/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 35.7703 - mse: 35.7703\n",
            "Epoch 48/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 35.6280 - mse: 35.6280\n",
            "Epoch 49/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 35.4875 - mse: 35.4875\n",
            "Epoch 50/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 35.3487 - mse: 35.3487\n",
            "Epoch 51/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 35.2116 - mse: 35.2116\n",
            "Epoch 52/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 35.0759 - mse: 35.0759\n",
            "Epoch 53/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 34.9414 - mse: 34.9414\n",
            "Epoch 54/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 34.8081 - mse: 34.8081\n",
            "Epoch 55/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 34.6760 - mse: 34.6760\n",
            "Epoch 56/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 34.5448 - mse: 34.5448\n",
            "Epoch 57/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 34.4146 - mse: 34.4146\n",
            "Epoch 58/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 34.2853 - mse: 34.2853\n",
            "Epoch 59/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 34.1569 - mse: 34.1569\n",
            "Epoch 60/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 34.0292 - mse: 34.0292\n",
            "Epoch 61/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 33.9022 - mse: 33.9022\n",
            "Epoch 62/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 33.7760 - mse: 33.7760\n",
            "Epoch 63/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 33.6505 - mse: 33.6505\n",
            "Epoch 64/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 33.5256 - mse: 33.5256\n",
            "Epoch 65/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 33.4014 - mse: 33.4014\n",
            "Epoch 66/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 33.2777 - mse: 33.2777\n",
            "Epoch 67/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 33.1547 - mse: 33.1547\n",
            "Epoch 68/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 33.0322 - mse: 33.0322\n",
            "Epoch 69/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 32.9103 - mse: 32.9103\n",
            "Epoch 70/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 32.7889 - mse: 32.7889\n",
            "Epoch 71/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 32.6681 - mse: 32.6681\n",
            "Epoch 72/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 32.5478 - mse: 32.5478\n",
            "Epoch 73/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 32.4280 - mse: 32.4280\n",
            "Epoch 74/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 32.3087 - mse: 32.3087\n",
            "Epoch 75/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 32.1899 - mse: 32.1899\n",
            "Epoch 76/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 32.0716 - mse: 32.0716\n",
            "Epoch 77/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 31.9538 - mse: 31.9538\n",
            "Epoch 78/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 31.8364 - mse: 31.8364\n",
            "Epoch 79/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 31.7195 - mse: 31.7195\n",
            "Epoch 80/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 31.6031 - mse: 31.6031\n",
            "Epoch 81/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 31.4871 - mse: 31.4871\n",
            "Epoch 82/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 31.3716 - mse: 31.3716\n",
            "Epoch 83/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 31.2565 - mse: 31.2565\n",
            "Epoch 84/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 31.1418 - mse: 31.1418\n",
            "Epoch 85/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 31.0277 - mse: 31.0277\n",
            "Epoch 86/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 30.9139 - mse: 30.9139\n",
            "Epoch 87/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 30.8006 - mse: 30.8006\n",
            "Epoch 88/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 30.6876 - mse: 30.6876\n",
            "Epoch 89/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 30.5752 - mse: 30.5752\n",
            "Epoch 90/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 30.4632 - mse: 30.4632\n",
            "Epoch 91/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 30.3515 - mse: 30.3515\n",
            "Epoch 92/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 30.2403 - mse: 30.2403\n",
            "Epoch 93/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 30.1295 - mse: 30.1295\n",
            "Epoch 94/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 30.0191 - mse: 30.0191\n",
            "Epoch 95/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 29.9091 - mse: 29.9091\n",
            "Epoch 96/500\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 29.7996 - mse: 29.7996\n",
            "Epoch 97/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 29.6905 - mse: 29.6905\n",
            "Epoch 98/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 29.5817 - mse: 29.5817\n",
            "Epoch 99/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 29.4734 - mse: 29.4734\n",
            "Epoch 100/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 29.3654 - mse: 29.3654\n",
            "Epoch 101/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 29.2579 - mse: 29.2579\n",
            "Epoch 102/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 29.1507 - mse: 29.1507\n",
            "Epoch 103/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 29.0440 - mse: 29.0440\n",
            "Epoch 104/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 28.9376 - mse: 28.9376\n",
            "Epoch 105/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 28.8316 - mse: 28.8316\n",
            "Epoch 106/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 28.7261 - mse: 28.7261\n",
            "Epoch 107/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 28.6209 - mse: 28.6209\n",
            "Epoch 108/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 28.5161 - mse: 28.5161\n",
            "Epoch 109/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 28.4116 - mse: 28.4116\n",
            "Epoch 110/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 28.3076 - mse: 28.3076\n",
            "Epoch 111/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 28.2040 - mse: 28.2040\n",
            "Epoch 112/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 28.1007 - mse: 28.1007\n",
            "Epoch 113/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 27.9978 - mse: 27.9978\n",
            "Epoch 114/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 27.8953 - mse: 27.8953\n",
            "Epoch 115/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 27.7932 - mse: 27.7932\n",
            "Epoch 116/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 27.6914 - mse: 27.6914\n",
            "Epoch 117/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 27.5900 - mse: 27.5900\n",
            "Epoch 118/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 27.4890 - mse: 27.4890\n",
            "Epoch 119/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 27.3884 - mse: 27.3884\n",
            "Epoch 120/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 27.2881 - mse: 27.2881\n",
            "Epoch 121/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 27.1882 - mse: 27.1882\n",
            "Epoch 122/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 27.0886 - mse: 27.0886\n",
            "Epoch 123/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 26.9894 - mse: 26.9894\n",
            "Epoch 124/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 26.8906 - mse: 26.8906\n",
            "Epoch 125/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 26.7922 - mse: 26.7922\n",
            "Epoch 126/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 26.6941 - mse: 26.6941\n",
            "Epoch 127/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 26.5964 - mse: 26.5964\n",
            "Epoch 128/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 26.4990 - mse: 26.4990\n",
            "Epoch 129/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 26.4020 - mse: 26.4020\n",
            "Epoch 130/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 26.3053 - mse: 26.3053\n",
            "Epoch 131/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 26.2090 - mse: 26.2090\n",
            "Epoch 132/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 26.1130 - mse: 26.1130\n",
            "Epoch 133/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 26.0175 - mse: 26.0175\n",
            "Epoch 134/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 25.9222 - mse: 25.9222\n",
            "Epoch 135/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 25.8273 - mse: 25.8273\n",
            "Epoch 136/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 25.7327 - mse: 25.7327\n",
            "Epoch 137/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 25.6385 - mse: 25.6385\n",
            "Epoch 138/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 25.5446 - mse: 25.5446\n",
            "Epoch 139/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 25.4511 - mse: 25.4511\n",
            "Epoch 140/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 25.3580 - mse: 25.3580\n",
            "Epoch 141/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 25.2651 - mse: 25.2651\n",
            "Epoch 142/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 25.1726 - mse: 25.1726\n",
            "Epoch 143/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 25.0805 - mse: 25.0805\n",
            "Epoch 144/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 24.9886 - mse: 24.9886\n",
            "Epoch 145/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 24.8972 - mse: 24.8972\n",
            "Epoch 146/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 24.8060 - mse: 24.8060\n",
            "Epoch 147/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 24.7152 - mse: 24.7152\n",
            "Epoch 148/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 24.6247 - mse: 24.6247\n",
            "Epoch 149/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 24.5346 - mse: 24.5346\n",
            "Epoch 150/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 24.4447 - mse: 24.4447\n",
            "Epoch 151/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 24.3553 - mse: 24.3553\n",
            "Epoch 152/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 24.2661 - mse: 24.2661\n",
            "Epoch 153/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 24.1773 - mse: 24.1773\n",
            "Epoch 154/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 24.0887 - mse: 24.0887\n",
            "Epoch 155/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 24.0005 - mse: 24.0005\n",
            "Epoch 156/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 23.9127 - mse: 23.9127\n",
            "Epoch 157/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 23.8251 - mse: 23.8251\n",
            "Epoch 158/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 23.7379 - mse: 23.7379\n",
            "Epoch 159/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 23.6510 - mse: 23.6510\n",
            "Epoch 160/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 23.5644 - mse: 23.5644\n",
            "Epoch 161/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 23.4782 - mse: 23.4782\n",
            "Epoch 162/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 23.3922 - mse: 23.3922\n",
            "Epoch 163/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 23.3066 - mse: 23.3066\n",
            "Epoch 164/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 23.2213 - mse: 23.2213\n",
            "Epoch 165/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 23.1362 - mse: 23.1362\n",
            "Epoch 166/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 23.0515 - mse: 23.0515\n",
            "Epoch 167/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 22.9671 - mse: 22.9671\n",
            "Epoch 168/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 22.8831 - mse: 22.8831\n",
            "Epoch 169/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 22.7993 - mse: 22.7993\n",
            "Epoch 170/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 22.7158 - mse: 22.7158\n",
            "Epoch 171/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 22.6326 - mse: 22.6326\n",
            "Epoch 172/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 22.5498 - mse: 22.5498\n",
            "Epoch 173/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 22.4673 - mse: 22.4673\n",
            "Epoch 174/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 22.3850 - mse: 22.3850\n",
            "Epoch 175/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 22.3031 - mse: 22.3031\n",
            "Epoch 176/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 22.2214 - mse: 22.2214\n",
            "Epoch 177/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 22.1400 - mse: 22.1400\n",
            "Epoch 178/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 22.0590 - mse: 22.0590\n",
            "Epoch 179/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 21.9783 - mse: 21.9783\n",
            "Epoch 180/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 21.8978 - mse: 21.8978\n",
            "Epoch 181/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 21.8176 - mse: 21.8176\n",
            "Epoch 182/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 21.7378 - mse: 21.7378\n",
            "Epoch 183/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 21.6582 - mse: 21.6582\n",
            "Epoch 184/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 21.5789 - mse: 21.5789\n",
            "Epoch 185/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 21.4999 - mse: 21.4999\n",
            "Epoch 186/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 21.4211 - mse: 21.4211\n",
            "Epoch 187/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 21.3428 - mse: 21.3428\n",
            "Epoch 188/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 21.2646 - mse: 21.2646\n",
            "Epoch 189/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 21.1867 - mse: 21.1867\n",
            "Epoch 190/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 21.1092 - mse: 21.1092\n",
            "Epoch 191/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 21.0319 - mse: 21.0319\n",
            "Epoch 192/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 20.9549 - mse: 20.9549\n",
            "Epoch 193/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 20.8782 - mse: 20.8782\n",
            "Epoch 194/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 20.8018 - mse: 20.8018\n",
            "Epoch 195/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 20.7256 - mse: 20.7256\n",
            "Epoch 196/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 20.6497 - mse: 20.6497\n",
            "Epoch 197/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 20.5742 - mse: 20.5742\n",
            "Epoch 198/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 20.4989 - mse: 20.4989\n",
            "Epoch 199/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 20.4238 - mse: 20.4238\n",
            "Epoch 200/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 20.3490 - mse: 20.3490\n",
            "Epoch 201/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 20.2746 - mse: 20.2746\n",
            "Epoch 202/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 20.2003 - mse: 20.2003\n",
            "Epoch 203/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 20.1264 - mse: 20.1264\n",
            "Epoch 204/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 20.0527 - mse: 20.0527\n",
            "Epoch 205/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 19.9793 - mse: 19.9793\n",
            "Epoch 206/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 19.9061 - mse: 19.9061\n",
            "Epoch 207/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 19.8333 - mse: 19.8333\n",
            "Epoch 208/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 19.7607 - mse: 19.7607\n",
            "Epoch 209/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 19.6884 - mse: 19.6884\n",
            "Epoch 210/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 19.6163 - mse: 19.6163\n",
            "Epoch 211/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 19.5445 - mse: 19.5445\n",
            "Epoch 212/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 19.4729 - mse: 19.4729\n",
            "Epoch 213/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 19.4016 - mse: 19.4016\n",
            "Epoch 214/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 19.3306 - mse: 19.3306\n",
            "Epoch 215/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 19.2599 - mse: 19.2599\n",
            "Epoch 216/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 19.1893 - mse: 19.1893\n",
            "Epoch 217/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 19.1191 - mse: 19.1191\n",
            "Epoch 218/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 19.0491 - mse: 19.0491\n",
            "Epoch 219/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 18.9794 - mse: 18.9794\n",
            "Epoch 220/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 18.9099 - mse: 18.9099\n",
            "Epoch 221/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 18.8407 - mse: 18.8407\n",
            "Epoch 222/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 18.7717 - mse: 18.7717\n",
            "Epoch 223/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 18.7030 - mse: 18.7030\n",
            "Epoch 224/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 18.6345 - mse: 18.6345\n",
            "Epoch 225/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 18.5663 - mse: 18.5663\n",
            "Epoch 226/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 18.4984 - mse: 18.4984\n",
            "Epoch 227/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 18.4306 - mse: 18.4306\n",
            "Epoch 228/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 18.3631 - mse: 18.3631\n",
            "Epoch 229/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 18.2959 - mse: 18.2959\n",
            "Epoch 230/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 18.2289 - mse: 18.2289\n",
            "Epoch 231/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 18.1622 - mse: 18.1622\n",
            "Epoch 232/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 18.0957 - mse: 18.0957\n",
            "Epoch 233/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 18.0295 - mse: 18.0295\n",
            "Epoch 234/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 17.9635 - mse: 17.9635\n",
            "Epoch 235/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 17.8977 - mse: 17.8977\n",
            "Epoch 236/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 17.8322 - mse: 17.8322\n",
            "Epoch 237/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 17.7670 - mse: 17.7670\n",
            "Epoch 238/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 17.7019 - mse: 17.7019\n",
            "Epoch 239/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 17.6371 - mse: 17.6371\n",
            "Epoch 240/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 17.5725 - mse: 17.5725\n",
            "Epoch 241/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 17.5082 - mse: 17.5082\n",
            "Epoch 242/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 17.4441 - mse: 17.4441\n",
            "Epoch 243/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 17.3803 - mse: 17.3803\n",
            "Epoch 244/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 17.3167 - mse: 17.3167\n",
            "Epoch 245/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 17.2533 - mse: 17.2533\n",
            "Epoch 246/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 17.1901 - mse: 17.1901\n",
            "Epoch 247/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 17.1272 - mse: 17.1272\n",
            "Epoch 248/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 17.0645 - mse: 17.0645\n",
            "Epoch 249/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 17.0020 - mse: 17.0020\n",
            "Epoch 250/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 16.9398 - mse: 16.9398\n",
            "Epoch 251/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 16.8778 - mse: 16.8778\n",
            "Epoch 252/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 16.8160 - mse: 16.8160\n",
            "Epoch 253/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 16.7544 - mse: 16.7544\n",
            "Epoch 254/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 16.6931 - mse: 16.6931\n",
            "Epoch 255/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 16.6320 - mse: 16.6320\n",
            "Epoch 256/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 16.5711 - mse: 16.5711\n",
            "Epoch 257/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 16.5105 - mse: 16.5105\n",
            "Epoch 258/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 16.4500 - mse: 16.4500\n",
            "Epoch 259/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 16.3898 - mse: 16.3898\n",
            "Epoch 260/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 16.3298 - mse: 16.3298\n",
            "Epoch 261/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 16.2701 - mse: 16.2701\n",
            "Epoch 262/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 16.2105 - mse: 16.2105\n",
            "Epoch 263/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 16.1512 - mse: 16.1512\n",
            "Epoch 264/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 16.0920 - mse: 16.0920\n",
            "Epoch 265/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 16.0331 - mse: 16.0331\n",
            "Epoch 266/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 15.9745 - mse: 15.9745\n",
            "Epoch 267/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 15.9160 - mse: 15.9160\n",
            "Epoch 268/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 15.8577 - mse: 15.8577\n",
            "Epoch 269/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 15.7997 - mse: 15.7997\n",
            "Epoch 270/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 15.7419 - mse: 15.7419\n",
            "Epoch 271/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 15.6842 - mse: 15.6842\n",
            "Epoch 272/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 15.6268 - mse: 15.6268\n",
            "Epoch 273/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 15.5696 - mse: 15.5696\n",
            "Epoch 274/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 15.5126 - mse: 15.5126\n",
            "Epoch 275/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 15.4558 - mse: 15.4558\n",
            "Epoch 276/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 15.3993 - mse: 15.3993\n",
            "Epoch 277/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 15.3429 - mse: 15.3429\n",
            "Epoch 278/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 15.2867 - mse: 15.2867\n",
            "Epoch 279/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 15.2308 - mse: 15.2308\n",
            "Epoch 280/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 15.1750 - mse: 15.1750\n",
            "Epoch 281/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 15.1195 - mse: 15.1195\n",
            "Epoch 282/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 15.0641 - mse: 15.0641\n",
            "Epoch 283/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 15.0090 - mse: 15.0090\n",
            "Epoch 284/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 14.9541 - mse: 14.9541\n",
            "Epoch 285/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 14.8993 - mse: 14.8993\n",
            "Epoch 286/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 14.8448 - mse: 14.8448\n",
            "Epoch 287/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 14.7904 - mse: 14.7904\n",
            "Epoch 288/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 14.7363 - mse: 14.7363\n",
            "Epoch 289/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 14.6824 - mse: 14.6824\n",
            "Epoch 290/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 14.6286 - mse: 14.6286\n",
            "Epoch 291/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 14.5751 - mse: 14.5751\n",
            "Epoch 292/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 14.5218 - mse: 14.5218\n",
            "Epoch 293/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 14.4686 - mse: 14.4686\n",
            "Epoch 294/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 14.4156 - mse: 14.4156\n",
            "Epoch 295/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 14.3629 - mse: 14.3629\n",
            "Epoch 296/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 14.3103 - mse: 14.3103\n",
            "Epoch 297/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 14.2579 - mse: 14.2579\n",
            "Epoch 298/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 14.2057 - mse: 14.2057\n",
            "Epoch 299/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 14.1537 - mse: 14.1537\n",
            "Epoch 300/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 14.1019 - mse: 14.1019\n",
            "Epoch 301/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 14.0503 - mse: 14.0503\n",
            "Epoch 302/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 13.9989 - mse: 13.9989\n",
            "Epoch 303/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 13.9477 - mse: 13.9477\n",
            "Epoch 304/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 13.8966 - mse: 13.8966\n",
            "Epoch 305/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 13.8457 - mse: 13.8457\n",
            "Epoch 306/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 13.7951 - mse: 13.7951\n",
            "Epoch 307/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 13.7446 - mse: 13.7446\n",
            "Epoch 308/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 13.6943 - mse: 13.6943\n",
            "Epoch 309/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 13.6442 - mse: 13.6442\n",
            "Epoch 310/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 13.5942 - mse: 13.5942\n",
            "Epoch 311/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 13.5445 - mse: 13.5445\n",
            "Epoch 312/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 13.4949 - mse: 13.4949\n",
            "Epoch 313/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 13.4455 - mse: 13.4455\n",
            "Epoch 314/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 13.3963 - mse: 13.3963\n",
            "Epoch 315/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 13.3472 - mse: 13.3472\n",
            "Epoch 316/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 13.2984 - mse: 13.2984\n",
            "Epoch 317/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 13.2497 - mse: 13.2497\n",
            "Epoch 318/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 13.2012 - mse: 13.2012\n",
            "Epoch 319/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 13.1529 - mse: 13.1529\n",
            "Epoch 320/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 13.1048 - mse: 13.1048\n",
            "Epoch 321/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 13.0568 - mse: 13.0568\n",
            "Epoch 322/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 13.0091 - mse: 13.0091\n",
            "Epoch 323/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 12.9614 - mse: 12.9614\n",
            "Epoch 324/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 12.9139 - mse: 12.9139\n",
            "Epoch 325/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 12.8667 - mse: 12.8667\n",
            "Epoch 326/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 12.8196 - mse: 12.8196\n",
            "Epoch 327/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 12.7727 - mse: 12.7727\n",
            "Epoch 328/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 12.7260 - mse: 12.7260\n",
            "Epoch 329/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 12.6794 - mse: 12.6794\n",
            "Epoch 330/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 12.6330 - mse: 12.6330\n",
            "Epoch 331/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 12.5868 - mse: 12.5868\n",
            "Epoch 332/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 12.5407 - mse: 12.5407\n",
            "Epoch 333/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 12.4948 - mse: 12.4948\n",
            "Epoch 334/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 12.4490 - mse: 12.4490\n",
            "Epoch 335/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 12.4035 - mse: 12.4035\n",
            "Epoch 336/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 12.3581 - mse: 12.3581\n",
            "Epoch 337/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 12.3129 - mse: 12.3129\n",
            "Epoch 338/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 12.2678 - mse: 12.2678\n",
            "Epoch 339/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 12.2229 - mse: 12.2229\n",
            "Epoch 340/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 12.1782 - mse: 12.1782\n",
            "Epoch 341/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 12.1336 - mse: 12.1336\n",
            "Epoch 342/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 12.0892 - mse: 12.0892\n",
            "Epoch 343/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 12.0449 - mse: 12.0449\n",
            "Epoch 344/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 12.0009 - mse: 12.0009\n",
            "Epoch 345/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 11.9569 - mse: 11.9569\n",
            "Epoch 346/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 11.9132 - mse: 11.9132\n",
            "Epoch 347/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 11.8696 - mse: 11.8696\n",
            "Epoch 348/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 11.8261 - mse: 11.8261\n",
            "Epoch 349/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 11.7829 - mse: 11.7829\n",
            "Epoch 350/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 11.7398 - mse: 11.7398\n",
            "Epoch 351/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 11.6968 - mse: 11.6968\n",
            "Epoch 352/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 11.6540 - mse: 11.6540\n",
            "Epoch 353/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 11.6113 - mse: 11.6113\n",
            "Epoch 354/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 11.5688 - mse: 11.5688\n",
            "Epoch 355/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 11.5265 - mse: 11.5265\n",
            "Epoch 356/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 11.4843 - mse: 11.4843\n",
            "Epoch 357/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 11.4423 - mse: 11.4423\n",
            "Epoch 358/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 11.4004 - mse: 11.4004\n",
            "Epoch 359/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 11.3587 - mse: 11.3587\n",
            "Epoch 360/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 11.3171 - mse: 11.3171\n",
            "Epoch 361/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 11.2757 - mse: 11.2757\n",
            "Epoch 362/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 11.2344 - mse: 11.2344\n",
            "Epoch 363/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 11.1933 - mse: 11.1933\n",
            "Epoch 364/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 11.1524 - mse: 11.1524\n",
            "Epoch 365/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 11.1116 - mse: 11.1116\n",
            "Epoch 366/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 11.0709 - mse: 11.0709\n",
            "Epoch 367/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 11.0304 - mse: 11.0304\n",
            "Epoch 368/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 10.9900 - mse: 10.9900\n",
            "Epoch 369/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 10.9498 - mse: 10.9498\n",
            "Epoch 370/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 10.9097 - mse: 10.9097\n",
            "Epoch 371/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 10.8698 - mse: 10.8698\n",
            "Epoch 372/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 10.8300 - mse: 10.8300\n",
            "Epoch 373/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 10.7904 - mse: 10.7904\n",
            "Epoch 374/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 10.7509 - mse: 10.7509\n",
            "Epoch 375/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 10.7116 - mse: 10.7116\n",
            "Epoch 376/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 10.6724 - mse: 10.6724\n",
            "Epoch 377/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 10.6333 - mse: 10.6333\n",
            "Epoch 378/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 10.5944 - mse: 10.5944\n",
            "Epoch 379/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 10.5556 - mse: 10.5556\n",
            "Epoch 380/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 10.5170 - mse: 10.5170\n",
            "Epoch 381/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 10.4785 - mse: 10.4785\n",
            "Epoch 382/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 10.4402 - mse: 10.4402\n",
            "Epoch 383/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 10.4020 - mse: 10.4020\n",
            "Epoch 384/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 10.3639 - mse: 10.3639\n",
            "Epoch 385/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 10.3260 - mse: 10.3260\n",
            "Epoch 386/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 10.2882 - mse: 10.2882\n",
            "Epoch 387/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 10.2505 - mse: 10.2505\n",
            "Epoch 388/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 10.2130 - mse: 10.2130\n",
            "Epoch 389/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 10.1757 - mse: 10.1757\n",
            "Epoch 390/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 10.1384 - mse: 10.1384\n",
            "Epoch 391/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 10.1013 - mse: 10.1013\n",
            "Epoch 392/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 10.0644 - mse: 10.0644\n",
            "Epoch 393/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 10.0276 - mse: 10.0276\n",
            "Epoch 394/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 9.9908 - mse: 9.9908\n",
            "Epoch 395/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 9.9543 - mse: 9.9543\n",
            "Epoch 396/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 9.9179 - mse: 9.9179\n",
            "Epoch 397/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.8816 - mse: 9.8816\n",
            "Epoch 398/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 9.8454 - mse: 9.8454\n",
            "Epoch 399/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 9.8094 - mse: 9.8094\n",
            "Epoch 400/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 9.7735 - mse: 9.7735\n",
            "Epoch 401/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 9.7377 - mse: 9.7377\n",
            "Epoch 402/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 9.7021 - mse: 9.7021\n",
            "Epoch 403/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 9.6666 - mse: 9.6666\n",
            "Epoch 404/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 9.6312 - mse: 9.6312\n",
            "Epoch 405/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 9.5960 - mse: 9.5960\n",
            "Epoch 406/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 9.5609 - mse: 9.5609\n",
            "Epoch 407/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 9.5259 - mse: 9.5259\n",
            "Epoch 408/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 9.4910 - mse: 9.4910\n",
            "Epoch 409/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 9.4563 - mse: 9.4563\n",
            "Epoch 410/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 9.4217 - mse: 9.4217\n",
            "Epoch 411/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 9.3872 - mse: 9.3872\n",
            "Epoch 412/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 9.3529 - mse: 9.3529\n",
            "Epoch 413/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 9.3187 - mse: 9.3187\n",
            "Epoch 414/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 9.2846 - mse: 9.2846\n",
            "Epoch 415/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 9.2506 - mse: 9.2506\n",
            "Epoch 416/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.2168 - mse: 9.2168\n",
            "Epoch 417/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.1830 - mse: 9.1830\n",
            "Epoch 418/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 9.1494 - mse: 9.1494\n",
            "Epoch 419/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 9.1160 - mse: 9.1160\n",
            "Epoch 420/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 9.0826 - mse: 9.0826\n",
            "Epoch 421/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 9.0493 - mse: 9.0493\n",
            "Epoch 422/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 9.0162 - mse: 9.0162\n",
            "Epoch 423/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 8.9833 - mse: 8.9833\n",
            "Epoch 424/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.9504 - mse: 8.9504\n",
            "Epoch 425/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.9177 - mse: 8.9177\n",
            "Epoch 426/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.8850 - mse: 8.8850\n",
            "Epoch 427/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 8.8525 - mse: 8.8525\n",
            "Epoch 428/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 8.8201 - mse: 8.8201\n",
            "Epoch 429/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 8.7879 - mse: 8.7879\n",
            "Epoch 430/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.7557 - mse: 8.7557\n",
            "Epoch 431/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.7237 - mse: 8.7237\n",
            "Epoch 432/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 8.6918 - mse: 8.6918\n",
            "Epoch 433/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.6600 - mse: 8.6600\n",
            "Epoch 434/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 8.6283 - mse: 8.6283\n",
            "Epoch 435/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 8.5967 - mse: 8.5967\n",
            "Epoch 436/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 8.5653 - mse: 8.5653\n",
            "Epoch 437/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.5339 - mse: 8.5339\n",
            "Epoch 438/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.5027 - mse: 8.5027\n",
            "Epoch 439/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 8.4716 - mse: 8.4716\n",
            "Epoch 440/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 8.4406 - mse: 8.4406\n",
            "Epoch 441/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.4097 - mse: 8.4097\n",
            "Epoch 442/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 8.3790 - mse: 8.3790\n",
            "Epoch 443/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 8.3483 - mse: 8.3483\n",
            "Epoch 444/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.3177 - mse: 8.3177\n",
            "Epoch 445/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 8.2873 - mse: 8.2873\n",
            "Epoch 446/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 8.2570 - mse: 8.2570\n",
            "Epoch 447/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.2268 - mse: 8.2268\n",
            "Epoch 448/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.1967 - mse: 8.1967\n",
            "Epoch 449/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 8.1667 - mse: 8.1667\n",
            "Epoch 450/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.1368 - mse: 8.1368\n",
            "Epoch 451/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 8.1071 - mse: 8.1071\n",
            "Epoch 452/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 8.0774 - mse: 8.0774\n",
            "Epoch 453/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 8.0479 - mse: 8.0479\n",
            "Epoch 454/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 8.0184 - mse: 8.0184\n",
            "Epoch 455/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 7.9891 - mse: 7.9891\n",
            "Epoch 456/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 7.9599 - mse: 7.9599\n",
            "Epoch 457/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 7.9308 - mse: 7.9308\n",
            "Epoch 458/500\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 7.9017 - mse: 7.9017\n",
            "Epoch 459/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 7.8728 - mse: 7.8728\n",
            "Epoch 460/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 7.8440 - mse: 7.8440\n",
            "Epoch 461/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 7.8153 - mse: 7.8153\n",
            "Epoch 462/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 7.7867 - mse: 7.7867\n",
            "Epoch 463/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 7.7583 - mse: 7.7583\n",
            "Epoch 464/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 7.7299 - mse: 7.7299\n",
            "Epoch 465/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 7.7016 - mse: 7.7016\n",
            "Epoch 466/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 7.6734 - mse: 7.6734\n",
            "Epoch 467/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.6453 - mse: 7.6453\n",
            "Epoch 468/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 7.6174 - mse: 7.6174\n",
            "Epoch 469/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 7.5895 - mse: 7.5895\n",
            "Epoch 470/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 7.5617 - mse: 7.5617\n",
            "Epoch 471/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 7.5341 - mse: 7.5341\n",
            "Epoch 472/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 7.5065 - mse: 7.5065\n",
            "Epoch 473/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 7.4791 - mse: 7.4791\n",
            "Epoch 474/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.4517 - mse: 7.4517\n",
            "Epoch 475/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 7.4245 - mse: 7.4245\n",
            "Epoch 476/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 7.3973 - mse: 7.3973\n",
            "Epoch 477/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 7.3702 - mse: 7.3702\n",
            "Epoch 478/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 7.3433 - mse: 7.3433\n",
            "Epoch 479/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 7.3164 - mse: 7.3164\n",
            "Epoch 480/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 7.2896 - mse: 7.2896\n",
            "Epoch 481/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 7.2630 - mse: 7.2630\n",
            "Epoch 482/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.2364 - mse: 7.2364\n",
            "Epoch 483/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.2100 - mse: 7.2100\n",
            "Epoch 484/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.1836 - mse: 7.1836\n",
            "Epoch 485/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 7.1573 - mse: 7.1573\n",
            "Epoch 486/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.1311 - mse: 7.1311\n",
            "Epoch 487/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 7.1051 - mse: 7.1051\n",
            "Epoch 488/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 7.0790 - mse: 7.0790\n",
            "Epoch 489/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 7.0532 - mse: 7.0532\n",
            "Epoch 490/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 7.0274 - mse: 7.0274\n",
            "Epoch 491/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 7.0017 - mse: 7.0017\n",
            "Epoch 492/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.9761 - mse: 6.9761\n",
            "Epoch 493/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.9506 - mse: 6.9506\n",
            "Epoch 494/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 6.9251 - mse: 6.9251\n",
            "Epoch 495/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 6.8998 - mse: 6.8998\n",
            "Epoch 496/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 6.8746 - mse: 6.8746\n",
            "Epoch 497/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 6.8494 - mse: 6.8494\n",
            "Epoch 498/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 6.8244 - mse: 6.8244\n",
            "Epoch 499/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 6.7994 - mse: 6.7994\n",
            "Epoch 500/500\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 6.7746 - mse: 6.7746\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb6f40d7c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3w6Ayk_xVsR",
        "outputId": "e4ee5a46-ebed-4c0c-e697-0398d81065f2"
      },
      "source": [
        "print(model.predict(X))\n",
        "print(y)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[76.89315 ]\n",
            " [82.31366 ]\n",
            " [69.53466 ]\n",
            " [57.90113 ]\n",
            " [31.367434]]\n",
            "[73 82 72 57 34]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMW-hzJyxo1U"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential # 케라스의 Sequential()을 임포트\n",
        "from tensorflow.keras.layers import Dense # 케라스의 Dense()를 임포트\n",
        "from tensorflow.keras import optimizers # 케라스의 옵티마이저를 임포트"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_npCb8ZxqYp",
        "outputId": "2986fb71-ca2b-4220-cb99-345ac6a0cba9"
      },
      "source": [
        "# 입력 벡터의 차원은 2입니다. 즉, input_dim은 2입니다.\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "# 출력 벡터의 차원은 1입니다. 즉, output_dim은 1입니다.\n",
        "y = np.array([0, 1, 1, 1])\n",
        "\n",
        "model = Sequential([\n",
        "                    Dense(units = 1, input_shape = (2,), activation = 'sigmoid')\n",
        "])\n",
        "model.compile(optimizer='sgd',loss = 'binary_crossentropy', metrics = ['binary_crossentropy'])\n",
        "model.fit(X,y,epochs = 800, batch_size = 1, shuffle = False)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5290 - binary_crossentropy: 0.5290\n",
            "Epoch 2/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5255 - binary_crossentropy: 0.5255\n",
            "Epoch 3/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5220 - binary_crossentropy: 0.5220\n",
            "Epoch 4/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5186 - binary_crossentropy: 0.5186\n",
            "Epoch 5/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5153 - binary_crossentropy: 0.5153\n",
            "Epoch 6/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5121 - binary_crossentropy: 0.5121\n",
            "Epoch 7/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5090 - binary_crossentropy: 0.5090\n",
            "Epoch 8/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5060 - binary_crossentropy: 0.5060\n",
            "Epoch 9/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5030 - binary_crossentropy: 0.5030\n",
            "Epoch 10/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5001 - binary_crossentropy: 0.5001\n",
            "Epoch 11/800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4973 - binary_crossentropy: 0.4973\n",
            "Epoch 12/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4945 - binary_crossentropy: 0.4945\n",
            "Epoch 13/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4919 - binary_crossentropy: 0.4919\n",
            "Epoch 14/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4892 - binary_crossentropy: 0.4892\n",
            "Epoch 15/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4867 - binary_crossentropy: 0.4867\n",
            "Epoch 16/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4842 - binary_crossentropy: 0.4842\n",
            "Epoch 17/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4817 - binary_crossentropy: 0.4817\n",
            "Epoch 18/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4793 - binary_crossentropy: 0.4793\n",
            "Epoch 19/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4770 - binary_crossentropy: 0.4770\n",
            "Epoch 20/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4747 - binary_crossentropy: 0.4747\n",
            "Epoch 21/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4725 - binary_crossentropy: 0.4725\n",
            "Epoch 22/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4703 - binary_crossentropy: 0.4703\n",
            "Epoch 23/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4682 - binary_crossentropy: 0.4682\n",
            "Epoch 24/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4661 - binary_crossentropy: 0.4661\n",
            "Epoch 25/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4641 - binary_crossentropy: 0.4641\n",
            "Epoch 26/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4621 - binary_crossentropy: 0.4621\n",
            "Epoch 27/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4601 - binary_crossentropy: 0.4601\n",
            "Epoch 28/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4582 - binary_crossentropy: 0.4582\n",
            "Epoch 29/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4563 - binary_crossentropy: 0.4563\n",
            "Epoch 30/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4545 - binary_crossentropy: 0.4545\n",
            "Epoch 31/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4527 - binary_crossentropy: 0.4527\n",
            "Epoch 32/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4509 - binary_crossentropy: 0.4509\n",
            "Epoch 33/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4492 - binary_crossentropy: 0.4492\n",
            "Epoch 34/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4475 - binary_crossentropy: 0.4475\n",
            "Epoch 35/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4459 - binary_crossentropy: 0.4459\n",
            "Epoch 36/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4442 - binary_crossentropy: 0.4442\n",
            "Epoch 37/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4426 - binary_crossentropy: 0.4426\n",
            "Epoch 38/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4411 - binary_crossentropy: 0.4411\n",
            "Epoch 39/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4395 - binary_crossentropy: 0.4395\n",
            "Epoch 40/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4380 - binary_crossentropy: 0.4380\n",
            "Epoch 41/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4365 - binary_crossentropy: 0.4365\n",
            "Epoch 42/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4351 - binary_crossentropy: 0.4351\n",
            "Epoch 43/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4337 - binary_crossentropy: 0.4337\n",
            "Epoch 44/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4323 - binary_crossentropy: 0.4323\n",
            "Epoch 45/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4309 - binary_crossentropy: 0.4309\n",
            "Epoch 46/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4295 - binary_crossentropy: 0.4295\n",
            "Epoch 47/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4282 - binary_crossentropy: 0.4282\n",
            "Epoch 48/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4269 - binary_crossentropy: 0.4269\n",
            "Epoch 49/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4256 - binary_crossentropy: 0.4256\n",
            "Epoch 50/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4244 - binary_crossentropy: 0.4244\n",
            "Epoch 51/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4231 - binary_crossentropy: 0.4231\n",
            "Epoch 52/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4219 - binary_crossentropy: 0.4219\n",
            "Epoch 53/800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4207 - binary_crossentropy: 0.4207\n",
            "Epoch 54/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4195 - binary_crossentropy: 0.4195\n",
            "Epoch 55/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4183 - binary_crossentropy: 0.4183\n",
            "Epoch 56/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4172 - binary_crossentropy: 0.4172\n",
            "Epoch 57/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4161 - binary_crossentropy: 0.4161\n",
            "Epoch 58/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4150 - binary_crossentropy: 0.4150\n",
            "Epoch 59/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4139 - binary_crossentropy: 0.4139\n",
            "Epoch 60/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4128 - binary_crossentropy: 0.4128\n",
            "Epoch 61/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4117 - binary_crossentropy: 0.4117\n",
            "Epoch 62/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4107 - binary_crossentropy: 0.4107\n",
            "Epoch 63/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4097 - binary_crossentropy: 0.4097\n",
            "Epoch 64/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4086 - binary_crossentropy: 0.4086\n",
            "Epoch 65/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4076 - binary_crossentropy: 0.4076\n",
            "Epoch 66/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4067 - binary_crossentropy: 0.4067\n",
            "Epoch 67/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4057 - binary_crossentropy: 0.4057\n",
            "Epoch 68/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4047 - binary_crossentropy: 0.4047\n",
            "Epoch 69/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4038 - binary_crossentropy: 0.4038\n",
            "Epoch 70/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4028 - binary_crossentropy: 0.4028\n",
            "Epoch 71/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4019 - binary_crossentropy: 0.4019\n",
            "Epoch 72/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4010 - binary_crossentropy: 0.4010\n",
            "Epoch 73/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4001 - binary_crossentropy: 0.4001\n",
            "Epoch 74/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3992 - binary_crossentropy: 0.3992\n",
            "Epoch 75/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3983 - binary_crossentropy: 0.3983\n",
            "Epoch 76/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3975 - binary_crossentropy: 0.3975\n",
            "Epoch 77/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3966 - binary_crossentropy: 0.3966\n",
            "Epoch 78/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3958 - binary_crossentropy: 0.3958\n",
            "Epoch 79/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3949 - binary_crossentropy: 0.3949\n",
            "Epoch 80/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3941 - binary_crossentropy: 0.3941\n",
            "Epoch 81/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3933 - binary_crossentropy: 0.3933\n",
            "Epoch 82/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3925 - binary_crossentropy: 0.3925\n",
            "Epoch 83/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3917 - binary_crossentropy: 0.3917\n",
            "Epoch 84/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3909 - binary_crossentropy: 0.3909\n",
            "Epoch 85/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3901 - binary_crossentropy: 0.3901\n",
            "Epoch 86/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3894 - binary_crossentropy: 0.3894\n",
            "Epoch 87/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3886 - binary_crossentropy: 0.3886\n",
            "Epoch 88/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3879 - binary_crossentropy: 0.3879\n",
            "Epoch 89/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3871 - binary_crossentropy: 0.3871\n",
            "Epoch 90/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3864 - binary_crossentropy: 0.3864\n",
            "Epoch 91/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3857 - binary_crossentropy: 0.3857\n",
            "Epoch 92/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3849 - binary_crossentropy: 0.3849\n",
            "Epoch 93/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3842 - binary_crossentropy: 0.3842\n",
            "Epoch 94/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3835 - binary_crossentropy: 0.3835\n",
            "Epoch 95/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3828 - binary_crossentropy: 0.3828\n",
            "Epoch 96/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3821 - binary_crossentropy: 0.3821\n",
            "Epoch 97/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3814 - binary_crossentropy: 0.3814\n",
            "Epoch 98/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3808 - binary_crossentropy: 0.3808\n",
            "Epoch 99/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3801 - binary_crossentropy: 0.3801\n",
            "Epoch 100/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3794 - binary_crossentropy: 0.3794\n",
            "Epoch 101/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3788 - binary_crossentropy: 0.3788\n",
            "Epoch 102/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3781 - binary_crossentropy: 0.3781\n",
            "Epoch 103/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3775 - binary_crossentropy: 0.3775\n",
            "Epoch 104/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3768 - binary_crossentropy: 0.3768\n",
            "Epoch 105/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3762 - binary_crossentropy: 0.3762\n",
            "Epoch 106/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3755 - binary_crossentropy: 0.3755\n",
            "Epoch 107/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3749 - binary_crossentropy: 0.3749\n",
            "Epoch 108/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3743 - binary_crossentropy: 0.3743\n",
            "Epoch 109/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3737 - binary_crossentropy: 0.3737\n",
            "Epoch 110/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3731 - binary_crossentropy: 0.3731\n",
            "Epoch 111/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3725 - binary_crossentropy: 0.3725\n",
            "Epoch 112/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3719 - binary_crossentropy: 0.3719\n",
            "Epoch 113/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3713 - binary_crossentropy: 0.3713\n",
            "Epoch 114/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3707 - binary_crossentropy: 0.3707\n",
            "Epoch 115/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3701 - binary_crossentropy: 0.3701\n",
            "Epoch 116/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3695 - binary_crossentropy: 0.3695\n",
            "Epoch 117/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3689 - binary_crossentropy: 0.3689\n",
            "Epoch 118/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3684 - binary_crossentropy: 0.3684\n",
            "Epoch 119/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3678 - binary_crossentropy: 0.3678\n",
            "Epoch 120/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3672 - binary_crossentropy: 0.3672\n",
            "Epoch 121/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3667 - binary_crossentropy: 0.3667\n",
            "Epoch 122/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3661 - binary_crossentropy: 0.3661\n",
            "Epoch 123/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3656 - binary_crossentropy: 0.3656\n",
            "Epoch 124/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3650 - binary_crossentropy: 0.3650\n",
            "Epoch 125/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3645 - binary_crossentropy: 0.3645\n",
            "Epoch 126/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3639 - binary_crossentropy: 0.3639\n",
            "Epoch 127/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3634 - binary_crossentropy: 0.3634\n",
            "Epoch 128/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3629 - binary_crossentropy: 0.3629\n",
            "Epoch 129/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3623 - binary_crossentropy: 0.3623\n",
            "Epoch 130/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3618 - binary_crossentropy: 0.3618\n",
            "Epoch 131/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3613 - binary_crossentropy: 0.3613\n",
            "Epoch 132/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3608 - binary_crossentropy: 0.3608\n",
            "Epoch 133/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3602 - binary_crossentropy: 0.3602\n",
            "Epoch 134/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3597 - binary_crossentropy: 0.3597\n",
            "Epoch 135/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3592 - binary_crossentropy: 0.3592\n",
            "Epoch 136/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3587 - binary_crossentropy: 0.3587\n",
            "Epoch 137/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3582 - binary_crossentropy: 0.3582\n",
            "Epoch 138/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3577 - binary_crossentropy: 0.3577\n",
            "Epoch 139/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3572 - binary_crossentropy: 0.3572\n",
            "Epoch 140/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3567 - binary_crossentropy: 0.3567\n",
            "Epoch 141/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3562 - binary_crossentropy: 0.3562\n",
            "Epoch 142/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3557 - binary_crossentropy: 0.3557\n",
            "Epoch 143/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3552 - binary_crossentropy: 0.3552\n",
            "Epoch 144/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3548 - binary_crossentropy: 0.3548\n",
            "Epoch 145/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3543 - binary_crossentropy: 0.3543\n",
            "Epoch 146/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3538 - binary_crossentropy: 0.3538\n",
            "Epoch 147/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3533 - binary_crossentropy: 0.3533\n",
            "Epoch 148/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3529 - binary_crossentropy: 0.3529\n",
            "Epoch 149/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3524 - binary_crossentropy: 0.3524\n",
            "Epoch 150/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3519 - binary_crossentropy: 0.3519\n",
            "Epoch 151/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3515 - binary_crossentropy: 0.3515\n",
            "Epoch 152/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3510 - binary_crossentropy: 0.3510\n",
            "Epoch 153/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3505 - binary_crossentropy: 0.3505\n",
            "Epoch 154/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3501 - binary_crossentropy: 0.3501\n",
            "Epoch 155/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3496 - binary_crossentropy: 0.3496\n",
            "Epoch 156/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3492 - binary_crossentropy: 0.3492\n",
            "Epoch 157/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3487 - binary_crossentropy: 0.3487\n",
            "Epoch 158/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3483 - binary_crossentropy: 0.3483\n",
            "Epoch 159/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3478 - binary_crossentropy: 0.3478\n",
            "Epoch 160/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3474 - binary_crossentropy: 0.3474\n",
            "Epoch 161/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3469 - binary_crossentropy: 0.3469\n",
            "Epoch 162/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3465 - binary_crossentropy: 0.3465\n",
            "Epoch 163/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3460 - binary_crossentropy: 0.3460\n",
            "Epoch 164/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3456 - binary_crossentropy: 0.3456\n",
            "Epoch 165/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3452 - binary_crossentropy: 0.3452\n",
            "Epoch 166/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3447 - binary_crossentropy: 0.3447\n",
            "Epoch 167/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3443 - binary_crossentropy: 0.3443\n",
            "Epoch 168/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3439 - binary_crossentropy: 0.3439\n",
            "Epoch 169/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3435 - binary_crossentropy: 0.3435\n",
            "Epoch 170/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3430 - binary_crossentropy: 0.3430\n",
            "Epoch 171/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3426 - binary_crossentropy: 0.3426\n",
            "Epoch 172/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3422 - binary_crossentropy: 0.3422\n",
            "Epoch 173/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3418 - binary_crossentropy: 0.3418\n",
            "Epoch 174/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3413 - binary_crossentropy: 0.3413\n",
            "Epoch 175/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3409 - binary_crossentropy: 0.3409\n",
            "Epoch 176/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3405 - binary_crossentropy: 0.3405\n",
            "Epoch 177/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3401 - binary_crossentropy: 0.3401\n",
            "Epoch 178/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3397 - binary_crossentropy: 0.3397\n",
            "Epoch 179/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3393 - binary_crossentropy: 0.3393\n",
            "Epoch 180/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3389 - binary_crossentropy: 0.3389\n",
            "Epoch 181/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3385 - binary_crossentropy: 0.3385\n",
            "Epoch 182/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3381 - binary_crossentropy: 0.3381\n",
            "Epoch 183/800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3377 - binary_crossentropy: 0.3377\n",
            "Epoch 184/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3373 - binary_crossentropy: 0.3373\n",
            "Epoch 185/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3369 - binary_crossentropy: 0.3369\n",
            "Epoch 186/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3365 - binary_crossentropy: 0.3365\n",
            "Epoch 187/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3361 - binary_crossentropy: 0.3361\n",
            "Epoch 188/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3357 - binary_crossentropy: 0.3357\n",
            "Epoch 189/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3353 - binary_crossentropy: 0.3353\n",
            "Epoch 190/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3349 - binary_crossentropy: 0.3349\n",
            "Epoch 191/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3345 - binary_crossentropy: 0.3345\n",
            "Epoch 192/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3341 - binary_crossentropy: 0.3341\n",
            "Epoch 193/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3337 - binary_crossentropy: 0.3337\n",
            "Epoch 194/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3333 - binary_crossentropy: 0.3333\n",
            "Epoch 195/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3329 - binary_crossentropy: 0.3329\n",
            "Epoch 196/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3325 - binary_crossentropy: 0.3325\n",
            "Epoch 197/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3322 - binary_crossentropy: 0.3322\n",
            "Epoch 198/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3318 - binary_crossentropy: 0.3318\n",
            "Epoch 199/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3314 - binary_crossentropy: 0.3314\n",
            "Epoch 200/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3310 - binary_crossentropy: 0.3310\n",
            "Epoch 201/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3306 - binary_crossentropy: 0.3306\n",
            "Epoch 202/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3303 - binary_crossentropy: 0.3303\n",
            "Epoch 203/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3299 - binary_crossentropy: 0.3299\n",
            "Epoch 204/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3295 - binary_crossentropy: 0.3295\n",
            "Epoch 205/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3291 - binary_crossentropy: 0.3291\n",
            "Epoch 206/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3288 - binary_crossentropy: 0.3288\n",
            "Epoch 207/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3284 - binary_crossentropy: 0.3284\n",
            "Epoch 208/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3280 - binary_crossentropy: 0.3280\n",
            "Epoch 209/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3276 - binary_crossentropy: 0.3276\n",
            "Epoch 210/800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3273 - binary_crossentropy: 0.3273\n",
            "Epoch 211/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3269 - binary_crossentropy: 0.3269\n",
            "Epoch 212/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3265 - binary_crossentropy: 0.3265\n",
            "Epoch 213/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3262 - binary_crossentropy: 0.3262\n",
            "Epoch 214/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3258 - binary_crossentropy: 0.3258\n",
            "Epoch 215/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3255 - binary_crossentropy: 0.3255\n",
            "Epoch 216/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3251 - binary_crossentropy: 0.3251\n",
            "Epoch 217/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3247 - binary_crossentropy: 0.3247\n",
            "Epoch 218/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3244 - binary_crossentropy: 0.3244\n",
            "Epoch 219/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3240 - binary_crossentropy: 0.3240\n",
            "Epoch 220/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3237 - binary_crossentropy: 0.3237\n",
            "Epoch 221/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3233 - binary_crossentropy: 0.3233\n",
            "Epoch 222/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3230 - binary_crossentropy: 0.3230\n",
            "Epoch 223/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3226 - binary_crossentropy: 0.3226\n",
            "Epoch 224/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3222 - binary_crossentropy: 0.3222\n",
            "Epoch 225/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3219 - binary_crossentropy: 0.3219\n",
            "Epoch 226/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3215 - binary_crossentropy: 0.3215\n",
            "Epoch 227/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3212 - binary_crossentropy: 0.3212\n",
            "Epoch 228/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3208 - binary_crossentropy: 0.3208\n",
            "Epoch 229/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3205 - binary_crossentropy: 0.3205\n",
            "Epoch 230/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3201 - binary_crossentropy: 0.3201\n",
            "Epoch 231/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3198 - binary_crossentropy: 0.3198\n",
            "Epoch 232/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3195 - binary_crossentropy: 0.3195\n",
            "Epoch 233/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3191 - binary_crossentropy: 0.3191\n",
            "Epoch 234/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3188 - binary_crossentropy: 0.3188\n",
            "Epoch 235/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3184 - binary_crossentropy: 0.3184\n",
            "Epoch 236/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3181 - binary_crossentropy: 0.3181\n",
            "Epoch 237/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3177 - binary_crossentropy: 0.3177\n",
            "Epoch 238/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3174 - binary_crossentropy: 0.3174\n",
            "Epoch 239/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3171 - binary_crossentropy: 0.3171\n",
            "Epoch 240/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3167 - binary_crossentropy: 0.3167\n",
            "Epoch 241/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3164 - binary_crossentropy: 0.3164\n",
            "Epoch 242/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3160 - binary_crossentropy: 0.3160\n",
            "Epoch 243/800\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3157 - binary_crossentropy: 0.3157\n",
            "Epoch 244/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3154 - binary_crossentropy: 0.3154\n",
            "Epoch 245/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3150 - binary_crossentropy: 0.3150\n",
            "Epoch 246/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3147 - binary_crossentropy: 0.3147\n",
            "Epoch 247/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3144 - binary_crossentropy: 0.3144\n",
            "Epoch 248/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3140 - binary_crossentropy: 0.3140\n",
            "Epoch 249/800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3137 - binary_crossentropy: 0.3137\n",
            "Epoch 250/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3134 - binary_crossentropy: 0.3134\n",
            "Epoch 251/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3131 - binary_crossentropy: 0.3131\n",
            "Epoch 252/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3127 - binary_crossentropy: 0.3127\n",
            "Epoch 253/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3124 - binary_crossentropy: 0.3124\n",
            "Epoch 254/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3121 - binary_crossentropy: 0.3121\n",
            "Epoch 255/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3118 - binary_crossentropy: 0.3118\n",
            "Epoch 256/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3114 - binary_crossentropy: 0.3114\n",
            "Epoch 257/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3111 - binary_crossentropy: 0.3111\n",
            "Epoch 258/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3108 - binary_crossentropy: 0.3108\n",
            "Epoch 259/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3105 - binary_crossentropy: 0.3105\n",
            "Epoch 260/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3101 - binary_crossentropy: 0.3101\n",
            "Epoch 261/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3098 - binary_crossentropy: 0.3098\n",
            "Epoch 262/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3095 - binary_crossentropy: 0.3095\n",
            "Epoch 263/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3092 - binary_crossentropy: 0.3092\n",
            "Epoch 264/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3089 - binary_crossentropy: 0.3089\n",
            "Epoch 265/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3085 - binary_crossentropy: 0.3085\n",
            "Epoch 266/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3082 - binary_crossentropy: 0.3082\n",
            "Epoch 267/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3079 - binary_crossentropy: 0.3079\n",
            "Epoch 268/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3076 - binary_crossentropy: 0.3076\n",
            "Epoch 269/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3073 - binary_crossentropy: 0.3073\n",
            "Epoch 270/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3070 - binary_crossentropy: 0.3070\n",
            "Epoch 271/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3066 - binary_crossentropy: 0.3066\n",
            "Epoch 272/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3063 - binary_crossentropy: 0.3063\n",
            "Epoch 273/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3060 - binary_crossentropy: 0.3060\n",
            "Epoch 274/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3057 - binary_crossentropy: 0.3057\n",
            "Epoch 275/800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3054 - binary_crossentropy: 0.3054\n",
            "Epoch 276/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3051 - binary_crossentropy: 0.3051\n",
            "Epoch 277/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3048 - binary_crossentropy: 0.3048\n",
            "Epoch 278/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3045 - binary_crossentropy: 0.3045\n",
            "Epoch 279/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3042 - binary_crossentropy: 0.3042\n",
            "Epoch 280/800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3038 - binary_crossentropy: 0.3038\n",
            "Epoch 281/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3035 - binary_crossentropy: 0.3035\n",
            "Epoch 282/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3032 - binary_crossentropy: 0.3032\n",
            "Epoch 283/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3029 - binary_crossentropy: 0.3029\n",
            "Epoch 284/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3026 - binary_crossentropy: 0.3026\n",
            "Epoch 285/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3023 - binary_crossentropy: 0.3023\n",
            "Epoch 286/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3020 - binary_crossentropy: 0.3020\n",
            "Epoch 287/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3017 - binary_crossentropy: 0.3017\n",
            "Epoch 288/800\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3014 - binary_crossentropy: 0.3014\n",
            "Epoch 289/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3011 - binary_crossentropy: 0.3011\n",
            "Epoch 290/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3008 - binary_crossentropy: 0.3008\n",
            "Epoch 291/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3005 - binary_crossentropy: 0.3005\n",
            "Epoch 292/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3002 - binary_crossentropy: 0.3002\n",
            "Epoch 293/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2999 - binary_crossentropy: 0.2999\n",
            "Epoch 294/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2996 - binary_crossentropy: 0.2996\n",
            "Epoch 295/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2993 - binary_crossentropy: 0.2993\n",
            "Epoch 296/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2990 - binary_crossentropy: 0.2990\n",
            "Epoch 297/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2987 - binary_crossentropy: 0.2987\n",
            "Epoch 298/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2984 - binary_crossentropy: 0.2984\n",
            "Epoch 299/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2981 - binary_crossentropy: 0.2981\n",
            "Epoch 300/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2978 - binary_crossentropy: 0.2978\n",
            "Epoch 301/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2975 - binary_crossentropy: 0.2975\n",
            "Epoch 302/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2972 - binary_crossentropy: 0.2972\n",
            "Epoch 303/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2969 - binary_crossentropy: 0.2969\n",
            "Epoch 304/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2966 - binary_crossentropy: 0.2966\n",
            "Epoch 305/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2964 - binary_crossentropy: 0.2964\n",
            "Epoch 306/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2961 - binary_crossentropy: 0.2961\n",
            "Epoch 307/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2958 - binary_crossentropy: 0.2958\n",
            "Epoch 308/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2955 - binary_crossentropy: 0.2955\n",
            "Epoch 309/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2952 - binary_crossentropy: 0.2952\n",
            "Epoch 310/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2949 - binary_crossentropy: 0.2949\n",
            "Epoch 311/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2946 - binary_crossentropy: 0.2946\n",
            "Epoch 312/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2943 - binary_crossentropy: 0.2943\n",
            "Epoch 313/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2940 - binary_crossentropy: 0.2940\n",
            "Epoch 314/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2937 - binary_crossentropy: 0.2937\n",
            "Epoch 315/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2935 - binary_crossentropy: 0.2935\n",
            "Epoch 316/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2932 - binary_crossentropy: 0.2932\n",
            "Epoch 317/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2929 - binary_crossentropy: 0.2929\n",
            "Epoch 318/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2926 - binary_crossentropy: 0.2926\n",
            "Epoch 319/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2923 - binary_crossentropy: 0.2923\n",
            "Epoch 320/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2920 - binary_crossentropy: 0.2920\n",
            "Epoch 321/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2917 - binary_crossentropy: 0.2917\n",
            "Epoch 322/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2915 - binary_crossentropy: 0.2915\n",
            "Epoch 323/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2912 - binary_crossentropy: 0.2912\n",
            "Epoch 324/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2909 - binary_crossentropy: 0.2909\n",
            "Epoch 325/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2906 - binary_crossentropy: 0.2906\n",
            "Epoch 326/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2903 - binary_crossentropy: 0.2903\n",
            "Epoch 327/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2901 - binary_crossentropy: 0.2901\n",
            "Epoch 328/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2898 - binary_crossentropy: 0.2898\n",
            "Epoch 329/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2895 - binary_crossentropy: 0.2895\n",
            "Epoch 330/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2892 - binary_crossentropy: 0.2892\n",
            "Epoch 331/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2889 - binary_crossentropy: 0.2889\n",
            "Epoch 332/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2887 - binary_crossentropy: 0.2887\n",
            "Epoch 333/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2884 - binary_crossentropy: 0.2884\n",
            "Epoch 334/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2881 - binary_crossentropy: 0.2881\n",
            "Epoch 335/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2878 - binary_crossentropy: 0.2878\n",
            "Epoch 336/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2876 - binary_crossentropy: 0.2876\n",
            "Epoch 337/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2873 - binary_crossentropy: 0.2873\n",
            "Epoch 338/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2870 - binary_crossentropy: 0.2870\n",
            "Epoch 339/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2867 - binary_crossentropy: 0.2867\n",
            "Epoch 340/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2865 - binary_crossentropy: 0.2865\n",
            "Epoch 341/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2862 - binary_crossentropy: 0.2862\n",
            "Epoch 342/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2859 - binary_crossentropy: 0.2859\n",
            "Epoch 343/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2856 - binary_crossentropy: 0.2856\n",
            "Epoch 344/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2854 - binary_crossentropy: 0.2854\n",
            "Epoch 345/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2851 - binary_crossentropy: 0.2851\n",
            "Epoch 346/800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2848 - binary_crossentropy: 0.2848\n",
            "Epoch 347/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2846 - binary_crossentropy: 0.2846\n",
            "Epoch 348/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2843 - binary_crossentropy: 0.2843\n",
            "Epoch 349/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2840 - binary_crossentropy: 0.2840\n",
            "Epoch 350/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2838 - binary_crossentropy: 0.2838\n",
            "Epoch 351/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2835 - binary_crossentropy: 0.2835\n",
            "Epoch 352/800\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2832 - binary_crossentropy: 0.2832\n",
            "Epoch 353/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2830 - binary_crossentropy: 0.2830\n",
            "Epoch 354/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2827 - binary_crossentropy: 0.2827\n",
            "Epoch 355/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2824 - binary_crossentropy: 0.2824\n",
            "Epoch 356/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2822 - binary_crossentropy: 0.2822\n",
            "Epoch 357/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2819 - binary_crossentropy: 0.2819\n",
            "Epoch 358/800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2816 - binary_crossentropy: 0.2816\n",
            "Epoch 359/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2814 - binary_crossentropy: 0.2814\n",
            "Epoch 360/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2811 - binary_crossentropy: 0.2811\n",
            "Epoch 361/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2808 - binary_crossentropy: 0.2808\n",
            "Epoch 362/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2806 - binary_crossentropy: 0.2806\n",
            "Epoch 363/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2803 - binary_crossentropy: 0.2803\n",
            "Epoch 364/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2801 - binary_crossentropy: 0.2801\n",
            "Epoch 365/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2798 - binary_crossentropy: 0.2798\n",
            "Epoch 366/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2795 - binary_crossentropy: 0.2795\n",
            "Epoch 367/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2793 - binary_crossentropy: 0.2793\n",
            "Epoch 368/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2790 - binary_crossentropy: 0.2790\n",
            "Epoch 369/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2787 - binary_crossentropy: 0.2787\n",
            "Epoch 370/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2785 - binary_crossentropy: 0.2785\n",
            "Epoch 371/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2782 - binary_crossentropy: 0.2782\n",
            "Epoch 372/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2780 - binary_crossentropy: 0.2780\n",
            "Epoch 373/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2777 - binary_crossentropy: 0.2777\n",
            "Epoch 374/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2775 - binary_crossentropy: 0.2775\n",
            "Epoch 375/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2772 - binary_crossentropy: 0.2772\n",
            "Epoch 376/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2769 - binary_crossentropy: 0.2769\n",
            "Epoch 377/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2767 - binary_crossentropy: 0.2767\n",
            "Epoch 378/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2764 - binary_crossentropy: 0.2764\n",
            "Epoch 379/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2762 - binary_crossentropy: 0.2762\n",
            "Epoch 380/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2759 - binary_crossentropy: 0.2759\n",
            "Epoch 381/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2757 - binary_crossentropy: 0.2757\n",
            "Epoch 382/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2754 - binary_crossentropy: 0.2754\n",
            "Epoch 383/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2752 - binary_crossentropy: 0.2752\n",
            "Epoch 384/800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2749 - binary_crossentropy: 0.2749\n",
            "Epoch 385/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2747 - binary_crossentropy: 0.2747\n",
            "Epoch 386/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2744 - binary_crossentropy: 0.2744\n",
            "Epoch 387/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2742 - binary_crossentropy: 0.2742\n",
            "Epoch 388/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2739 - binary_crossentropy: 0.2739\n",
            "Epoch 389/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2737 - binary_crossentropy: 0.2737\n",
            "Epoch 390/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2734 - binary_crossentropy: 0.2734\n",
            "Epoch 391/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2732 - binary_crossentropy: 0.2732\n",
            "Epoch 392/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2729 - binary_crossentropy: 0.2729\n",
            "Epoch 393/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2727 - binary_crossentropy: 0.2727\n",
            "Epoch 394/800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2724 - binary_crossentropy: 0.2724\n",
            "Epoch 395/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2722 - binary_crossentropy: 0.2722\n",
            "Epoch 396/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2719 - binary_crossentropy: 0.2719\n",
            "Epoch 397/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2717 - binary_crossentropy: 0.2717\n",
            "Epoch 398/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2714 - binary_crossentropy: 0.2714\n",
            "Epoch 399/800\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2712 - binary_crossentropy: 0.2712\n",
            "Epoch 400/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2709 - binary_crossentropy: 0.2709\n",
            "Epoch 401/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2707 - binary_crossentropy: 0.2707\n",
            "Epoch 402/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2704 - binary_crossentropy: 0.2704\n",
            "Epoch 403/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2702 - binary_crossentropy: 0.2702\n",
            "Epoch 404/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2699 - binary_crossentropy: 0.2699\n",
            "Epoch 405/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2697 - binary_crossentropy: 0.2697\n",
            "Epoch 406/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2695 - binary_crossentropy: 0.2695\n",
            "Epoch 407/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2692 - binary_crossentropy: 0.2692\n",
            "Epoch 408/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2690 - binary_crossentropy: 0.2690\n",
            "Epoch 409/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2687 - binary_crossentropy: 0.2687\n",
            "Epoch 410/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2685 - binary_crossentropy: 0.2685\n",
            "Epoch 411/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2682 - binary_crossentropy: 0.2682\n",
            "Epoch 412/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2680 - binary_crossentropy: 0.2680\n",
            "Epoch 413/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2678 - binary_crossentropy: 0.2678\n",
            "Epoch 414/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2675 - binary_crossentropy: 0.2675\n",
            "Epoch 415/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2673 - binary_crossentropy: 0.2673\n",
            "Epoch 416/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2670 - binary_crossentropy: 0.2670\n",
            "Epoch 417/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2668 - binary_crossentropy: 0.2668\n",
            "Epoch 418/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2666 - binary_crossentropy: 0.2666\n",
            "Epoch 419/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2663 - binary_crossentropy: 0.2663\n",
            "Epoch 420/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2661 - binary_crossentropy: 0.2661\n",
            "Epoch 421/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2659 - binary_crossentropy: 0.2659\n",
            "Epoch 422/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2656 - binary_crossentropy: 0.2656\n",
            "Epoch 423/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2654 - binary_crossentropy: 0.2654\n",
            "Epoch 424/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2651 - binary_crossentropy: 0.2651\n",
            "Epoch 425/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2649 - binary_crossentropy: 0.2649\n",
            "Epoch 426/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2647 - binary_crossentropy: 0.2647\n",
            "Epoch 427/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2644 - binary_crossentropy: 0.2644\n",
            "Epoch 428/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2642 - binary_crossentropy: 0.2642\n",
            "Epoch 429/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2640 - binary_crossentropy: 0.2640\n",
            "Epoch 430/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2637 - binary_crossentropy: 0.2637\n",
            "Epoch 431/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2635 - binary_crossentropy: 0.2635\n",
            "Epoch 432/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2633 - binary_crossentropy: 0.2633\n",
            "Epoch 433/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2630 - binary_crossentropy: 0.2630\n",
            "Epoch 434/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2628 - binary_crossentropy: 0.2628\n",
            "Epoch 435/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2626 - binary_crossentropy: 0.2626\n",
            "Epoch 436/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2623 - binary_crossentropy: 0.2623\n",
            "Epoch 437/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2621 - binary_crossentropy: 0.2621\n",
            "Epoch 438/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2619 - binary_crossentropy: 0.2619\n",
            "Epoch 439/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2616 - binary_crossentropy: 0.2616\n",
            "Epoch 440/800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2614 - binary_crossentropy: 0.2614\n",
            "Epoch 441/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2612 - binary_crossentropy: 0.2612\n",
            "Epoch 442/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2610 - binary_crossentropy: 0.2610\n",
            "Epoch 443/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2607 - binary_crossentropy: 0.2607\n",
            "Epoch 444/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2605 - binary_crossentropy: 0.2605\n",
            "Epoch 445/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2603 - binary_crossentropy: 0.2603\n",
            "Epoch 446/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2600 - binary_crossentropy: 0.2600\n",
            "Epoch 447/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2598 - binary_crossentropy: 0.2598\n",
            "Epoch 448/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2596 - binary_crossentropy: 0.2596\n",
            "Epoch 449/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2594 - binary_crossentropy: 0.2594\n",
            "Epoch 450/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2591 - binary_crossentropy: 0.2591\n",
            "Epoch 451/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2589 - binary_crossentropy: 0.2589\n",
            "Epoch 452/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2587 - binary_crossentropy: 0.2587\n",
            "Epoch 453/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2585 - binary_crossentropy: 0.2585\n",
            "Epoch 454/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2582 - binary_crossentropy: 0.2582\n",
            "Epoch 455/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2580 - binary_crossentropy: 0.2580\n",
            "Epoch 456/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2578 - binary_crossentropy: 0.2578\n",
            "Epoch 457/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2576 - binary_crossentropy: 0.2576\n",
            "Epoch 458/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2573 - binary_crossentropy: 0.2573\n",
            "Epoch 459/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2571 - binary_crossentropy: 0.2571\n",
            "Epoch 460/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2569 - binary_crossentropy: 0.2569\n",
            "Epoch 461/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2567 - binary_crossentropy: 0.2567\n",
            "Epoch 462/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2564 - binary_crossentropy: 0.2564\n",
            "Epoch 463/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2562 - binary_crossentropy: 0.2562\n",
            "Epoch 464/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2560 - binary_crossentropy: 0.2560\n",
            "Epoch 465/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2558 - binary_crossentropy: 0.2558\n",
            "Epoch 466/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2556 - binary_crossentropy: 0.2556\n",
            "Epoch 467/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2553 - binary_crossentropy: 0.2553\n",
            "Epoch 468/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2551 - binary_crossentropy: 0.2551\n",
            "Epoch 469/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2549 - binary_crossentropy: 0.2549\n",
            "Epoch 470/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2547 - binary_crossentropy: 0.2547\n",
            "Epoch 471/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2545 - binary_crossentropy: 0.2545\n",
            "Epoch 472/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2542 - binary_crossentropy: 0.2542\n",
            "Epoch 473/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2540 - binary_crossentropy: 0.2540\n",
            "Epoch 474/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2538 - binary_crossentropy: 0.2538\n",
            "Epoch 475/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2536 - binary_crossentropy: 0.2536\n",
            "Epoch 476/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2534 - binary_crossentropy: 0.2534\n",
            "Epoch 477/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2532 - binary_crossentropy: 0.2532\n",
            "Epoch 478/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2529 - binary_crossentropy: 0.2529\n",
            "Epoch 479/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2527 - binary_crossentropy: 0.2527\n",
            "Epoch 480/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2525 - binary_crossentropy: 0.2525\n",
            "Epoch 481/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2523 - binary_crossentropy: 0.2523\n",
            "Epoch 482/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2521 - binary_crossentropy: 0.2521\n",
            "Epoch 483/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2519 - binary_crossentropy: 0.2519\n",
            "Epoch 484/800\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2516 - binary_crossentropy: 0.2516\n",
            "Epoch 485/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2514 - binary_crossentropy: 0.2514\n",
            "Epoch 486/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2512 - binary_crossentropy: 0.2512\n",
            "Epoch 487/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2510 - binary_crossentropy: 0.2510\n",
            "Epoch 488/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2508 - binary_crossentropy: 0.2508\n",
            "Epoch 489/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2506 - binary_crossentropy: 0.2506\n",
            "Epoch 490/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2504 - binary_crossentropy: 0.2504\n",
            "Epoch 491/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2502 - binary_crossentropy: 0.2502\n",
            "Epoch 492/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2499 - binary_crossentropy: 0.2499\n",
            "Epoch 493/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2497 - binary_crossentropy: 0.2497\n",
            "Epoch 494/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2495 - binary_crossentropy: 0.2495\n",
            "Epoch 495/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2493 - binary_crossentropy: 0.2493\n",
            "Epoch 496/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2491 - binary_crossentropy: 0.2491\n",
            "Epoch 497/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2489 - binary_crossentropy: 0.2489\n",
            "Epoch 498/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2487 - binary_crossentropy: 0.2487\n",
            "Epoch 499/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2485 - binary_crossentropy: 0.2485\n",
            "Epoch 500/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2483 - binary_crossentropy: 0.2483\n",
            "Epoch 501/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2480 - binary_crossentropy: 0.2480\n",
            "Epoch 502/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2478 - binary_crossentropy: 0.2478\n",
            "Epoch 503/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2476 - binary_crossentropy: 0.2476\n",
            "Epoch 504/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2474 - binary_crossentropy: 0.2474\n",
            "Epoch 505/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2472 - binary_crossentropy: 0.2472\n",
            "Epoch 506/800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2470 - binary_crossentropy: 0.2470\n",
            "Epoch 507/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2468 - binary_crossentropy: 0.2468\n",
            "Epoch 508/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2466 - binary_crossentropy: 0.2466\n",
            "Epoch 509/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2464 - binary_crossentropy: 0.2464\n",
            "Epoch 510/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2462 - binary_crossentropy: 0.2462\n",
            "Epoch 511/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2460 - binary_crossentropy: 0.2460\n",
            "Epoch 512/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2458 - binary_crossentropy: 0.2458\n",
            "Epoch 513/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2456 - binary_crossentropy: 0.2456\n",
            "Epoch 514/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2454 - binary_crossentropy: 0.2454\n",
            "Epoch 515/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2452 - binary_crossentropy: 0.2452\n",
            "Epoch 516/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2450 - binary_crossentropy: 0.2450\n",
            "Epoch 517/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2447 - binary_crossentropy: 0.2447\n",
            "Epoch 518/800\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2445 - binary_crossentropy: 0.2445\n",
            "Epoch 519/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2443 - binary_crossentropy: 0.2443\n",
            "Epoch 520/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2441 - binary_crossentropy: 0.2441\n",
            "Epoch 521/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2439 - binary_crossentropy: 0.2439\n",
            "Epoch 522/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2437 - binary_crossentropy: 0.2437\n",
            "Epoch 523/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2435 - binary_crossentropy: 0.2435\n",
            "Epoch 524/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2433 - binary_crossentropy: 0.2433\n",
            "Epoch 525/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2431 - binary_crossentropy: 0.2431\n",
            "Epoch 526/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2429 - binary_crossentropy: 0.2429\n",
            "Epoch 527/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2427 - binary_crossentropy: 0.2427\n",
            "Epoch 528/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2425 - binary_crossentropy: 0.2425\n",
            "Epoch 529/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2423 - binary_crossentropy: 0.2423\n",
            "Epoch 530/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2421 - binary_crossentropy: 0.2421\n",
            "Epoch 531/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2419 - binary_crossentropy: 0.2419\n",
            "Epoch 532/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2417 - binary_crossentropy: 0.2417\n",
            "Epoch 533/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2415 - binary_crossentropy: 0.2415\n",
            "Epoch 534/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2413 - binary_crossentropy: 0.2413\n",
            "Epoch 535/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2411 - binary_crossentropy: 0.2411\n",
            "Epoch 536/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2409 - binary_crossentropy: 0.2409\n",
            "Epoch 537/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2407 - binary_crossentropy: 0.2407\n",
            "Epoch 538/800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2405 - binary_crossentropy: 0.2405\n",
            "Epoch 539/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2403 - binary_crossentropy: 0.2403\n",
            "Epoch 540/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2401 - binary_crossentropy: 0.2401\n",
            "Epoch 541/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2399 - binary_crossentropy: 0.2399\n",
            "Epoch 542/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2398 - binary_crossentropy: 0.2398\n",
            "Epoch 543/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2396 - binary_crossentropy: 0.2396\n",
            "Epoch 544/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2394 - binary_crossentropy: 0.2394\n",
            "Epoch 545/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2392 - binary_crossentropy: 0.2392\n",
            "Epoch 546/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2390 - binary_crossentropy: 0.2390\n",
            "Epoch 547/800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2388 - binary_crossentropy: 0.2388\n",
            "Epoch 548/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2386 - binary_crossentropy: 0.2386\n",
            "Epoch 549/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2384 - binary_crossentropy: 0.2384\n",
            "Epoch 550/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2382 - binary_crossentropy: 0.2382\n",
            "Epoch 551/800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2380 - binary_crossentropy: 0.2380\n",
            "Epoch 552/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2378 - binary_crossentropy: 0.2378\n",
            "Epoch 553/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2376 - binary_crossentropy: 0.2376\n",
            "Epoch 554/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2374 - binary_crossentropy: 0.2374\n",
            "Epoch 555/800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2372 - binary_crossentropy: 0.2372\n",
            "Epoch 556/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2370 - binary_crossentropy: 0.2370\n",
            "Epoch 557/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2368 - binary_crossentropy: 0.2368\n",
            "Epoch 558/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2367 - binary_crossentropy: 0.2367\n",
            "Epoch 559/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2365 - binary_crossentropy: 0.2365\n",
            "Epoch 560/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2363 - binary_crossentropy: 0.2363\n",
            "Epoch 561/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2361 - binary_crossentropy: 0.2361\n",
            "Epoch 562/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2359 - binary_crossentropy: 0.2359\n",
            "Epoch 563/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2357 - binary_crossentropy: 0.2357\n",
            "Epoch 564/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2355 - binary_crossentropy: 0.2355\n",
            "Epoch 565/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2353 - binary_crossentropy: 0.2353\n",
            "Epoch 566/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2351 - binary_crossentropy: 0.2351\n",
            "Epoch 567/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2349 - binary_crossentropy: 0.2349\n",
            "Epoch 568/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2348 - binary_crossentropy: 0.2348\n",
            "Epoch 569/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2346 - binary_crossentropy: 0.2346\n",
            "Epoch 570/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2344 - binary_crossentropy: 0.2344\n",
            "Epoch 571/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2342 - binary_crossentropy: 0.2342\n",
            "Epoch 572/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2340 - binary_crossentropy: 0.2340\n",
            "Epoch 573/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2338 - binary_crossentropy: 0.2338\n",
            "Epoch 574/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2336 - binary_crossentropy: 0.2336\n",
            "Epoch 575/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2334 - binary_crossentropy: 0.2334\n",
            "Epoch 576/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2333 - binary_crossentropy: 0.2333\n",
            "Epoch 577/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2331 - binary_crossentropy: 0.2331\n",
            "Epoch 578/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2329 - binary_crossentropy: 0.2329\n",
            "Epoch 579/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2327 - binary_crossentropy: 0.2327\n",
            "Epoch 580/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2325 - binary_crossentropy: 0.2325\n",
            "Epoch 581/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2323 - binary_crossentropy: 0.2323\n",
            "Epoch 582/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2321 - binary_crossentropy: 0.2321\n",
            "Epoch 583/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2320 - binary_crossentropy: 0.2320\n",
            "Epoch 584/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2318 - binary_crossentropy: 0.2318\n",
            "Epoch 585/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2316 - binary_crossentropy: 0.2316\n",
            "Epoch 586/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2314 - binary_crossentropy: 0.2314\n",
            "Epoch 587/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2312 - binary_crossentropy: 0.2312\n",
            "Epoch 588/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2310 - binary_crossentropy: 0.2310\n",
            "Epoch 589/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2309 - binary_crossentropy: 0.2309\n",
            "Epoch 590/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2307 - binary_crossentropy: 0.2307\n",
            "Epoch 591/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2305 - binary_crossentropy: 0.2305\n",
            "Epoch 592/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2303 - binary_crossentropy: 0.2303\n",
            "Epoch 593/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2301 - binary_crossentropy: 0.2301\n",
            "Epoch 594/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2299 - binary_crossentropy: 0.2299\n",
            "Epoch 595/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2298 - binary_crossentropy: 0.2298\n",
            "Epoch 596/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2296 - binary_crossentropy: 0.2296\n",
            "Epoch 597/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2294 - binary_crossentropy: 0.2294\n",
            "Epoch 598/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2292 - binary_crossentropy: 0.2292\n",
            "Epoch 599/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2290 - binary_crossentropy: 0.2290\n",
            "Epoch 600/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2289 - binary_crossentropy: 0.2289\n",
            "Epoch 601/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2287 - binary_crossentropy: 0.2287\n",
            "Epoch 602/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2285 - binary_crossentropy: 0.2285\n",
            "Epoch 603/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2283 - binary_crossentropy: 0.2283\n",
            "Epoch 604/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2281 - binary_crossentropy: 0.2281\n",
            "Epoch 605/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2280 - binary_crossentropy: 0.2280\n",
            "Epoch 606/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2278 - binary_crossentropy: 0.2278\n",
            "Epoch 607/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2276 - binary_crossentropy: 0.2276\n",
            "Epoch 608/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2274 - binary_crossentropy: 0.2274\n",
            "Epoch 609/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2272 - binary_crossentropy: 0.2272\n",
            "Epoch 610/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2271 - binary_crossentropy: 0.2271\n",
            "Epoch 611/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2269 - binary_crossentropy: 0.2269\n",
            "Epoch 612/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2267 - binary_crossentropy: 0.2267\n",
            "Epoch 613/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2265 - binary_crossentropy: 0.2265\n",
            "Epoch 614/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2264 - binary_crossentropy: 0.2264\n",
            "Epoch 615/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2262 - binary_crossentropy: 0.2262\n",
            "Epoch 616/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2260 - binary_crossentropy: 0.2260\n",
            "Epoch 617/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2258 - binary_crossentropy: 0.2258\n",
            "Epoch 618/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2257 - binary_crossentropy: 0.2257\n",
            "Epoch 619/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2255 - binary_crossentropy: 0.2255\n",
            "Epoch 620/800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2253 - binary_crossentropy: 0.2253\n",
            "Epoch 621/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2251 - binary_crossentropy: 0.2251\n",
            "Epoch 622/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2250 - binary_crossentropy: 0.2250\n",
            "Epoch 623/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2248 - binary_crossentropy: 0.2248\n",
            "Epoch 624/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2246 - binary_crossentropy: 0.2246\n",
            "Epoch 625/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2244 - binary_crossentropy: 0.2244\n",
            "Epoch 626/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2243 - binary_crossentropy: 0.2243\n",
            "Epoch 627/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2241 - binary_crossentropy: 0.2241\n",
            "Epoch 628/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2239 - binary_crossentropy: 0.2239\n",
            "Epoch 629/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2237 - binary_crossentropy: 0.2237\n",
            "Epoch 630/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2236 - binary_crossentropy: 0.2236\n",
            "Epoch 631/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2234 - binary_crossentropy: 0.2234\n",
            "Epoch 632/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2232 - binary_crossentropy: 0.2232\n",
            "Epoch 633/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2231 - binary_crossentropy: 0.2231\n",
            "Epoch 634/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2229 - binary_crossentropy: 0.2229\n",
            "Epoch 635/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2227 - binary_crossentropy: 0.2227\n",
            "Epoch 636/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2225 - binary_crossentropy: 0.2225\n",
            "Epoch 637/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2224 - binary_crossentropy: 0.2224\n",
            "Epoch 638/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2222 - binary_crossentropy: 0.2222\n",
            "Epoch 639/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2220 - binary_crossentropy: 0.2220\n",
            "Epoch 640/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2219 - binary_crossentropy: 0.2219\n",
            "Epoch 641/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2217 - binary_crossentropy: 0.2217\n",
            "Epoch 642/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2215 - binary_crossentropy: 0.2215\n",
            "Epoch 643/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2213 - binary_crossentropy: 0.2213\n",
            "Epoch 644/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2212 - binary_crossentropy: 0.2212\n",
            "Epoch 645/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2210 - binary_crossentropy: 0.2210\n",
            "Epoch 646/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2208 - binary_crossentropy: 0.2208\n",
            "Epoch 647/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2207 - binary_crossentropy: 0.2207\n",
            "Epoch 648/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2205 - binary_crossentropy: 0.2205\n",
            "Epoch 649/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2203 - binary_crossentropy: 0.2203\n",
            "Epoch 650/800\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2202 - binary_crossentropy: 0.2202\n",
            "Epoch 651/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2200 - binary_crossentropy: 0.2200\n",
            "Epoch 652/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2198 - binary_crossentropy: 0.2198\n",
            "Epoch 653/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2197 - binary_crossentropy: 0.2197\n",
            "Epoch 654/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2195 - binary_crossentropy: 0.2195\n",
            "Epoch 655/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2193 - binary_crossentropy: 0.2193\n",
            "Epoch 656/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2192 - binary_crossentropy: 0.2192\n",
            "Epoch 657/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2190 - binary_crossentropy: 0.2190\n",
            "Epoch 658/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2188 - binary_crossentropy: 0.2188\n",
            "Epoch 659/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2187 - binary_crossentropy: 0.2187\n",
            "Epoch 660/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2185 - binary_crossentropy: 0.2185\n",
            "Epoch 661/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2183 - binary_crossentropy: 0.2183\n",
            "Epoch 662/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2182 - binary_crossentropy: 0.2182\n",
            "Epoch 663/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2180 - binary_crossentropy: 0.2180\n",
            "Epoch 664/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2178 - binary_crossentropy: 0.2178\n",
            "Epoch 665/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2177 - binary_crossentropy: 0.2177\n",
            "Epoch 666/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2175 - binary_crossentropy: 0.2175\n",
            "Epoch 667/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2174 - binary_crossentropy: 0.2174\n",
            "Epoch 668/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2172 - binary_crossentropy: 0.2172\n",
            "Epoch 669/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2170 - binary_crossentropy: 0.2170\n",
            "Epoch 670/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2169 - binary_crossentropy: 0.2169\n",
            "Epoch 671/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2167 - binary_crossentropy: 0.2167\n",
            "Epoch 672/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2165 - binary_crossentropy: 0.2165\n",
            "Epoch 673/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2164 - binary_crossentropy: 0.2164\n",
            "Epoch 674/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2162 - binary_crossentropy: 0.2162\n",
            "Epoch 675/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2160 - binary_crossentropy: 0.2160\n",
            "Epoch 676/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2159 - binary_crossentropy: 0.2159\n",
            "Epoch 677/800\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2157 - binary_crossentropy: 0.2157\n",
            "Epoch 678/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2156 - binary_crossentropy: 0.2156\n",
            "Epoch 679/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2154 - binary_crossentropy: 0.2154\n",
            "Epoch 680/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2152 - binary_crossentropy: 0.2152\n",
            "Epoch 681/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2151 - binary_crossentropy: 0.2151\n",
            "Epoch 682/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2149 - binary_crossentropy: 0.2149\n",
            "Epoch 683/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2148 - binary_crossentropy: 0.2148\n",
            "Epoch 684/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2146 - binary_crossentropy: 0.2146\n",
            "Epoch 685/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2144 - binary_crossentropy: 0.2144\n",
            "Epoch 686/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2143 - binary_crossentropy: 0.2143\n",
            "Epoch 687/800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2141 - binary_crossentropy: 0.2141\n",
            "Epoch 688/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2140 - binary_crossentropy: 0.2140\n",
            "Epoch 689/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2138 - binary_crossentropy: 0.2138\n",
            "Epoch 690/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2136 - binary_crossentropy: 0.2136\n",
            "Epoch 691/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2135 - binary_crossentropy: 0.2135\n",
            "Epoch 692/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2133 - binary_crossentropy: 0.2133\n",
            "Epoch 693/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2132 - binary_crossentropy: 0.2132\n",
            "Epoch 694/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2130 - binary_crossentropy: 0.2130\n",
            "Epoch 695/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2129 - binary_crossentropy: 0.2129\n",
            "Epoch 696/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2127 - binary_crossentropy: 0.2127\n",
            "Epoch 697/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2125 - binary_crossentropy: 0.2125\n",
            "Epoch 698/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2124 - binary_crossentropy: 0.2124\n",
            "Epoch 699/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2122 - binary_crossentropy: 0.2122\n",
            "Epoch 700/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2121 - binary_crossentropy: 0.2121\n",
            "Epoch 701/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2119 - binary_crossentropy: 0.2119\n",
            "Epoch 702/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2118 - binary_crossentropy: 0.2118\n",
            "Epoch 703/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2116 - binary_crossentropy: 0.2116\n",
            "Epoch 704/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2114 - binary_crossentropy: 0.2114\n",
            "Epoch 705/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2113 - binary_crossentropy: 0.2113\n",
            "Epoch 706/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2111 - binary_crossentropy: 0.2111\n",
            "Epoch 707/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2110 - binary_crossentropy: 0.2110\n",
            "Epoch 708/800\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2108 - binary_crossentropy: 0.2108\n",
            "Epoch 709/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2107 - binary_crossentropy: 0.2107\n",
            "Epoch 710/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2105 - binary_crossentropy: 0.2105\n",
            "Epoch 711/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2104 - binary_crossentropy: 0.2104\n",
            "Epoch 712/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2102 - binary_crossentropy: 0.2102\n",
            "Epoch 713/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2101 - binary_crossentropy: 0.2101\n",
            "Epoch 714/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2099 - binary_crossentropy: 0.2099\n",
            "Epoch 715/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2097 - binary_crossentropy: 0.2097\n",
            "Epoch 716/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2096 - binary_crossentropy: 0.2096\n",
            "Epoch 717/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2094 - binary_crossentropy: 0.2094\n",
            "Epoch 718/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2093 - binary_crossentropy: 0.2093\n",
            "Epoch 719/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2091 - binary_crossentropy: 0.2091\n",
            "Epoch 720/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2090 - binary_crossentropy: 0.2090\n",
            "Epoch 721/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2088 - binary_crossentropy: 0.2088\n",
            "Epoch 722/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2087 - binary_crossentropy: 0.2087\n",
            "Epoch 723/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2085 - binary_crossentropy: 0.2085\n",
            "Epoch 724/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2084 - binary_crossentropy: 0.2084\n",
            "Epoch 725/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2082 - binary_crossentropy: 0.2082\n",
            "Epoch 726/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2081 - binary_crossentropy: 0.2081\n",
            "Epoch 727/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2079 - binary_crossentropy: 0.2079\n",
            "Epoch 728/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2078 - binary_crossentropy: 0.2078\n",
            "Epoch 729/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2076 - binary_crossentropy: 0.2076\n",
            "Epoch 730/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2075 - binary_crossentropy: 0.2075\n",
            "Epoch 731/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2073 - binary_crossentropy: 0.2073\n",
            "Epoch 732/800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2072 - binary_crossentropy: 0.2072\n",
            "Epoch 733/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2070 - binary_crossentropy: 0.2070\n",
            "Epoch 734/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2069 - binary_crossentropy: 0.2069\n",
            "Epoch 735/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2067 - binary_crossentropy: 0.2067\n",
            "Epoch 736/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2066 - binary_crossentropy: 0.2066\n",
            "Epoch 737/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2064 - binary_crossentropy: 0.2064\n",
            "Epoch 738/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2063 - binary_crossentropy: 0.2063\n",
            "Epoch 739/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2061 - binary_crossentropy: 0.2061\n",
            "Epoch 740/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2060 - binary_crossentropy: 0.2060\n",
            "Epoch 741/800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2058 - binary_crossentropy: 0.2058\n",
            "Epoch 742/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2057 - binary_crossentropy: 0.2057\n",
            "Epoch 743/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2055 - binary_crossentropy: 0.2055\n",
            "Epoch 744/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2054 - binary_crossentropy: 0.2054\n",
            "Epoch 745/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2052 - binary_crossentropy: 0.2052\n",
            "Epoch 746/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2051 - binary_crossentropy: 0.2051\n",
            "Epoch 747/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2049 - binary_crossentropy: 0.2049\n",
            "Epoch 748/800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2048 - binary_crossentropy: 0.2048\n",
            "Epoch 749/800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2047 - binary_crossentropy: 0.2047\n",
            "Epoch 750/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2045 - binary_crossentropy: 0.2045\n",
            "Epoch 751/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2044 - binary_crossentropy: 0.2044\n",
            "Epoch 752/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2042 - binary_crossentropy: 0.2042\n",
            "Epoch 753/800\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2041 - binary_crossentropy: 0.2041\n",
            "Epoch 754/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2039 - binary_crossentropy: 0.2039\n",
            "Epoch 755/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2038 - binary_crossentropy: 0.2038\n",
            "Epoch 756/800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2036 - binary_crossentropy: 0.2036\n",
            "Epoch 757/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2035 - binary_crossentropy: 0.2035\n",
            "Epoch 758/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2033 - binary_crossentropy: 0.2033\n",
            "Epoch 759/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2032 - binary_crossentropy: 0.2032\n",
            "Epoch 760/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2031 - binary_crossentropy: 0.2031\n",
            "Epoch 761/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2029 - binary_crossentropy: 0.2029\n",
            "Epoch 762/800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2028 - binary_crossentropy: 0.2028\n",
            "Epoch 763/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2026 - binary_crossentropy: 0.2026\n",
            "Epoch 764/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2025 - binary_crossentropy: 0.2025\n",
            "Epoch 765/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2023 - binary_crossentropy: 0.2023\n",
            "Epoch 766/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2022 - binary_crossentropy: 0.2022\n",
            "Epoch 767/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2020 - binary_crossentropy: 0.2020\n",
            "Epoch 768/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2019 - binary_crossentropy: 0.2019\n",
            "Epoch 769/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2018 - binary_crossentropy: 0.2018\n",
            "Epoch 770/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2016 - binary_crossentropy: 0.2016\n",
            "Epoch 771/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2015 - binary_crossentropy: 0.2015\n",
            "Epoch 772/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2013 - binary_crossentropy: 0.2013\n",
            "Epoch 773/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2012 - binary_crossentropy: 0.2012\n",
            "Epoch 774/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2011 - binary_crossentropy: 0.2011\n",
            "Epoch 775/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2009 - binary_crossentropy: 0.2009\n",
            "Epoch 776/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2008 - binary_crossentropy: 0.2008\n",
            "Epoch 777/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2006 - binary_crossentropy: 0.2006\n",
            "Epoch 778/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2005 - binary_crossentropy: 0.2005\n",
            "Epoch 779/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2003 - binary_crossentropy: 0.2003\n",
            "Epoch 780/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2002 - binary_crossentropy: 0.2002\n",
            "Epoch 781/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2001 - binary_crossentropy: 0.2001\n",
            "Epoch 782/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1999 - binary_crossentropy: 0.1999\n",
            "Epoch 783/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1998 - binary_crossentropy: 0.1998\n",
            "Epoch 784/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1996 - binary_crossentropy: 0.1996\n",
            "Epoch 785/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1995 - binary_crossentropy: 0.1995\n",
            "Epoch 786/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1994 - binary_crossentropy: 0.1994\n",
            "Epoch 787/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1992 - binary_crossentropy: 0.1992\n",
            "Epoch 788/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1991 - binary_crossentropy: 0.1991\n",
            "Epoch 789/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1989 - binary_crossentropy: 0.1989\n",
            "Epoch 790/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1988 - binary_crossentropy: 0.1988\n",
            "Epoch 791/800\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1987 - binary_crossentropy: 0.1987\n",
            "Epoch 792/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1985 - binary_crossentropy: 0.1985\n",
            "Epoch 793/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1984 - binary_crossentropy: 0.1984\n",
            "Epoch 794/800\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1983 - binary_crossentropy: 0.1983\n",
            "Epoch 795/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1981 - binary_crossentropy: 0.1981\n",
            "Epoch 796/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1980 - binary_crossentropy: 0.1980\n",
            "Epoch 797/800\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1978 - binary_crossentropy: 0.1978\n",
            "Epoch 798/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1977 - binary_crossentropy: 0.1977\n",
            "Epoch 799/800\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1976 - binary_crossentropy: 0.1976\n",
            "Epoch 800/800\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1974 - binary_crossentropy: 0.1974\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb6f40efd50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvVCyLC9ySqK"
      },
      "source": [
        "  ## 소프트맥스 회귀 구현(Keras)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeag8LE-2R5g"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPNetoWC2c6q",
        "outputId": "0ebf3920-4048-4bae-a851-7ff723dfa111"
      },
      "source": [
        "df = load_iris()\n",
        "df.keys()"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmuvTPMD2ho9",
        "outputId": "50f6a0cd-0409-42f6-f2fb-8cc5975e4bfd"
      },
      "source": [
        "x_data = np.array(df.data, dtype = np.float32)\n",
        "y_data = np.array(df.target, dtype = np.int32)\n",
        "nb_features = x_data.shape[1]\n",
        "nb_classes = len(set(y_data))\n",
        "print(x_data.shape,y_data.shape,nb_features, nb_classes)"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 4) (150,) 4 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGAegnAa3R9K"
      },
      "source": [
        "# one-hot encoding\n",
        "y_one_hot = tf.one_hot(indices=list(y_data), depth = nb_classes)"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bk9FUR13sK0",
        "outputId": "8761b14d-4218-47bd-961a-52654e734977"
      },
      "source": [
        "from tensorflow.keras.models import Sequential # 케라스의 Sequential()을 임포트\n",
        "from tensorflow.keras.layers import Dense # 케라스의 Dense()를 임포트\n",
        "from tensorflow.keras import optimizers # 케라스의 옵티마이저를 임포트\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# 입력의 차원은 4, 출력의 차원은 3, activation function은 softmax\n",
        "model.add(Dense(3, input_dim=4, activation='softmax'))\n",
        "\n",
        "# 학습률(learning rate, lr)은 0.01로 합니다.\n",
        "sgd = optimizers.SGD(lr=0.01)\n",
        "\n",
        "# 옵티마이저는 경사하강법의 일종인 adam을 사용합니다.\n",
        "# 손실 함수(Loss function)는 크로스 엔트로피 함수를 사용합니다.\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "# 주어진 X와 y데이터에 대해서 오차를 최소화하는 작업을 200번 시도합니다.\n",
        "history = model.fit(x_data, y_one_hot, batch_size=1, epochs=200)"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 1.1259 - accuracy: 0.6667\n",
            "Epoch 2/200\n",
            "150/150 [==============================] - 0s 993us/step - loss: 0.9011 - accuracy: 0.5133\n",
            "Epoch 3/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.8418 - accuracy: 0.4600\n",
            "Epoch 4/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.8040 - accuracy: 0.5000\n",
            "Epoch 5/200\n",
            "150/150 [==============================] - 0s 954us/step - loss: 0.7654 - accuracy: 0.5600\n",
            "Epoch 6/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.7313 - accuracy: 0.5400\n",
            "Epoch 7/200\n",
            "150/150 [==============================] - 0s 968us/step - loss: 0.7069 - accuracy: 0.5333\n",
            "Epoch 8/200\n",
            "150/150 [==============================] - 0s 1000us/step - loss: 0.6835 - accuracy: 0.5400\n",
            "Epoch 9/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.6586 - accuracy: 0.5600\n",
            "Epoch 10/200\n",
            "150/150 [==============================] - 0s 972us/step - loss: 0.6425 - accuracy: 0.5733\n",
            "Epoch 11/200\n",
            "150/150 [==============================] - 0s 976us/step - loss: 0.6240 - accuracy: 0.5867\n",
            "Epoch 12/200\n",
            "150/150 [==============================] - 0s 943us/step - loss: 0.6079 - accuracy: 0.6000\n",
            "Epoch 13/200\n",
            "150/150 [==============================] - 0s 914us/step - loss: 0.5951 - accuracy: 0.6467\n",
            "Epoch 14/200\n",
            "150/150 [==============================] - 0s 935us/step - loss: 0.5827 - accuracy: 0.6533\n",
            "Epoch 15/200\n",
            "150/150 [==============================] - 0s 906us/step - loss: 0.5695 - accuracy: 0.6600\n",
            "Epoch 16/200\n",
            "150/150 [==============================] - 0s 950us/step - loss: 0.5621 - accuracy: 0.6533\n",
            "Epoch 17/200\n",
            "150/150 [==============================] - 0s 978us/step - loss: 0.5500 - accuracy: 0.6800\n",
            "Epoch 18/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.5377 - accuracy: 0.6933\n",
            "Epoch 19/200\n",
            "150/150 [==============================] - 0s 984us/step - loss: 0.5304 - accuracy: 0.6867\n",
            "Epoch 20/200\n",
            "150/150 [==============================] - 0s 951us/step - loss: 0.5202 - accuracy: 0.6933\n",
            "Epoch 21/200\n",
            "150/150 [==============================] - 0s 958us/step - loss: 0.5155 - accuracy: 0.7467\n",
            "Epoch 22/200\n",
            "150/150 [==============================] - 0s 986us/step - loss: 0.5080 - accuracy: 0.7000\n",
            "Epoch 23/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.5016 - accuracy: 0.7400\n",
            "Epoch 24/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.7400\n",
            "Epoch 25/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.4849 - accuracy: 0.7600\n",
            "Epoch 26/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7400\n",
            "Epoch 27/200\n",
            "150/150 [==============================] - 0s 976us/step - loss: 0.4730 - accuracy: 0.8000\n",
            "Epoch 28/200\n",
            "150/150 [==============================] - 0s 970us/step - loss: 0.4650 - accuracy: 0.8133\n",
            "Epoch 29/200\n",
            "150/150 [==============================] - 0s 981us/step - loss: 0.4601 - accuracy: 0.8000\n",
            "Epoch 30/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.8200\n",
            "Epoch 31/200\n",
            "150/150 [==============================] - 0s 961us/step - loss: 0.4522 - accuracy: 0.8067\n",
            "Epoch 32/200\n",
            "150/150 [==============================] - 0s 964us/step - loss: 0.4439 - accuracy: 0.8867\n",
            "Epoch 33/200\n",
            "150/150 [==============================] - 0s 965us/step - loss: 0.4387 - accuracy: 0.8333\n",
            "Epoch 34/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.4341 - accuracy: 0.8600\n",
            "Epoch 35/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.4299 - accuracy: 0.9000\n",
            "Epoch 36/200\n",
            "150/150 [==============================] - 0s 983us/step - loss: 0.4238 - accuracy: 0.9000\n",
            "Epoch 37/200\n",
            "150/150 [==============================] - 0s 993us/step - loss: 0.4184 - accuracy: 0.9267\n",
            "Epoch 38/200\n",
            "150/150 [==============================] - 0s 923us/step - loss: 0.4171 - accuracy: 0.8933\n",
            "Epoch 39/200\n",
            "150/150 [==============================] - 0s 936us/step - loss: 0.4109 - accuracy: 0.9067\n",
            "Epoch 40/200\n",
            "150/150 [==============================] - 0s 978us/step - loss: 0.4044 - accuracy: 0.9467\n",
            "Epoch 41/200\n",
            "150/150 [==============================] - 0s 941us/step - loss: 0.4021 - accuracy: 0.9133\n",
            "Epoch 42/200\n",
            "150/150 [==============================] - 0s 972us/step - loss: 0.3978 - accuracy: 0.9467\n",
            "Epoch 43/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.3954 - accuracy: 0.9067\n",
            "Epoch 44/200\n",
            "150/150 [==============================] - 0s 994us/step - loss: 0.3898 - accuracy: 0.8933\n",
            "Epoch 45/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.3851 - accuracy: 0.9400\n",
            "Epoch 46/200\n",
            "150/150 [==============================] - 0s 952us/step - loss: 0.3775 - accuracy: 0.9600\n",
            "Epoch 47/200\n",
            "150/150 [==============================] - 0s 990us/step - loss: 0.3799 - accuracy: 0.9200\n",
            "Epoch 48/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.3768 - accuracy: 0.9400\n",
            "Epoch 49/200\n",
            "150/150 [==============================] - 0s 946us/step - loss: 0.3730 - accuracy: 0.9333\n",
            "Epoch 50/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.3663 - accuracy: 0.9200\n",
            "Epoch 51/200\n",
            "150/150 [==============================] - 0s 934us/step - loss: 0.3656 - accuracy: 0.9467\n",
            "Epoch 52/200\n",
            "150/150 [==============================] - 0s 975us/step - loss: 0.3625 - accuracy: 0.9333\n",
            "Epoch 53/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.3576 - accuracy: 0.9400\n",
            "Epoch 54/200\n",
            "150/150 [==============================] - 0s 945us/step - loss: 0.3584 - accuracy: 0.9600\n",
            "Epoch 55/200\n",
            "150/150 [==============================] - 0s 984us/step - loss: 0.3531 - accuracy: 0.9667\n",
            "Epoch 56/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.3473 - accuracy: 0.9667\n",
            "Epoch 57/200\n",
            "150/150 [==============================] - 0s 949us/step - loss: 0.3438 - accuracy: 0.9667\n",
            "Epoch 58/200\n",
            "150/150 [==============================] - 0s 969us/step - loss: 0.3427 - accuracy: 0.9667\n",
            "Epoch 59/200\n",
            "150/150 [==============================] - 0s 988us/step - loss: 0.3377 - accuracy: 0.9600\n",
            "Epoch 60/200\n",
            "150/150 [==============================] - 0s 984us/step - loss: 0.3340 - accuracy: 0.9667\n",
            "Epoch 61/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.9600\n",
            "Epoch 62/200\n",
            "150/150 [==============================] - 0s 999us/step - loss: 0.3279 - accuracy: 0.9800\n",
            "Epoch 63/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.3251 - accuracy: 0.9600\n",
            "Epoch 64/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.3235 - accuracy: 0.9667\n",
            "Epoch 65/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.3187 - accuracy: 0.9733\n",
            "Epoch 66/200\n",
            "150/150 [==============================] - 0s 965us/step - loss: 0.3160 - accuracy: 0.9667\n",
            "Epoch 67/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.3138 - accuracy: 0.9600\n",
            "Epoch 68/200\n",
            "150/150 [==============================] - 0s 964us/step - loss: 0.3121 - accuracy: 0.9533\n",
            "Epoch 69/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.3074 - accuracy: 0.9600\n",
            "Epoch 70/200\n",
            "150/150 [==============================] - 0s 992us/step - loss: 0.3080 - accuracy: 0.9733\n",
            "Epoch 71/200\n",
            "150/150 [==============================] - 0s 921us/step - loss: 0.3046 - accuracy: 0.9733\n",
            "Epoch 72/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2998 - accuracy: 0.9667\n",
            "Epoch 73/200\n",
            "150/150 [==============================] - 0s 994us/step - loss: 0.2988 - accuracy: 0.9667\n",
            "Epoch 74/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2945 - accuracy: 0.9733\n",
            "Epoch 75/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2947 - accuracy: 0.9667\n",
            "Epoch 76/200\n",
            "150/150 [==============================] - 0s 955us/step - loss: 0.2904 - accuracy: 0.9733\n",
            "Epoch 77/200\n",
            "150/150 [==============================] - 0s 944us/step - loss: 0.2884 - accuracy: 0.9733\n",
            "Epoch 78/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2885 - accuracy: 0.9667\n",
            "Epoch 79/200\n",
            "150/150 [==============================] - 0s 941us/step - loss: 0.2862 - accuracy: 0.9733\n",
            "Epoch 80/200\n",
            "150/150 [==============================] - 0s 972us/step - loss: 0.2826 - accuracy: 0.9733\n",
            "Epoch 81/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2805 - accuracy: 0.9600\n",
            "Epoch 82/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2772 - accuracy: 0.9667\n",
            "Epoch 83/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2742 - accuracy: 0.9667\n",
            "Epoch 84/200\n",
            "150/150 [==============================] - 0s 996us/step - loss: 0.2736 - accuracy: 0.9733\n",
            "Epoch 85/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2711 - accuracy: 0.9600\n",
            "Epoch 86/200\n",
            "150/150 [==============================] - 0s 939us/step - loss: 0.2680 - accuracy: 0.9800\n",
            "Epoch 87/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2653 - accuracy: 0.9733\n",
            "Epoch 88/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2659 - accuracy: 0.9667\n",
            "Epoch 89/200\n",
            "150/150 [==============================] - 0s 941us/step - loss: 0.2642 - accuracy: 0.9667\n",
            "Epoch 90/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2599 - accuracy: 0.9733\n",
            "Epoch 91/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2567 - accuracy: 0.9800\n",
            "Epoch 92/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2568 - accuracy: 0.9733\n",
            "Epoch 93/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2561 - accuracy: 0.9667\n",
            "Epoch 94/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2517 - accuracy: 0.9733\n",
            "Epoch 95/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2524 - accuracy: 0.9733\n",
            "Epoch 96/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.9667\n",
            "Epoch 97/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2477 - accuracy: 0.9733\n",
            "Epoch 98/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2447 - accuracy: 0.9733\n",
            "Epoch 99/200\n",
            "150/150 [==============================] - 0s 972us/step - loss: 0.2455 - accuracy: 0.9667\n",
            "Epoch 100/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2430 - accuracy: 0.9733\n",
            "Epoch 101/200\n",
            "150/150 [==============================] - 0s 950us/step - loss: 0.2409 - accuracy: 0.9667\n",
            "Epoch 102/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2381 - accuracy: 0.9667\n",
            "Epoch 103/200\n",
            "150/150 [==============================] - 0s 995us/step - loss: 0.2377 - accuracy: 0.9733\n",
            "Epoch 104/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2350 - accuracy: 0.9733\n",
            "Epoch 105/200\n",
            "150/150 [==============================] - 0s 1000us/step - loss: 0.2349 - accuracy: 0.9800\n",
            "Epoch 106/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2315 - accuracy: 0.9733\n",
            "Epoch 107/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2310 - accuracy: 0.9667\n",
            "Epoch 108/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2292 - accuracy: 0.9667\n",
            "Epoch 109/200\n",
            "150/150 [==============================] - 0s 975us/step - loss: 0.2294 - accuracy: 0.9733\n",
            "Epoch 110/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2274 - accuracy: 0.9733\n",
            "Epoch 111/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2236 - accuracy: 0.9667\n",
            "Epoch 112/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2234 - accuracy: 0.9667\n",
            "Epoch 113/200\n",
            "150/150 [==============================] - 0s 978us/step - loss: 0.2214 - accuracy: 0.9733\n",
            "Epoch 114/200\n",
            "150/150 [==============================] - 0s 942us/step - loss: 0.2200 - accuracy: 0.9667\n",
            "Epoch 115/200\n",
            "150/150 [==============================] - 0s 971us/step - loss: 0.2186 - accuracy: 0.9733\n",
            "Epoch 116/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2169 - accuracy: 0.9667\n",
            "Epoch 117/200\n",
            "150/150 [==============================] - 0s 1000us/step - loss: 0.2200 - accuracy: 0.9667\n",
            "Epoch 118/200\n",
            "150/150 [==============================] - 0s 996us/step - loss: 0.2167 - accuracy: 0.9733\n",
            "Epoch 119/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2143 - accuracy: 0.9733\n",
            "Epoch 120/200\n",
            "150/150 [==============================] - 0s 999us/step - loss: 0.2122 - accuracy: 0.9667\n",
            "Epoch 121/200\n",
            "150/150 [==============================] - 0s 958us/step - loss: 0.2099 - accuracy: 0.9667\n",
            "Epoch 122/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2099 - accuracy: 0.9667\n",
            "Epoch 123/200\n",
            "150/150 [==============================] - 0s 982us/step - loss: 0.2076 - accuracy: 0.9733\n",
            "Epoch 124/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2073 - accuracy: 0.9667\n",
            "Epoch 125/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2059 - accuracy: 0.9667\n",
            "Epoch 126/200\n",
            "150/150 [==============================] - 0s 964us/step - loss: 0.2054 - accuracy: 0.9733\n",
            "Epoch 127/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.2062 - accuracy: 0.9600\n",
            "Epoch 128/200\n",
            "150/150 [==============================] - 0s 967us/step - loss: 0.2018 - accuracy: 0.9600\n",
            "Epoch 129/200\n",
            "150/150 [==============================] - 0s 963us/step - loss: 0.2007 - accuracy: 0.9733\n",
            "Epoch 130/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1999 - accuracy: 0.9667\n",
            "Epoch 131/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1992 - accuracy: 0.9667\n",
            "Epoch 132/200\n",
            "150/150 [==============================] - 0s 949us/step - loss: 0.1977 - accuracy: 0.9733\n",
            "Epoch 133/200\n",
            "150/150 [==============================] - 0s 979us/step - loss: 0.1954 - accuracy: 0.9733\n",
            "Epoch 134/200\n",
            "150/150 [==============================] - 0s 982us/step - loss: 0.1962 - accuracy: 0.9733\n",
            "Epoch 135/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1939 - accuracy: 0.9600\n",
            "Epoch 136/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1933 - accuracy: 0.9667\n",
            "Epoch 137/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1907 - accuracy: 0.9667\n",
            "Epoch 138/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1931 - accuracy: 0.9667\n",
            "Epoch 139/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1896 - accuracy: 0.9667\n",
            "Epoch 140/200\n",
            "150/150 [==============================] - 0s 989us/step - loss: 0.1882 - accuracy: 0.9733\n",
            "Epoch 141/200\n",
            "150/150 [==============================] - 0s 944us/step - loss: 0.1882 - accuracy: 0.9733\n",
            "Epoch 142/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.9600\n",
            "Epoch 143/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.9733\n",
            "Epoch 144/200\n",
            "150/150 [==============================] - 0s 970us/step - loss: 0.1846 - accuracy: 0.9600\n",
            "Epoch 145/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.9600\n",
            "Epoch 146/200\n",
            "150/150 [==============================] - 0s 979us/step - loss: 0.1821 - accuracy: 0.9667\n",
            "Epoch 147/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.9667\n",
            "Epoch 148/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1804 - accuracy: 0.9667\n",
            "Epoch 149/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.9667\n",
            "Epoch 150/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1793 - accuracy: 0.9733\n",
            "Epoch 151/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1775 - accuracy: 0.9667\n",
            "Epoch 152/200\n",
            "150/150 [==============================] - 0s 976us/step - loss: 0.1767 - accuracy: 0.9800\n",
            "Epoch 153/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1763 - accuracy: 0.9733\n",
            "Epoch 154/200\n",
            "150/150 [==============================] - 0s 987us/step - loss: 0.1761 - accuracy: 0.9733\n",
            "Epoch 155/200\n",
            "150/150 [==============================] - 0s 993us/step - loss: 0.1755 - accuracy: 0.9600\n",
            "Epoch 156/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1733 - accuracy: 0.9667\n",
            "Epoch 157/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1724 - accuracy: 0.9733\n",
            "Epoch 158/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1726 - accuracy: 0.9600\n",
            "Epoch 159/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1703 - accuracy: 0.9667\n",
            "Epoch 160/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1700 - accuracy: 0.9667\n",
            "Epoch 161/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1684 - accuracy: 0.9667\n",
            "Epoch 162/200\n",
            "150/150 [==============================] - 0s 953us/step - loss: 0.1670 - accuracy: 0.9667\n",
            "Epoch 163/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1679 - accuracy: 0.9667\n",
            "Epoch 164/200\n",
            "150/150 [==============================] - 0s 941us/step - loss: 0.1664 - accuracy: 0.9667\n",
            "Epoch 165/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1666 - accuracy: 0.9667\n",
            "Epoch 166/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1655 - accuracy: 0.9600\n",
            "Epoch 167/200\n",
            "150/150 [==============================] - 0s 966us/step - loss: 0.1654 - accuracy: 0.9667\n",
            "Epoch 168/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1635 - accuracy: 0.9667\n",
            "Epoch 169/200\n",
            "150/150 [==============================] - 0s 982us/step - loss: 0.1643 - accuracy: 0.9800\n",
            "Epoch 170/200\n",
            "150/150 [==============================] - 0s 962us/step - loss: 0.1614 - accuracy: 0.9667\n",
            "Epoch 171/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1624 - accuracy: 0.9667\n",
            "Epoch 172/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1614 - accuracy: 0.9600\n",
            "Epoch 173/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1616 - accuracy: 0.9667\n",
            "Epoch 174/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1611 - accuracy: 0.9667\n",
            "Epoch 175/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1604 - accuracy: 0.9667\n",
            "Epoch 176/200\n",
            "150/150 [==============================] - 0s 980us/step - loss: 0.1588 - accuracy: 0.9667\n",
            "Epoch 177/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1567 - accuracy: 0.9667\n",
            "Epoch 178/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1572 - accuracy: 0.9667\n",
            "Epoch 179/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1570 - accuracy: 0.9667\n",
            "Epoch 180/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1564 - accuracy: 0.9733\n",
            "Epoch 181/200\n",
            "150/150 [==============================] - 0s 986us/step - loss: 0.1573 - accuracy: 0.9667\n",
            "Epoch 182/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1534 - accuracy: 0.9667\n",
            "Epoch 183/200\n",
            "150/150 [==============================] - 0s 978us/step - loss: 0.1532 - accuracy: 0.9733\n",
            "Epoch 184/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1541 - accuracy: 0.9667\n",
            "Epoch 185/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1525 - accuracy: 0.9733\n",
            "Epoch 186/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1526 - accuracy: 0.9667\n",
            "Epoch 187/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1512 - accuracy: 0.9667\n",
            "Epoch 188/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1508 - accuracy: 0.9667\n",
            "Epoch 189/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1499 - accuracy: 0.9667\n",
            "Epoch 190/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1495 - accuracy: 0.9867\n",
            "Epoch 191/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1490 - accuracy: 0.9667\n",
            "Epoch 192/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1483 - accuracy: 0.9667\n",
            "Epoch 193/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1486 - accuracy: 0.9733\n",
            "Epoch 194/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1470 - accuracy: 0.9733\n",
            "Epoch 195/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1456 - accuracy: 0.9733\n",
            "Epoch 196/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1454 - accuracy: 0.9800\n",
            "Epoch 197/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1460 - accuracy: 0.9667\n",
            "Epoch 198/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1448 - accuracy: 0.9667\n",
            "Epoch 199/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1442 - accuracy: 0.9667\n",
            "Epoch 200/200\n",
            "150/150 [==============================] - 0s 1ms/step - loss: 0.1432 - accuracy: 0.9667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIDO4E2X4dz9"
      },
      "source": [
        "## 소프트맥스 회귀 구현(Tape)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfq7vujJ3wW9"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris"
      ],
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shR31aZs39DJ",
        "outputId": "2159e58e-0416-4e41-9b35-61184e784c0c"
      },
      "source": [
        "df = load_iris()\n",
        "df.keys()"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdOQH2Tf3_oV",
        "outputId": "1004de57-a690-455e-c882-e6f931ac4ab9"
      },
      "source": [
        "x_data = np.array(df.data, dtype = np.float32)\n",
        "y_data = np.array(df.target, dtype = np.int32)\n",
        "\n",
        "nb_features = x_data.shape[1]\n",
        "nb_classes = len(set(y_data))\n",
        "print(x_data.shape,y_data.shape,nb_features,nb_classes)\n",
        "y_ont_hot = tf.one_hot(indices = list(y_data), depth = nb_classes)"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 4) (150,) 4 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr2CeGdJ4Yjx",
        "outputId": "02495207-3511-461d-cc16-159bcb481fbb"
      },
      "source": [
        "tf.random.set_seed(2021)\n",
        "W = tf.Variable(tf.random.normal(shape = [nb_features, nb_classes]))\n",
        "b = tf.Variable(tf.random.normal(shape = [nb_classes]))\n",
        "print(W.numpy())\n",
        "print(b.numpy())"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.0473857  -0.12665796  0.5701126 ]\n",
            " [-1.2995517   0.68507546 -0.6931981 ]\n",
            " [-0.14386335  0.86525923  1.4287399 ]\n",
            " [-0.8128876  -0.05127564 -0.14279948]]\n",
            "[-0.5503563  1.0144334 -0.9311876]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0liowOZY_CSD"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FI4D6n6YB5f7",
        "outputId": "3993b761-f3aa-4f86-c69c-70a5f4907e4b"
      },
      "source": [
        "#learning_rate\n",
        "learning_rate = 0.01\n",
        "\n",
        "#softmax function\n",
        "@tf.function\n",
        "def softmax(x):\n",
        "  # 3차원 텐서 사이에서 행렬 곱(tf.matmul)\n",
        "  return tf.nn.softmax(tf.matmul(x_data,W) + b)\n",
        "\n",
        "# for Training\n",
        "for i in range(10000):\n",
        "  with tf.GradientTape() as tape:\n",
        "    #입력된 X별로 세 개의 class에 대한 예측값 계산\n",
        "    sm = softmax(x_data)\n",
        "    \n",
        "    #예측값에 로그를 취한 후 실제 y값과 곱하는데, 이 과정을 모든 예측값과 관측치에 적용\n",
        "    #그 후 값을 평균을 취해주고 -를 곱하여 비용 계산\n",
        "    cost = -tf.reduce_mean(tf.reduce_sum(y_one_hot*tf.math.log(sm),axis = 1))\n",
        "\n",
        "  #아래 코드가 with의 절에 있든, 그 밖에 있든 결과상 차이 없음\n",
        "  \n",
        "  W_grad,b_grad = tape.gradient(cost,[W,b])\n",
        "  #tape.gradient()로도 gradient를 계산할 수 있지만, compute_gradients도 가능\n",
        "  #동일한 역할을 수행하나, tape에 저장된 연산 결과를 토대로 특정 weights를 업데이트 시 tape.gradient를 쓰고\n",
        "  #tape를 미사용 시 직접 gradient를 계산할 경우 compute_gradients를 사용함\n",
        "  \n",
        "  #또한 optimizer.apply_gradients로도 weight를 업데이트할 수 있지만\n",
        "  #optimizer를 쓰지 않는 경우 직집적으로 learning_rate를 곱하여 Weight 및 bias를 계산해줌\n",
        "  #아래 assign_sub를 하면 W에 ()안의 값만큼 weight를 변환함\n",
        "  W.assign_sub(learning_rate * W_grad)\n",
        "  b.assign_sub(learning_rate * b_grad)\n",
        "  if (i+1) % 1000 == 0:\n",
        "        print(\">>> #%s \\n Weights: \\n%s \\n Bias: \\n%s \\n cost: %s\\n\" % (i+1, W.numpy(), b.numpy(), cost.numpy()))"
      ],
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> #1000 \n",
            " Weights: \n",
            "[[ 1.6149405  -0.08084445 -0.04325487]\n",
            " [-0.34560114  0.04531072 -1.0073849 ]\n",
            " [-0.9433694   1.1390452   1.9544592 ]\n",
            " [-1.1922408  -0.23309867  0.41837618]] \n",
            " Bias: \n",
            "[-0.35298625  1.0165349  -1.130658  ] \n",
            " cost: 0.34616858\n",
            "\n",
            ">>> #2000 \n",
            " Weights: \n",
            "[[ 1.7114769   0.12960836 -0.35024437]\n",
            " [-0.05019419 -0.08555552 -1.1719257 ]\n",
            " [-1.299022    1.0721405   2.3770175 ]\n",
            " [-1.3511709  -0.48280838  0.8270172 ]] \n",
            " Bias: \n",
            "[-0.2996098  1.0910336 -1.2585324] \n",
            " cost: 0.25822216\n",
            "\n",
            ">>> #3000 \n",
            " Weights: \n",
            "[[ 1.7842565   0.27599204 -0.56940854]\n",
            " [ 0.15832108 -0.15490103 -1.3110955 ]\n",
            " [-1.546414    1.0098495   2.6867008 ]\n",
            " [-1.4635335  -0.6700696   1.1266425 ]] \n",
            " Bias: \n",
            "[-0.26111662  1.1551049  -1.3610975 ] \n",
            " cost: 0.21221003\n",
            "\n",
            ">>> #4000 \n",
            " Weights: \n",
            "[[ 1.8430264   0.38329026 -0.7354771 ]\n",
            " [ 0.3211854  -0.19609612 -1.4327643 ]\n",
            " [-1.7393829   0.95986444  2.9296522 ]\n",
            " [-1.5522476  -0.8166467   1.3619335 ]] \n",
            " Bias: \n",
            "[-0.23062427  1.2114524  -1.4479376 ] \n",
            " cost: 0.18401949\n",
            "\n",
            ">>> #5000 \n",
            " Weights: \n",
            "[[ 1.8924683   0.46582147 -0.8674509 ]\n",
            " [ 0.45516452 -0.22148022 -1.5413587 ]\n",
            " [-1.8983575   0.91939026  3.1290991 ]\n",
            " [-1.6260544  -0.9366749   1.5557679 ]] \n",
            " Bias: \n",
            "[-0.20527712  1.2623681  -1.5242008 ] \n",
            " cost: 0.1649412\n",
            "\n",
            ">>> #6000 \n",
            " Weights: \n",
            "[[ 1.9352429   0.53166157 -0.9760668 ]\n",
            " [ 0.5691368  -0.23710625 -1.6397041 ]\n",
            " [-2.0338712   0.8858979   3.2981043 ]\n",
            " [-1.6894933  -1.0383573   1.7208897 ]] \n",
            " Bias: \n",
            "[-0.18353783  1.3092815  -1.5928531 ] \n",
            " cost: 0.15111907\n",
            "\n",
            ">>> #7000 \n",
            " Weights: \n",
            "[[ 1.9730079   0.5856577  -1.0678272 ]\n",
            " [ 0.66841507 -0.24635258 -1.7297357 ]\n",
            " [-2.152165    0.8576304   3.4446628 ]\n",
            " [-1.7452692  -1.1266891   1.8649986 ]] \n",
            " Bias: \n",
            "[-0.16447446  1.3531082  -1.6557432 ] \n",
            " cost: 0.14060234\n",
            "\n",
            ">>> #8000 \n",
            " Weights: \n",
            "[[ 2.006861    0.6308984  -1.1469218 ]\n",
            " [ 0.75643575 -0.25125948 -1.8128483 ]\n",
            " [-2.2572544   0.83338004  3.5739994 ]\n",
            " [-1.7951342  -1.2048932   1.9930679 ]] \n",
            " Bias: \n",
            "[-0.14747852  1.3944676  -1.7140983 ] \n",
            " cost: 0.13230237\n",
            "\n",
            ">>> #9000 \n",
            " Weights: \n",
            "[[ 2.0375698   0.6694537  -1.2161894 ]\n",
            " [ 0.83555007 -0.2531324  -1.8900887 ]\n",
            " [-2.351884    0.8122963   3.6897082 ]\n",
            " [-1.8402908  -1.2751541   2.108486  ]] \n",
            " Bias: \n",
            "[-0.13212946  1.4337988  -1.7687781 ] \n",
            " cost: 0.12556432\n",
            "\n",
            ">>> #10000 \n",
            " Weights: \n",
            "[[ 2.0656939   0.7027701  -1.2776328 ]\n",
            " [ 0.9074366  -0.25284043 -1.9622651 ]\n",
            " [-2.4380138   0.7937637   3.7943652 ]\n",
            " [-1.881603   -1.3390175   2.2136614 ]] \n",
            " Bias: \n",
            "[-0.11812525  1.4714233  -1.8204072 ] \n",
            " cost: 0.11997034\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wEqJcT6FDt1",
        "outputId": "83df4ed6-63fc-4ae5-b33c-2d7d53fbdeb9"
      },
      "source": [
        "predicted = tf.argmax(softmax(x_data), axis = 1)\n",
        "real = tf.argmax(y_one_hot, axis = 1)\n",
        "def acc(pred,real):\n",
        "  accuracy = tf.reduce_mean(tf.cast(tf.equal(pred,real), dtype = tf.float32))\n",
        "  #tf.equal 논리 결과 값 반환 True / False\n",
        "  #tf.cast 텐서를 새로운 형태로 캐스팅하는데 사\n",
        "    # 부동소수점형에서 정수형으로 바꾼 경우 소수점 버림\n",
        "    # Boolean형태인 경우 True이면 1, False이면 0을 출력\n",
        "  return accuracy\n",
        "\n",
        "print(f\"Accuracy : {acc(predicted,real)}%\")"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9866666793823242%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTcFU-_XNhE8"
      },
      "source": [
        "## 다층 퍼셉트론으로 MNIST 분류\n",
        "---\n",
        "- MNIST 데이터베이스 는 손으로 쓴 숫자들로 이루어진 대형 데이터베이스"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PPe04eFN-EU"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Flatten\n",
        "from tensorflow.keras import optimizers"
      ],
      "execution_count": 383,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRV8K3vNONmr"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist \n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "#x_train, x_test normalize: 값이 0~255 gray값으로 되어 있으며 이 값을 0~1로 표준화\n",
        "x_train,x_test = x_train/255.0, x_test/255.0"
      ],
      "execution_count": 384,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42sr8abVQ281",
        "outputId": "e5641b4d-1a03-4761-d9a2-00fc87b60bd9"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 385,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 385
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRb6pypUPiRu"
      },
      "source": [
        "model = Sequential([\n",
        "                    Flatten(input_shape = (28,28)), #28x28 이미지 데이터를 펴줌\n",
        "                    Dense(128, activation = 'relu'), #활성화 함수로 relu 사용\n",
        "                    Dropout(0.2), #데이터의 20%를 제외한 상태에서 학습 진행\n",
        "                    Dense(10, activation = 'softmax'), #총 10개의 class(0~9)로 분류\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              #분류 모델에서 y값은 one-hot encoding값을 입력해줘야 하지만,\n",
        "              #integer 그대로 사용하고자 할 경우 sparse_categorical_crossentropy, ont-hot encoding이 되어 있으면 categorical_crossentropy\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 386,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfU71lYZQRho",
        "outputId": "45c1e9a1-ece4-4037-8bfb-edff08c450d6"
      },
      "source": [
        "model.fit(x_train,y_train,epochs = 5)\n",
        "model.evaluate(x_test,y_test,verbose = 1)#2 = one line per epoch."
      ],
      "execution_count": 387,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2975 - accuracy: 0.9137\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1409 - accuracy: 0.9576\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1075 - accuracy: 0.9680\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0856 - accuracy: 0.9737\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0736 - accuracy: 0.9765\n",
            "313/313 [==============================] - 1s 1ms/step - loss: 0.0729 - accuracy: 0.9776\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0729101225733757, 0.9775999784469604]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 387
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GX14w_SPex8y",
        "outputId": "b06f77f7-d491-493e-dab5-0c659e403d2b"
      },
      "source": [
        "model.evaluate(x_test,y_test,verbose = 2)"
      ],
      "execution_count": 390,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 0s - loss: 0.0729 - accuracy: 0.9776\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0729101225733757, 0.9775999784469604]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 390
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k-toWqYe9vT",
        "outputId": "1ab730a0-8c32-4c8c-ccae-536e5ae5b7cf"
      },
      "source": [
        "model.evaluate(x_test,y_test,verbose = 0)"
      ],
      "execution_count": 391,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0729101225733757, 0.9775999784469604]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 391
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sA1db8heQikM"
      },
      "source": [
        "## 다층 퍼셉트론으로 20개의 뉴스 그룹 분류하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeWSWejnSO0G"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4inLrccSiTe"
      },
      "source": [
        "newsdata = fetch_20newsgroups(subset = \"train\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0X9yN9vSuUV"
      },
      "source": [
        "subset = \"all\",\"train\",\"test\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUiIm1FLSm8_",
        "outputId": "174fa56d-2d3d-4d14-fa3b-c523b415c33e"
      },
      "source": [
        "print(newsdata.keys())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGiE5ejnS4qF"
      },
      "source": [
        "- data : 훈련에 사용할 데이터\n",
        "- target : 분류 class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tCrysTSS-eg",
        "outputId": "8ea2097b-df10-48ca-c120-ec22121fc51b"
      },
      "source": [
        "print('훈련용 샘플 개수: ', len(newsdata.data))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련용 샘플 개수:  11314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLkrS535TMD-",
        "outputId": "7fc69c81-c4b0-46b1-9bb6-a5a16bb5b8ea"
      },
      "source": [
        "import pprint\n",
        "pp = pprint.PrettyPrinter()\n",
        "print(\"총 주제 개수: \", len(set(newsdata.target)))\n",
        "for i,s in enumerate(newsdata.target_names,start = 1):\n",
        "  print(f\"{i:>2}번 주제: {s}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "총 주제 개수:  20\n",
            " 1번 주제: alt.atheism\n",
            " 2번 주제: comp.graphics\n",
            " 3번 주제: comp.os.ms-windows.misc\n",
            " 4번 주제: comp.sys.ibm.pc.hardware\n",
            " 5번 주제: comp.sys.mac.hardware\n",
            " 6번 주제: comp.windows.x\n",
            " 7번 주제: misc.forsale\n",
            " 8번 주제: rec.autos\n",
            " 9번 주제: rec.motorcycles\n",
            "10번 주제: rec.sport.baseball\n",
            "11번 주제: rec.sport.hockey\n",
            "12번 주제: sci.crypt\n",
            "13번 주제: sci.electronics\n",
            "14번 주제: sci.med\n",
            "15번 주제: sci.space\n",
            "16번 주제: soc.religion.christian\n",
            "17번 주제: talk.politics.guns\n",
            "18번 주제: talk.politics.mideast\n",
            "19번 주제: talk.politics.misc\n",
            "20번 주제: talk.religion.misc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnfSnq9WTSMa",
        "outputId": "0556828c-26c8-41d3-9e9f-5987bcf12e42"
      },
      "source": [
        "#첫 번째 샘플 데이터 확인\n",
        "print(newsdata.data[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: lerxst@wam.umd.edu (where's my thing)\n",
            "Subject: WHAT car is this!?\n",
            "Nntp-Posting-Host: rac3.wam.umd.edu\n",
            "Organization: University of Maryland, College Park\n",
            "Lines: 15\n",
            "\n",
            " I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "\n",
            "Thanks,\n",
            "- IL\n",
            "   ---- brought to you by your neighborhood Lerxst ----\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "QsqJ6hc8UWQc",
        "outputId": "b90eb042-80a1-4b39-9940-aed12e65d15d"
      },
      "source": [
        "#pandas를 이용하여 dataframe 생성\n",
        "data = pd.DataFrame(newsdata.data, columns = [\"email\"])\n",
        "data['target'] = newsdata.target\n",
        "data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>email</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               email  target\n",
              "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...       7\n",
              "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...       4\n",
              "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...       4\n",
              "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1\n",
              "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxXoBW-3UjKZ",
        "outputId": "7ff3e4a6-ed9d-40aa-a56f-f3af5bd14d34"
      },
      "source": [
        "#data 정보 확인\n",
        "data.info()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11314 entries, 0 to 11313\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   email   11314 non-null  object\n",
            " 1   target  11314 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 176.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cjqAydpUqdu",
        "outputId": "fc76a579-1b7f-4835-eeab-77883d866953"
      },
      "source": [
        "# 결측치 확인\n",
        "print(data.isnull().any())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "email     False\n",
            "target    False\n",
            "dtype: bool\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CRg-4IRU2bG",
        "outputId": "e2fb867f-ba75-4783-f434-1ca8b3e6ef28"
      },
      "source": [
        "#중복값 확인\n",
        "print(f\"중복을 제외한 샘플의 수: \", data.email.nunique())\n",
        "print(f\"중복을 제외한 주제의 수: \", data.target.nunique())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "중복을 제외한 샘플의 수:  11314\n",
            "중복을 제외한 주제의 수:  20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "FCWVRZpzVLsg",
        "outputId": "1cae5278-6e9d-44ca-d62f-81085c180050"
      },
      "source": [
        "data.target.value_counts().sort_index().plot.bar()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7d4adf8650>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "id": "bHrBLi9zVfrW",
        "outputId": "71e7468c-e98f-4f91-b8ba-646d3fb05037"
      },
      "source": [
        "data.groupby('target').size().reset_index(name = 'count')\n",
        "# data.groupby('target').agg({\"email\" : \"count\"}).reset_index()\n",
        "# data.groupby('target').email.count().reset_index(name = 'count')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>377</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    target  count\n",
              "0        0    480\n",
              "1        1    584\n",
              "2        2    591\n",
              "3        3    590\n",
              "4        4    578\n",
              "5        5    593\n",
              "6        6    585\n",
              "7        7    594\n",
              "8        8    598\n",
              "9        9    597\n",
              "10      10    600\n",
              "11      11    595\n",
              "12      12    591\n",
              "13      13    594\n",
              "14      14    593\n",
              "15      15    599\n",
              "16      16    546\n",
              "17      17    564\n",
              "18      18    465\n",
              "19      19    377"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fjTkEW3Wp_I"
      },
      "source": [
        "newsdata_test = fetch_20newsgroups(subset = \"test\")\n",
        "train_email = data.email #훈련 데이터 본문\n",
        "train_label = data.target #훈련 데이터 레이블\n",
        "\n",
        "test_email = newsdata_test.data #테스트 데이터 본문\n",
        "test_label = newsdata_test.target #테스트 데이터 레이블"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN5PC5CSW-J3"
      },
      "source": [
        "max_words = 10000 #실습에 사용할 단어 개수 지정\n",
        "num_classes = len(set(train_label)) #20개"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piPvBzgXXTsy"
      },
      "source": [
        "def preprocessing_data(train_data, test_data, mode):\n",
        "  t = Tokenizer(num_words = max_words) \n",
        "  t.fit_on_texts(train_data)\n",
        "  X_train = t.texts_to_matrix(train_data, mode = mode)\n",
        "  X_test = t.texts_to_matrix(test_data, mode = mode)\n",
        "  return X_train,X_test,t.index_word"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVY2-Ji3cK3z"
      },
      "source": [
        "X_train,X_test,index_to_word = preprocessing_data(train_email,test_email,'binary')\n",
        "y_train = to_categorical(train_label,num_classes = num_classes)\n",
        "y_test = to_categorical(test_label,num_classes = num_classes)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlpwC-Gvcnd1",
        "outputId": "99320fb9-6926-4442-b3c0-593b7a48f359"
      },
      "source": [
        "print('훈련 샘플 본문의 크기 : {}'.format(X_train.shape))\n",
        "print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\n",
        "print('테스트 샘플 본문의 크기 : {}'.format(X_test.shape))\n",
        "print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련 샘플 본문의 크기 : (11314, 10000)\n",
            "훈련 샘플 레이블의 크기 : (11314, 20)\n",
            "테스트 샘플 본문의 크기 : (7532, 10000)\n",
            "테스트 샘플 레이블의 크기 : (7532, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2grTJMXQcn0_",
        "outputId": "ce3ae9df-d801-48aa-f800-559511ddf5ee"
      },
      "source": [
        "print(\" 빈도수 상위 1번째 단어: \", index_to_word[1],\"\\n\",\"빈도수 상위 9999번째 단어: \",index_to_word[9999])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 빈도수 상위 1번째 단어:  the \n",
            " 빈도수 상위 9999번째 단어:  mic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2rFEYmKcy3O"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Da4cYeJxdH3I"
      },
      "source": [
        "def fit_and_evaluate(X_train,y_train,X_test,y_test):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(units = 256,input_shape = (10000,),activation = \"relu\"))\n",
        "  model.add(Dense(units = 128, activation = \"relu\"))\n",
        "  model.add(Dense(units = 20, activation = \"softmax\"))\n",
        "\n",
        "  model.compile(optimizer = 'adam', loss = \"categorical_crossentropy\", metrics = ['accuracy'])\n",
        "  model.fit(X_train,y_train,epochs = 5, batch_size = 128, verbose = 1, validation_split=0.1)\n",
        "  score = model.evaluate(X_test,y_test, batch_size = 128, verbose = 0)\n",
        "  return score"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD7bIrGlfDnB",
        "outputId": "4adcc362-3af5-4b95-c3bc-5310200ac949"
      },
      "source": [
        "modes = ['binary','count','tfidf','freq']\n",
        "for mode in modes:\n",
        "  X_train,X_test,_ = preprocessing_data(train_email,test_email,mode)\n",
        "  score = fit_and_evaluate(X_train,y_train,X_test,y_test)\n",
        "  print(mode + \"모드의 정확도: \", score[1])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "80/80 [==============================] - 4s 44ms/step - loss: 1.2841 - accuracy: 0.7102 - val_loss: 0.4663 - val_accuracy: 0.8710\n",
            "Epoch 2/5\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.1839 - accuracy: 0.9637 - val_loss: 0.3318 - val_accuracy: 0.9046\n",
            "Epoch 3/5\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0580 - accuracy: 0.9950 - val_loss: 0.3015 - val_accuracy: 0.9099\n",
            "Epoch 4/5\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0224 - accuracy: 0.9984 - val_loss: 0.3080 - val_accuracy: 0.9064\n",
            "Epoch 5/5\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.0136 - accuracy: 0.9986 - val_loss: 0.3124 - val_accuracy: 0.9099\n",
            "binary모드의 정확도:  0.8130642771720886\n",
            "Epoch 1/5\n",
            "80/80 [==============================] - 4s 42ms/step - loss: 1.5070 - accuracy: 0.6831 - val_loss: 0.5995 - val_accuracy: 0.8728\n",
            "Epoch 2/5\n",
            "80/80 [==============================] - 3s 40ms/step - loss: 0.3186 - accuracy: 0.9402 - val_loss: 0.6038 - val_accuracy: 0.8242\n",
            "Epoch 3/5\n",
            "80/80 [==============================] - 3s 41ms/step - loss: 0.1414 - accuracy: 0.9802 - val_loss: 0.8290 - val_accuracy: 0.8905\n",
            "Epoch 4/5\n",
            "80/80 [==============================] - 3s 41ms/step - loss: 0.0741 - accuracy: 0.9960 - val_loss: 0.4501 - val_accuracy: 0.8887\n",
            "Epoch 5/5\n",
            "80/80 [==============================] - 3s 41ms/step - loss: 0.0567 - accuracy: 0.9983 - val_loss: 0.4127 - val_accuracy: 0.8966\n",
            "count모드의 정확도:  0.8090812563896179\n",
            "Epoch 1/5\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 0.9819 - accuracy: 0.7600 - val_loss: 0.3760 - val_accuracy: 0.9055\n",
            "Epoch 2/5\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0999 - accuracy: 0.9815 - val_loss: 0.6626 - val_accuracy: 0.8852\n",
            "Epoch 3/5\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0575 - accuracy: 0.9947 - val_loss: 0.3428 - val_accuracy: 0.9125\n",
            "Epoch 4/5\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0158 - accuracy: 0.9979 - val_loss: 0.3336 - val_accuracy: 0.9134\n",
            "Epoch 5/5\n",
            "80/80 [==============================] - 3s 43ms/step - loss: 0.0106 - accuracy: 0.9986 - val_loss: 0.3488 - val_accuracy: 0.9117\n",
            "tfidf모드의 정확도:  0.816383421421051\n",
            "Epoch 1/5\n",
            "80/80 [==============================] - 4s 42ms/step - loss: 2.9347 - accuracy: 0.1466 - val_loss: 2.7633 - val_accuracy: 0.2102\n",
            "Epoch 2/5\n",
            "80/80 [==============================] - 3s 40ms/step - loss: 2.3477 - accuracy: 0.4069 - val_loss: 1.9602 - val_accuracy: 0.5751\n",
            "Epoch 3/5\n",
            "80/80 [==============================] - 3s 40ms/step - loss: 1.5602 - accuracy: 0.6470 - val_loss: 1.3551 - val_accuracy: 0.6714\n",
            "Epoch 4/5\n",
            "80/80 [==============================] - 3s 40ms/step - loss: 1.0160 - accuracy: 0.7912 - val_loss: 0.9936 - val_accuracy: 0.7562\n",
            "Epoch 5/5\n",
            "80/80 [==============================] - 3s 40ms/step - loss: 0.6712 - accuracy: 0.8670 - val_loss: 0.7619 - val_accuracy: 0.8110\n",
            "freq모드의 정확도:  0.734067976474762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoAuFfF3faYn"
      },
      "source": [
        "## 다층 퍼셉트론으로 네이버 영화 리뷰 분류"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAFDHT-dh2M5",
        "outputId": "3ee0a86f-bae7-4a66-d561-155c32060774"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/88/f817ef1af6f794e8f11313dcd1549de833f4599abcec82746ab5ed086686/JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 41.0MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: colorama, JPype1, beautifulsoup4, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdBSxvvzh3zv",
        "outputId": "95efba81-ed19-4980-dc35-2ef1756a6caf"
      },
      "source": [
        "import pandas as pd\n",
        "import urllib.request\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ratings_test.txt', <http.client.HTTPMessage at 0x7f82b51edb10>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6vwx1L0h7xx"
      },
      "source": [
        "train_data = pd.read_table('ratings_train.txt')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "qdxMW3XJiA_3",
        "outputId": "f0de106e-9fa1-4aec-9458-460eca64c0b9"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9045019</td>\n",
              "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6483659</td>\n",
              "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                           document  label\n",
              "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
              "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
              "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
              "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
              "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyc-wUOiiIAL"
      },
      "source": [
        "def read_data(filename):\n",
        "  with open(filename,'r') as f:\n",
        "    data = [line.split(\"\\t\") for line in f.read().splitlines()]\n",
        "    #txt file의 헤더(id document label) 제외하기\n",
        "    data = data[1:]\n",
        "  return data\n",
        "\n",
        "train_data = read_data(\"ratings_train.txt\")\n",
        "test_data = read_data(\"ratings_test.txt\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOjBGBqnioYU",
        "outputId": "5ac756da-6e0c-4c88-8875-ed78f2619e39"
      },
      "source": [
        "print(\"train_data shape: \",(len(train_data),len(train_data[0])))\n",
        "print(\"test_data shape: \",(len(test_data),len(test_data[0])))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_data shape:  (150000, 3)\n",
            "test_data shape:  (50000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idg2oMywjSWm",
        "outputId": "af55712d-15fe-4f7f-d097-b241d579e95b"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "okt = Okt()\n",
        "print(okt.pos('아 더빙.. 진짜 짜증나네요 목소리'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('아', 'Exclamation'), ('더빙', 'Noun'), ('..', 'Punctuation'), ('진짜', 'Noun'), ('짜증나네요', 'Adjective'), ('목소리', 'Noun')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il8lmDfNjhg-"
      },
      "source": [
        "import json\n",
        "import os\n",
        "from pprint import pprint\n",
        "def tokenize(doc):\n",
        "  #norm : 정규화, stem : 근어\n",
        "  return ['/'.join(t) for t in okt.pos(doc, norm = True, stem = True)]\n",
        "\n",
        "if os.path.isfile('train_docs.json'):\n",
        "  with open('train_docs.json') as f:\n",
        "    train_docs = json.load(f)\n",
        "  with open('test_docs.json') as f:\n",
        "    test_docs = json.load(f)\n",
        "else:\n",
        "  train_docs = [[tokenize(row[1]),row[2]] for row in train_data]\n",
        "  test_docs = [[tokenize(row[1]),row[2]] for row in test_data]\n",
        "  with open('train_docs.json','w',encoding = 'utf-8') as make_file:\n",
        "    json.dump('train_docs.json',make_file, ensure_ascii=False, indent = \"\\t\")\n",
        "  with open('test_docs.json','w',encoding = 'utf-8') as make_file:\n",
        "    json.dump('test_docs.json',make_file, ensure_ascii=False, indent = \"\\t\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLMf3ylWnfMy",
        "outputId": "f6872277-4b50-4412-ab99-708a8bc4900b"
      },
      "source": [
        "pprint(train_docs[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['아/Exclamation',\n",
            "  '더빙/Noun',\n",
            "  '../Punctuation',\n",
            "  '진짜/Noun',\n",
            "  '짜증나다/Adjective',\n",
            "  '목소리/Noun'],\n",
            " '0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWNn1HQlq-PW",
        "outputId": "28a44459-3037-4508-b92f-8a4ce7dd9758"
      },
      "source": [
        "tokens = [t for d in train_docs for t in d[0]]\n",
        "print(len(tokens))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEEukawdrEl0",
        "outputId": "f4795527-c725-46cb-fb46-51371a5c5a09"
      },
      "source": [
        "import nltk\n",
        "text = nltk.Text(tokens, name = \"NMSC\")\n",
        "#전체 토큰 개수\n",
        "print(len(text.tokens))\n",
        "\n",
        "#중복을 제외한 토큰 개수\n",
        "print(len(set(text.tokens)))\n",
        "\n",
        "#출현 빈도가 높은 상위 10개 토큰\n",
        "print(text.vocab().most_common(10))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "162\n",
            "128\n",
            "[('../Punctuation', 6), ('영화/Noun', 4), ('./Punctuation', 4), ('연기/Noun', 3), ('없다/Adjective', 3), ('하다/Verb', 3), ('도/Josa', 3), ('이/Josa', 3), ('만/Josa', 3), ('.../Punctuation', 2)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2M28zbZrwN2"
      },
      "source": [
        "#상위 10000개 토큰 선택\n",
        "num_tokens = 10000\n",
        "\n",
        "selected_words = [t[0] for t in text.vocab().most_common(num_tokens)]\n",
        "\n",
        "def term_frequency(doc):\n",
        "  return [doc.count(word) for word in selected_words]\n",
        "\n",
        "train_x = [term_frequency(d) for d,_ in train_docs]\n",
        "test_x = [term_frequency(d) for d,_ in test_docs]\n",
        "train_y = [c for _,c in train_docs]\n",
        "test_y = [c for _,c in test_docs]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K4RBOWZs6QZ"
      },
      "source": [
        "import numpy as np\n",
        "x_train = np.array(train_x).astype('float32')\n",
        "x_test = np.array(test_x).astype('float32')\n",
        "\n",
        "y_train = np.array(train_y).astype('float32')\n",
        "y_test = np.array(test_y).astype('float32')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJ_iAUQbtInU",
        "outputId": "be1d6143-ae4f-4024-b9a1-1e1e28d7d17b"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 128)\n",
            "(10, 128)\n",
            "(10,)\n",
            "(10,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "id": "TOwCKvywtKqR",
        "outputId": "00e8198f-97f8-470e-b9e0-d3e7674f8148"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import metrics\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "             loss=losses.binary_crossentropy,\n",
        "             metrics=[metrics.binary_accuracy])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=512)\n",
        "results = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-a539ee2a3d45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m              metrics=[metrics.binary_accuracy])\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    763\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 764\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3289\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:838 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:795 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:255 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 10000 but received input with shape (None, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSFQCy3otSzT"
      },
      "source": [
        "## functional API로 만든 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "725ThT2Cvkws"
      },
      "source": [
        "앞에서 케라스를 사용하여 모델을 설계하는 방식을 sequential API를 사용하였다고 합니다. 그런데 sequential API는 여러층을 공유하거나 다양한 종류의 입력과 출력을 사용하는 등의 복잡한 모델을 만드는 일을 하기에는 한계가 있습니다. 이번에는 복잡한 모델을 생성할 수 있는 방식인 functional API(함수형 API)에 대해서 알아봅니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuttduO_vlEG"
      },
      "source": [
        "functional API는 각 층을 일종의 함수(function)로서 정의합니다. 그리고 각 함수를 조합하기 위한 연산자들을 제공하는데, 이를 이용하여 신경망을 설계합니다. functional API로 FFNN, RNN 등 다양한 모델을 만들면서 기존의 sequential API와의 차이를 이해해봅시다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwE-syT8voHE"
      },
      "source": [
        "### 피드포워드 신경망"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMQ_OKuavpij"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rjMgI7jvzBs"
      },
      "source": [
        "#입력\n",
        "inputs = Input(shape = (10,))\n",
        "\n",
        "hidden1 = Dense(64, activation = \"relu\")(inputs)\n",
        "hidden2 = Dense(32, activation = \"relu\")(hidden1)\n",
        "\n",
        "#출력\n",
        "output = Dense(1, activation = \"sigmoid\")(hidden2)\n",
        "\n",
        "#입력과 출력 정의\n",
        "model = Model(inputs = inputs, outputs = output)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeaQL7h0wPOA",
        "outputId": "0d3ed9f7-5ce0-4cdc-aa87-29b6fbc88c38"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 10)]              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 64)                704       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 2,817\n",
            "Trainable params: 2,817\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvX2wkU0wW6j"
      },
      "source": [
        "### 선형 회귀"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0R1efNZmwYil",
        "outputId": "b3e4ae3b-ab85-4b6d-b61c-3a17a8a98a26"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "inputs = Input(shape = (3,))\n",
        "output = Dense(1, activation = 'linear')(inputs)\n",
        "linear_model = Model(inputs = inputs, outputs= output)\n",
        "linear_model.compile(optimizer='adam',loss = 'mse',metrics = ['msc'])\n",
        "linear_model.summary()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 3)]               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 4         \n",
            "=================================================================\n",
            "Total params: 4\n",
            "Trainable params: 4\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4n7Mmoafw19P"
      },
      "source": [
        "### 로지스틱 회귀"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huThcCV0ww2t",
        "outputId": "9afc8000-5343-4afb-c881-935c1b53e0e8"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "inputs = Input(shape=(3,))\n",
        "output = Dense(1, activation='sigmoid')(inputs)\n",
        "logistic_model = Model(inputs, output)\n",
        "\n",
        "logistic_model.compile(optimizer='sgd', loss = 'binary_crossentropy', metrics=['accuracy'])\n",
        "logistic_model.summary()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 3)]               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1)                 4         \n",
            "=================================================================\n",
            "Total params: 4\n",
            "Trainable params: 4\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37pegODowzbH"
      },
      "source": [
        "### 다중 입력을 받는 모델(models that accepts multiple inputs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIEQakOdxB6E",
        "outputId": "849c4b13-e2f8-4bd7-efac-a6dff0917a63"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# 두 개의 입력층을 정의\n",
        "inputA = Input(shape=(64,))\n",
        "inputB = Input(shape=(128,))\n",
        "\n",
        "# 첫번째 입력층으로부터 분기되어 진행되는 인공 신경망을 정의\n",
        "x = Dense(16, activation=\"relu\")(inputA)\n",
        "x = Dense(8, activation=\"relu\")(x)\n",
        "x = Model(inputs=inputA, outputs=x)\n",
        "\n",
        "# 두번째 입력층으로부터 분기되어 진행되는 인공 신경망을 정의\n",
        "y = Dense(64, activation=\"relu\")(inputB)\n",
        "y = Dense(32, activation=\"relu\")(y)\n",
        "y = Dense(8, activation=\"relu\")(y)\n",
        "y = Model(inputs=inputB, outputs=y)\n",
        "\n",
        "# 두개의 인공 신경망의 출력을 연결(concatenate)\n",
        "result = concatenate([x.output, y.output])\n",
        "\n",
        "# 연결된 값을 입력으로 받는 밀집층을 추가(Dense layer)\n",
        "z = Dense(2, activation=\"relu\")(result)\n",
        "# 선형 회귀를 위해 activation=linear를 설정\n",
        "z = Dense(1, activation=\"linear\")(z)\n",
        "\n",
        "# 결과적으로 이 모델은 두 개의 입력층으로부터 분기되어 진행된 후 마지막에는 하나의 출력을 예측하는 모델이 됨.\n",
        "model = Model(inputs=[x.input, y.input], outputs=z)\n",
        "model.summary()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_15\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_16 (InputLayer)           [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_15 (InputLayer)           [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_37 (Dense)                (None, 64)           8256        input_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_35 (Dense)                (None, 16)           1040        input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_38 (Dense)                (None, 32)           2080        dense_37[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_36 (Dense)                (None, 8)            136         dense_35[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_39 (Dense)                (None, 8)            264         dense_38[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 16)           0           dense_36[0][0]                   \n",
            "                                                                 dense_39[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_40 (Dense)                (None, 2)            34          concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_41 (Dense)                (None, 1)            3           dense_40[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 11,813\n",
            "Trainable params: 11,813\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nCBrbQNxY1O"
      },
      "source": [
        "encoder = Dense(128)(input)  \n",
        "\n",
        "이와 같은 표현은  \n",
        "\n",
        "encoder = Dense(128)  \n",
        "encoder(input)\n",
        "\n",
        "이 표현과 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7BIc7FZy7_S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFzimbZBFwgo"
      },
      "source": [
        "## soynlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeSk8fjkF0QP"
      },
      "source": [
        "soynlp는 품사 태깅, 형태소 분석 등을 지원하는 한국어 형태소 분석기입니다. 비지도 학습으로 형태소 분석을 한다는 특징을 갖고 있으며, 데이터에 자주 등장하는 단어들을 형태소로 분석합니다. soynlp 형태소 분석기는 내부적으로 단어 점수 표로 동작합니다. 이 점수는 응집 확률(cohesion probability)과 브랜칭 엔트로피(branching entropy)를 활용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQnqQXy4Fu_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b150082a-2115-408e-e695-873edeebd88f"
      },
      "source": [
        "!pip install soynlp"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting soynlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/50/6913dc52a86a6b189419e59f9eef1b8d599cffb6f44f7bb91854165fc603/soynlp-0.0.493-py3-none-any.whl (416kB)\n",
            "\r\u001b[K     |▉                               | 10kB 19.8MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20kB 23.1MB/s eta 0:00:01\r\u001b[K     |██▍                             | 30kB 17.1MB/s eta 0:00:01\r\u001b[K     |███▏                            | 40kB 15.5MB/s eta 0:00:01\r\u001b[K     |████                            | 51kB 7.3MB/s eta 0:00:01\r\u001b[K     |████▊                           | 61kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 71kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 81kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 92kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 102kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 112kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 122kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 133kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 143kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 153kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 163kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 174kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 184kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 194kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 204kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 215kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 225kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 235kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 245kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 256kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 266kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 276kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 286kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 296kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 307kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 317kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 327kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 337kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 348kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 358kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 368kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 378kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 389kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 399kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 409kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 419kB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from soynlp) (0.22.2.post1)\n",
            "Requirement already satisfied: psutil>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from soynlp) (5.4.8)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->soynlp) (1.0.1)\n",
            "Installing collected packages: soynlp\n",
            "Successfully installed soynlp-0.0.493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR5hjIsmF1-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f963d522-9bf2-4473-b729-60c8becd07a7"
      },
      "source": [
        "import urllib.request\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/lovit/soynlp/master/tutorials/2016-10-20.txt\", filename=\"2016-10-20.txt\")"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2016-10-20.txt', <http.client.HTTPMessage at 0x7f82890c1a50>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVULVPMdF6eE"
      },
      "source": [
        "다운로드 한 말뭉치를 문서 단위로 분리합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0835RTkF45f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdc0535f-0817-4664-9158-375a15793f7e"
      },
      "source": [
        "from soynlp import DoublespaceLineCorpus\n",
        "\n",
        "# 말뭉치에 대해서 다수의 문서로 분리\n",
        "corpus = DoublespaceLineCorpus(\"2016-10-20.txt\")\n",
        "len(corpus)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30091"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibxbjyLlF-2k"
      },
      "source": [
        "총 3만 91개의 문서가 존재합니다. 공백이 아닌 문서에 한해 상위 3개의 문서만 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-H52M98_F9JP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "473fc327-06c2-4ac7-9d24-84369626c026"
      },
      "source": [
        "i = 0\n",
        "for document in corpus:\n",
        "  if len(document) > 0:\n",
        "    print(document)\n",
        "    i = i+1\n",
        "  if i == 3:\n",
        "    break"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19  1990  52 1 22\n",
            "오패산터널 총격전 용의자 검거 서울 연합뉴스 경찰 관계자들이 19일 오후 서울 강북구 오패산 터널 인근에서 사제 총기를 발사해 경찰을 살해한 용의자 성모씨를 검거하고 있다 성씨는 검거 당시 서바이벌 게임에서 쓰는 방탄조끼에 헬멧까지 착용한 상태였다 독자제공 영상 캡처 연합뉴스  서울 연합뉴스 김은경 기자 사제 총기로 경찰을 살해한 범인 성모 46 씨는 주도면밀했다  경찰에 따르면 성씨는 19일 오후 강북경찰서 인근 부동산 업소 밖에서 부동산업자 이모 67 씨가 나오기를 기다렸다 이씨와는 평소에도 말다툼을 자주 한 것으로 알려졌다  이씨가 나와 걷기 시작하자 성씨는 따라가면서 미리 준비해온 사제 총기를 이씨에게 발사했다 총알이 빗나가면서 이씨는 도망갔다 그 빗나간 총알은 지나가던 행인 71 씨의 배를 스쳤다  성씨는 강북서 인근 치킨집까지 이씨 뒤를 쫓으며 실랑이하다 쓰러뜨린 후 총기와 함께 가져온 망치로 이씨 머리를 때렸다  이 과정에서 오후 6시 20분께 강북구 번동 길 위에서 사람들이 싸우고 있다 총소리가 났다 는 등의 신고가 여러건 들어왔다  5분 후에 성씨의 전자발찌가 훼손됐다는 신고가 보호관찰소 시스템을 통해 들어왔다 성범죄자로 전자발찌를 차고 있던 성씨는 부엌칼로 직접 자신의 발찌를 끊었다  용의자 소지 사제총기 2정 서울 연합뉴스 임헌정 기자 서울 시내에서 폭행 용의자가 현장 조사를 벌이던 경찰관에게 사제총기를 발사해 경찰관이 숨졌다 19일 오후 6시28분 강북구 번동에서 둔기로 맞았다 는 폭행 피해 신고가 접수돼 현장에서 조사하던 강북경찰서 번동파출소 소속 김모 54 경위가 폭행 용의자 성모 45 씨가 쏜 사제총기에 맞고 쓰러진 뒤 병원에 옮겨졌으나 숨졌다 사진은 용의자가 소지한 사제총기  신고를 받고 번동파출소에서 김창호 54 경위 등 경찰들이 오후 6시 29분께 현장으로 출동했다 성씨는 그사이 부동산 앞에 놓아뒀던 가방을 챙겨 오패산 쪽으로 도망간 후였다  김 경위는 오패산 터널 입구 오른쪽의 급경사에서 성씨에게 접근하다가 오후 6시 33분께 풀숲에 숨은 성씨가 허공에 난사한 10여발의 총알 중 일부를 왼쪽 어깨 뒷부분에 맞고 쓰러졌다  김 경위는 구급차가 도착했을 때 이미 의식이 없었고 심폐소생술을 하며 병원으로 옮겨졌으나 총알이 폐를 훼손해 오후 7시 40분께 사망했다  김 경위는 외근용 조끼를 입고 있었으나 총알을 막기에는 역부족이었다  머리에 부상을 입은 이씨도 함께 병원으로 이송됐으나 생명에는 지장이 없는 것으로 알려졌다  성씨는 오패산 터널 밑쪽 숲에서 오후 6시 45분께 잡혔다  총격현장 수색하는 경찰들 서울 연합뉴스 이효석 기자 19일 오후 서울 강북구 오패산 터널 인근에서 경찰들이 폭행 용의자가 사제총기를 발사해 경찰관이 사망한 사건을 조사 하고 있다  총 때문에 쫓던 경관들과 민간인들이 몸을 숨겼는데 인근 신발가게 직원 이모씨가 다가가 성씨를 덮쳤고 이어 현장에 있던 다른 상인들과 경찰이 가세해 체포했다  성씨는 경찰에 붙잡힌 직후 나 자살하려고 한 거다 맞아 죽어도 괜찮다 고 말한 것으로 전해졌다  성씨 자신도 경찰이 발사한 공포탄 1발 실탄 3발 중 실탄 1발을 배에 맞았으나 방탄조끼를 입은 상태여서 부상하지는 않았다  경찰은 인근을 수색해 성씨가 만든 사제총 16정과 칼 7개를 압수했다 실제 폭발할지는 알 수 없는 요구르트병에 무언가를 채워두고 심지를 꽂은 사제 폭탄도 발견됐다  일부는 숲에서 발견됐고 일부는 성씨가 소지한 가방 안에 있었다\n",
            "테헤란 연합뉴스 강훈상 특파원 이용 승객수 기준 세계 최대 공항인 아랍에미리트 두바이국제공항은 19일 현지시간 이 공항을 이륙하는 모든 항공기의 탑승객은 삼성전자의 갤럭시노트7을 휴대하면 안 된다고 밝혔다  두바이국제공항은 여러 항공 관련 기구의 권고에 따라 안전성에 우려가 있는 스마트폰 갤럭시노트7을 휴대하고 비행기를 타면 안 된다 며 탑승 전 검색 중 발견되면 압수할 계획 이라고 발표했다  공항 측은 갤럭시노트7의 배터리가 폭발 우려가 제기된 만큼 이 제품을 갖고 공항 안으로 들어오지 말라고 이용객에 당부했다  이런 조치는 두바이국제공항 뿐 아니라 신공항인 두바이월드센터에도 적용된다  배터리 폭발문제로 회수된 갤럭시노트7 연합뉴스자료사진\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmviMaUAGEH3"
      },
      "source": [
        "soynlp는 비지도학습 형태소 분석기이므로 기존의 형태소 분석기와는 달리 학습 과정을 거쳐야 합니다. 이는 전체 코퍼스로부터 응집 확률과 브랜칭 엔트로피 단어 점수표를 만드는 과정이지요. WordExtractor.extract()를 통해서 전체 코퍼스에 대해 단어 점수표를 계산합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9wDUf8RGEsu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cc1d94f-c156-4fa1-e792-eee9dc389a1d"
      },
      "source": [
        "from soynlp.word import WordExtractor\n",
        "word_extractor = WordExtractor()\n",
        "word_extractor.train(corpus)\n",
        "word_score_table = word_extractor.extract()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training was done. used memory 2.462 Gb\n",
            "all cohesion probabilities was computed. # words = 223348\n",
            "all branching entropies was computed # words = 361598\n",
            "all accessor variety was computed # words = 361598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4tAK15-GJiN"
      },
      "source": [
        "## soynlp의 응집 확률(cohesion probability)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgV9OQplGMMV"
      },
      "source": [
        "응집 확률은 내부 문자열(substring)이 얼마나 응집하여 자주 등장하는지를 판단하는 척도입니다. 응집 확률은 문자열을 문자 단위로 분리하여 내부 문자열을 만드는 과정에서 왼쪽부터 순서대로 문자를 추가하면서 각 문자열이 주어졌을 때 그 다음 문자가 나올 확률을 계산하여 누적곱을 한 값입니다. 이 값이 높을수록 전체 코퍼스에서 이 문자열 시퀀스는 하나의 단어로 등장할 가능성이 높습니다. 수식은 아래와 같습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx_dW5mRGNMD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "d166c727-1882-4c99-af7c-7e9d416901e8"
      },
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image('https://wikidocs.net/images/page/84111/soynlp.png')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_vszl7YG4uY"
      },
      "source": [
        "아직은 아리송 할 거에요. '반포한강공원에'라는 7의 길이를 가진 문자 시퀀스에 대해서 각 내부 문자열의 스코어를 구하는 과정은 아래와 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPJa_edNGyOX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "outputId": "fb078984-637d-403a-f2d3-63392bba4255"
      },
      "source": [
        "Image('https://wikidocs.net/images/page/84111/soynlp2.png')"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXG0qmBBG76m"
      },
      "source": [
        "실습을 통해 직접 응집 확률을 계산해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwsPQmGR1Vg6",
        "outputId": "5468d203-ea2e-4d63-b427-4c251f39e998"
      },
      "source": [
        "word_score_table[\"반\"].cohesion_forward"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "evccfkGY1Uh2",
        "outputId": "8ff0fcc2-3fba-4e70-d9f5-e0515ac9c92a"
      },
      "source": [
        "word_score_table[\"반포\"].cohesion_forward"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-a1e6fbab0b5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword_score_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"반포\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcohesion_forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: '반포'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u25oZKTCG1rP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "231fbc49-7556-4c42-9c4b-87055f23c232"
      },
      "source": [
        "word_score_table[\"반포한\"].cohesion_forward"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08838002913645132"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sekKNFNG-d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ec12599-d337-4b68-cdc9-58a66892153e"
      },
      "source": [
        "word_score_table[\"반포한강\"].cohesion_forward"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.19841268168224552"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRT7n6N3G_TI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7883d7f3-c458-476a-93f4-a97e9bb3813b"
      },
      "source": [
        "word_score_table[\"반포한강공\"].cohesion_forward"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2972877884078849"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKE32nDKHHo7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ec99a2f-f38f-4f75-e9aa-13850159bb4c"
      },
      "source": [
        "word_score_table[\"반포한강공원\"].cohesion_forward"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.37891487632839754"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVpqoRvfHI5K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a8da17e-133e-46e5-8ffe-5793fb956ff8"
      },
      "source": [
        "word_score_table[\"반포한강공원에\"].cohesion_forward"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.33492963377557666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVfhi2tTHPVl"
      },
      "source": [
        "## soynlp의 브랜칭 엔트로피(branching entropy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzzaSHi3HQC3"
      },
      "source": [
        "Branching Entropy는 확률 분포의 엔트로피값을 사용합니다.  이는 주어진 문자열에서 얼마나 다음 문자가 등장할 수 있는지를 판단하는 척도입니다. 이해를 위해 퀴즈를 내보겠습니다. 제가 어떤 단어를 생각 중인데, 한 문자씩 말해드릴테니까 매번 다음 문자를 맞추는 것이 퀴즈입니다.\n",
        "\n",
        "첫번째 문자는 '디'입니다. 다음에 등장할 문자를 맞춰보세요. 솔직히 가늠이 잘 안 가지요? '디'로 시작하는 단어가 얼마나 많은데요. 이걸 어떻게 맞추냐구요. 정답은 '스' 입니다.\n",
        "\n",
        "이제 '디스'까지 나왔네요. '디스 '다음 문자는 뭘까요? 벌써 정답 단어를 예측한 분도 있을테고, 여전히 가늠이 잘 안가시는 분도 있을 거에요. '디스카운트'라는 단어가 있으니까 '카'일까? 아니면 '디스코드'라는 단어가 있으니까 '코'인가? 생각해보니 '디스코'가 정답일 수도 있겠네요. 그러면 '코'인가? '디스아너드'라는 게임이 있으니까 '아'? 전부 땡땡땡! 이 단어들을 생각하신 분들은 전부 틀렸습니다. 정답은 '플'이었습니다.\n",
        "\n",
        "'디스플'까지 왔습니다. 다음 문자 맞춰보세요. 이제 좀 명백해지는군요. 이 정도 되면 헷갈리시는 분들은 거의 없을거에요. 정답은 '레'입니다. '디스플레' 다음에는 어떤 문자일까요? 너무 명백해서 문제라고 보기도 어려워졌어요. 정답은 '이'입니다. 제가 생각한 단어는 '디스플레이'였습니다!\n",
        "\n",
        "저는 지금 브랜칭 엔트로피를 시뮬레이션한 겁니다. 브랜칭 엔트로피를 주어진 문자 시퀀스에서 다음 문자 예측을 위해 헷갈리는 정도로 비유해봅시다. 브랜칭 엔트로피의 값은 하나의 완성된 단어에 가까워질수록 문맥으로 인해 점점 정확히 예측할 수 있게 되면서 점점 줄어듭니다. 실습해볼게요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIitCxwbHRn3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceafd857-80f8-4147-ace8-a3a751762743"
      },
      "source": [
        "word_score_table[\"디스\"].right_branching_entropy"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.6371694761537934"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnKStLHyHXam",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20fceef2-d984-4ddb-fed4-e60bcda7a00c"
      },
      "source": [
        "word_score_table[\"디스플\"].right_branching_entropy"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fzudrAAHccz"
      },
      "source": [
        "'디스' 다음에는 다양한 문자가 올 수 있으니까 1.63이라는 값을 가지는 반면, '디스플'이라는 문자열 다음에는 다음 문자로 '레'가 오는 것이 너무나 명백하기 때문에 0이란 값을 가집니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRKwW0q4HenU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "816b375f-3b33-46b1-e8c6-105ea7936f14"
      },
      "source": [
        "word_score_table[\"디스플레\"].right_branching_entropy"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCLchyiFHgHA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f5d2c0b-e724-4c67-dbb1-41e46abcf4fa"
      },
      "source": [
        "word_score_table[\"디스플레이\"].right_branching_entropy"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.1400392861792916"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ktRy49nHlcR"
      },
      "source": [
        "갑자기 값이 급증합니다. 그 이유는 문자 시퀀스 '디스플레이'라는 문자 시퀀스 다음에는 조사나 다른 단어와 같은 다양한 경우가 있을 수 있기 때문입니다. 이는 하나의 단어가 끝나면 그 경계 부분부터 다시 브랜칭 엔트로피 값이 증가하게 됨을 의미합니다. 그리고 이 값으로 단어를 판단하는 것이 가능하겠죠?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DigXtkNpHnuZ"
      },
      "source": [
        "## soynlp의 L tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-KO3A2HHsam"
      },
      "source": [
        "한국어는 띄어쓰기 단위로 나눈 어절 토큰은 주로 L 토큰 + R 토큰의 형식을 가질 때가 많습니다. 예를 들어서 '공원에'는 '공원 + 에'로 나눌 수 있겠지요. 또는 '공부하는'은 '공부 + 하는'으로 나눌 수도 있을 것입니다. L 토크나이저는 L 토큰 + R 토큰으로 나누되, 분리 기준을 점수가 가장 높은 L 토큰을 찾아내는 원리를 가지고 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXrktIsSHrHo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "638e8e0d-0670-4747-91fc-11e76426f8f0"
      },
      "source": [
        "from soynlp.tokenizer import LTokenizer\n",
        "\n",
        "scores = {word:score.cohesion_forward for word, score in word_score_table.items()}\n",
        "l_tokenizer = LTokenizer(scores=scores)\n",
        "l_tokenizer.tokenize(\"국제사회와 우리의 노력들로 범죄를 척결하자\", flatten=False)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('국제사회', '와'), ('우리', '의'), ('노력', '들로'), ('범죄', '를'), ('척결', '하자')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nh-YlIvnHySl"
      },
      "source": [
        "## 최대 점수 토크나이저"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ml5hwIWTH0fh"
      },
      "source": [
        "최대 점수 토크나이저는 띄어쓰기가 되지 않는 문장에서 점수가 높은 글자 시퀀스를 순차적으로 찾아내는 토크나이저입니다. 띄어쓰기가 되어 있지 않은 문장을 넣어서 점수를 통해 토큰화 된 결과를 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6k2y_q3HuAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1090cf09-f1a1-4088-c57a-6fcdfdedb734"
      },
      "source": [
        "from soynlp.tokenizer import MaxScoreTokenizer\n",
        "\n",
        "maxscore_tokenizer = MaxScoreTokenizer(scores=scores)\n",
        "maxscore_tokenizer.tokenize(\"국제사회와우리의노력들로범죄를척결하자\")"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['국제사회', '와', '우리', '의', '노력', '들로', '범죄', '를', '척결', '하자']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    }
  ]
}